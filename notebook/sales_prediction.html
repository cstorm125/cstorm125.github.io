<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Predict Zero-inflated and Long/fat-tailed Outcomes – chariblog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3fcf6f9ed68d419e61de4dc6f9dc2392.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">chariblog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cstorm125"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/cstorm125/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://scholar.google.com/citations?user=UX36NGkAAAAJ"> <i class="bi bi-google" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predict Zero-inflated and Long/fat-tailed Outcomes</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This notebook details how to predict a real-number outcome that is zero-inflated and long/fat-tailed such as sales prediction in retail. We provide baseline regression, regression trained using winsorized outcome, regression trained on log(y+1) outcome, and hurdle regression with and without Duan’s method.</p>
<section id="import" class="level2">
<h2 class="anchored" data-anchor-id="import">Import</h2>
<div id="cell-4" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ucimlrepo <span class="im">import</span> fetch_ucirepo </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularDataset, TabularPredictor</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    mean_squared_error, mean_absolute_error, r2_score, median_absolute_error,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr, spearmanr, wasserstein_distance</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_regression_metrics(y_true, y_pred):</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'root_mean_squared_error'</span>: np.sqrt(mean_squared_error(y_true, y_pred)),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'mean_squared_error'</span>: mean_squared_error(y_true, y_pred),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'mean_absolute_error'</span>: mean_absolute_error(y_true, y_pred),</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'r2'</span>: r2_score(y_true, y_pred),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pearsonr'</span>: pearsonr(y_true, y_pred)[<span class="dv">0</span>],  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'spearmanr'</span>: spearmanr(y_true, y_pred)[<span class="dv">0</span>],</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'median_absolute_error'</span>: median_absolute_error(y_true, y_pred),</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'earths_mover_distance'</span>: wasserstein_distance(y_true, y_pred)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> caluclate_classification_metrics(y_true, y_pred):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy_score(y_true, y_pred),</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'precision'</span>: precision_score(y_true, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">'recall'</span>: recall_score(y_true, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>),</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'f1_score'</span>: f1_score(y_true, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>),</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'confusion_matrix'</span>: confusion_matrix(y_true, y_pred)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> string_to_yearmon(date):</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    date <span class="op">=</span> date.split()</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    date <span class="op">=</span> date[<span class="dv">0</span>].split(<span class="st">'/'</span>) <span class="op">+</span> date[<span class="dv">1</span>].split(<span class="st">':'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    date <span class="op">=</span> date[<span class="dv">2</span>] <span class="op">+</span> <span class="st">'-'</span> <span class="op">+</span> date[<span class="dv">0</span>].zfill(<span class="dv">2</span>) <span class="co">#+ '-' + date[1].zfill(2) + ' ' + date[3].zfill(2) + ':' + date[4].zfill(2)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> date</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_llama(system_prompt, <span class="bu">input</span>):</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    template <span class="op">=</span> <span class="ss">f"""&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ss">&lt;&lt;/SYS&gt;&gt;</span><span class="sc">{</span><span class="bu">input</span><span class="sc">}</span><span class="ss">[/INST]"""</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    client <span class="op">=</span> boto3.client(service_name<span class="op">=</span><span class="st">'bedrock-runtime'</span>,region_name<span class="op">=</span><span class="st">'us-west-2'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    body <span class="op">=</span> json.dumps({</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prompt"</span>: template,</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"temperature"</span>: <span class="fl">0.</span>,</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">"top_p"</span>: <span class="fl">0.9</span>,</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"max_gen_len"</span>: <span class="dv">2048</span>,</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.invoke_model(</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        body<span class="op">=</span>body,</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        modelId<span class="op">=</span><span class="st">'us.meta.llama3-2-90b-instruct-v1:0'</span>,</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        accept<span class="op">=</span><span class="st">'application/json'</span>,</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>        contentType<span class="op">=</span><span class="st">'application/json'</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    response_body <span class="op">=</span> json.loads(response[<span class="st">'body'</span>].read())</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response_body</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_claude(system_prompt, <span class="bu">input</span>):</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    client <span class="op">=</span> boto3.client(service_name<span class="op">=</span><span class="st">'bedrock-runtime'</span>,region_name<span class="op">=</span><span class="st">'us-west-2'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    body<span class="op">=</span>json.dumps(</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>            <span class="st">"anthropic_version"</span>: <span class="st">"bedrock-2023-05-31"</span>,</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">"max_tokens"</span>: <span class="dv">2048</span>,</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">"messages"</span>: [</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>                {</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"content"</span>: [</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>                    {</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"type"</span>: <span class="st">"text"</span>,</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"text"</span>: system_prompt <span class="op">+</span> <span class="st">'</span><span class="ch">\n</span><span class="st">'</span> <span class="op">+</span> <span class="bu">input</span>,</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>                    ]</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        }  </span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    )  </span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.invoke_model(body<span class="op">=</span>body, </span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>                                   modelId<span class="op">=</span><span class="st">'anthropic.claude-3-5-sonnet-20241022-v2:0'</span>,</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>                                   contentType<span class="op">=</span><span class="st">'application/json'</span>,</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>                                   accept<span class="op">=</span><span class="st">'application/json'</span>)</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    response_body <span class="op">=</span> json.loads(response.get(<span class="st">'body'</span>).read())</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response_body</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<p>We use the <a href="https://archive.ics.uci.edu/dataset/352/online+retail">UCI Online Retail</a> dataset, which are transactions from a UK-based, non-store online retail from 2010-12-01 and 2011-12-09. We perform the following data processing:</p>
<ol type="1">
<li>Remove transactions without <code>CustomerID</code>; from 541,909 to 406,829 transactions</li>
<li>Filter out transactions where either <code>UnitPrice</code> or <code>Quantity</code> is less than zero; from 406,829 to 397,884 transactions</li>
<li>Fill in missing product <code>Description</code> with value <code>UNKNOWN</code>.</li>
</ol>
<div id="cell-7" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>online_retail <span class="op">=</span> fetch_ucirepo(<span class="bu">id</span><span class="op">=</span><span class="dv">352</span>) </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>transaction_df <span class="op">=</span> online_retail[<span class="st">'data'</span>][<span class="st">'original'</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>transaction_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>(541909, 8)</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create yearmon for train-valid split</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>transaction_df[<span class="st">'yearmon'</span>] <span class="op">=</span> transaction_df.InvoiceDate.<span class="bu">map</span>(string_to_yearmon)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#get rid of transactions without cid</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>transaction_df <span class="op">=</span> transaction_df[<span class="op">~</span>transaction_df.CustomerID.isna()].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#fill in unknown descriptions</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>transaction_df.Description <span class="op">=</span> transaction_df.Description.fillna(<span class="st">'UNKNOWN'</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">#convert customer id to string</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>transaction_df[<span class="st">'CustomerID'</span>] <span class="op">=</span> transaction_df[<span class="st">'CustomerID'</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="bu">str</span>(<span class="bu">int</span>(x)))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>transaction_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>(406829, 9)</code></pre>
</div>
</div>
<div id="cell-9" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#check if still na</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>transaction_df.isna().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>InvoiceNo      0.0
StockCode      0.0
Description    0.0
Quantity       0.0
InvoiceDate    0.0
UnitPrice      0.0
CustomerID     0.0
Country        0.0
yearmon        0.0
dtype: float64</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simplify by filtering unit price and quantity to be non-zero (get rid of discounts, cancellations, etc)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>transaction_df <span class="op">=</span> transaction_df[(transaction_df.UnitPrice<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">&amp;\</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                (transaction_df.Quantity<span class="op">&gt;</span><span class="dv">0</span>)].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#add sales</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>transaction_df[<span class="st">'Sales'</span>] <span class="op">=</span> transaction_df.UnitPrice <span class="op">*</span> transaction_df.Quantity</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>transaction_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>(397884, 10)</code></pre>
</div>
</div>
</section>
<section id="problem-formulation-and-outcome" class="level2">
<h2 class="anchored" data-anchor-id="problem-formulation-and-outcome">Problem Formulation and Outcome</h2>
<p>We formulate the problem as predicting the sales (<code>TargetSales</code>) during Q4 2011 for each customers who bought at least one item during Q1-Q3 2011. Note that we are interested in predicting the <strong>actual sales number per customer</strong> as accurately as possible; this is common for marketing use cases such as determining what spend threshold to give each customer in a promotion, targeting customers for upselling, or detecting early signs of churns.</p>
<p>We transform the transaction dataset into a customer-level dataset where we calculate features using transactions between 2011-01 to 2011-09 and outcome using transactions between 2011-10 to 2011-12, summing <code>Quantity</code> times <code>UnitPrice</code>. We left-join the customers in feature set to outcome set. This will result in the zero-inflated nature of the outcome as not all customers will come back in Q4. The distribution of non-zero sales is naturally long/fat-tailed with a few customers having extraordinarily high amount of sales in Q4. This resulted in a customer-level dataset with 3,438 customers.</p>
<div id="cell-13" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>feature_period <span class="op">=</span> {<span class="st">'start'</span>: <span class="st">'2011-01'</span>, <span class="st">'end'</span>: <span class="st">'2011-09'</span>}</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>outcome_period <span class="op">=</span> {<span class="st">'start'</span>: <span class="st">'2011-10'</span>, <span class="st">'end'</span>: <span class="st">'2011-12'</span>}</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>feature_transaction <span class="op">=</span> transaction_df[(transaction_df.yearmon<span class="op">&gt;=</span>feature_period[<span class="st">'start'</span>])<span class="op">&amp;\</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                                      (transaction_df.yearmon<span class="op">&lt;=</span>feature_period[<span class="st">'end'</span>])]</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>outcome_transaction <span class="op">=</span> transaction_df[(transaction_df.yearmon<span class="op">&gt;=</span>outcome_period[<span class="st">'start'</span>])<span class="op">&amp;\</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>                                      (transaction_df.yearmon<span class="op">&lt;=</span>outcome_period[<span class="st">'end'</span>])]</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>feature_transaction.shape, outcome_transaction.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>((240338, 10), (131389, 10))</code></pre>
</div>
</div>
<div id="cell-14" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#aggregate sales during outcome period</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>outcome_sales <span class="op">=</span> outcome_transaction.groupby(<span class="st">'CustomerID'</span>).Sales.<span class="bu">sum</span>().reset_index()</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>outcome_sales</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Sales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12347</td>
<td>1519.14</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12349</td>
<td>1757.55</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>12352</td>
<td>311.73</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12356</td>
<td>58.35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>12357</td>
<td>6207.67</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2555</td>
<td>18276</td>
<td>335.86</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2556</td>
<td>18277</td>
<td>110.38</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2557</td>
<td>18282</td>
<td>77.84</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2558</td>
<td>18283</td>
<td>974.21</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2559</td>
<td>18287</td>
<td>1072.00</td>
</tr>
</tbody>
</table>

<p>2560 rows × 2 columns</p>
</div>
</div>
</div>
<div id="cell-15" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#aggregate sales during feature period</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>feature_sales <span class="op">=</span> feature_transaction.groupby(<span class="st">'CustomerID'</span>).Sales.<span class="bu">sum</span>().reset_index()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>feature_sales</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Sales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12346</td>
<td>77183.60</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12347</td>
<td>2079.07</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>12348</td>
<td>904.44</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12350</td>
<td>334.40</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>12352</td>
<td>2194.31</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3433</td>
<td>18280</td>
<td>180.60</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3434</td>
<td>18281</td>
<td>80.82</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3435</td>
<td>18282</td>
<td>100.21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3436</td>
<td>18283</td>
<td>1120.67</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3437</td>
<td>18287</td>
<td>765.28</td>
</tr>
</tbody>
</table>

<p>3438 rows × 2 columns</p>
</div>
</div>
</div>
<div id="cell-16" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#merge to get TargetSales including those who spent during feature period but not during outcome (zeroes)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>outcome_df <span class="op">=</span> feature_sales[[<span class="st">'CustomerID'</span>]].merge(outcome_sales, on<span class="op">=</span><span class="st">'CustomerID'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>outcome_df[<span class="st">'Sales'</span>] <span class="op">=</span> outcome_df[<span class="st">'Sales'</span>].fillna(<span class="dv">0</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>outcome_df.columns <span class="op">=</span> [<span class="st">'CustomerID'</span>, <span class="st">'TargetSales'</span>]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>outcome_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">TargetSales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12346</td>
<td>0.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12347</td>
<td>1519.14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>12348</td>
<td>0.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12350</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>12352</td>
<td>311.73</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3433</td>
<td>18280</td>
<td>0.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3434</td>
<td>18281</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3435</td>
<td>18282</td>
<td>77.84</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3436</td>
<td>18283</td>
<td>974.21</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3437</td>
<td>18287</td>
<td>1072.00</td>
</tr>
</tbody>
</table>

<p>3438 rows × 2 columns</p>
</div>
</div>
</div>
<div id="cell-17" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#confirm zero-inflated, long/fat-tailed</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>outcome_df.TargetSales.describe(percentiles<span class="op">=</span>[i<span class="op">/</span><span class="dv">10</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>count      3438.000000
mean        666.245829
std        4016.843037
min           0.000000
0%            0.000000
10%           0.000000
20%           0.000000
30%           0.000000
40%           0.000000
50%         102.005000
60%         263.006000
70%         425.790000
80%         705.878000
90%        1273.611000
max      168469.600000
Name: TargetSales, dtype: float64</code></pre>
</div>
</div>
<div id="cell-18" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#confirm zero-inflated, long/fat-tailed</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>outcome_df[outcome_df.TargetSales<span class="op">&lt;=</span><span class="dv">10_000</span>].TargetSales.hist(bins<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sales_prediction_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="feature" class="level2">
<h2 class="anchored" data-anchor-id="feature">Feature</h2>
<p>We represent a customer using traditional RFM features namely recency of purchase, purchase days, total sales, number of distinct products purchased, number of distinct category purchased, customer tenure within 2011, average purchase frequency, average purchase value, and percentage of purchase across all 9 categories. This is based on data from Q1-Q3 2011.</p>
<p>Since the <a href="https://archive.ics.uci.edu/dataset/352/online+retail">UCI Online Retail</a> dataset does not have a category but only contains descriptions over 3,000 items, we use <code>LLaMA 3.2 90B</code> to infer categories based on randomly selected 1,000 descriptions. This is to make the category preference representation for each customer, which is more tractable than including features about all 3,000+ items. After that, we use the same model to label a category for each description. The categories are:</p>
<ol type="1">
<li>Home Decor</li>
<li>Kitchen and Dining</li>
<li>Fashion Accessories</li>
<li>Stationary and Gifts</li>
<li>Toys and Games</li>
<li>Seasonal and Holiday</li>
<li>Personal Care and Wellness</li>
<li>Outdoor and Garden</li>
<li>Others</li>
</ol>
<section id="classify-description-into-category" class="level3">
<h3 class="anchored" data-anchor-id="classify-description-into-category">Classify <code>Description</code> into <code>Category</code></h3>
<div id="cell-22" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>feature_transaction.Description.nunique()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>3548</code></pre>
</div>
</div>
<section id="get-category" class="level4">
<h4 class="anchored" data-anchor-id="get-category">Get <code>Category</code></h4>
<div id="cell-24" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>descriptions <span class="op">=</span> feature_transaction.Description.unique().tolist()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(descriptions[:<span class="dv">5</span>])</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#randomize descriptions with seed 112 to get which categories we should use</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">112</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>random_descriptions <span class="op">=</span> np.random.choice(descriptions, <span class="dv">1000</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(random_descriptions[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['JUMBO BAG PINK POLKADOT', 'BLUE POLKADOT WRAP', 'RED RETROSPOT WRAP ', 'RECYCLING BAG RETROSPOT ', 'RED RETROSPOT SHOPPER BAG']
['MODERN FLORAL STATIONERY SET' 'PURPLE BERTIE GLASS BEAD BAG CHARM'
 'PARTY INVITES SPACEMAN' 'MONTANA DIAMOND CLUSTER EARRINGS'
 'SKULLS  DESIGN  COTTON TOTE BAG']</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># res = call_llama(</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     'You are a product categorization assistant at a retail website.',</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\n'.join(random_descriptions)</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(res['generation'])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-26" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># res</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># res = call_claude(</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     'You are a product categorization assistant at a retail website.',</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\n'.join(random_descriptions)</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(res['content'][0]['text'])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-28" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># res</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>LLaMA 3.2 90B Output:</p>
<pre><code>&lt;&lt;SYS&gt;&gt;Based on the product descriptions, I would categorize them into the following categories:

1. Home Decor:
    * Wall art
    * Decorative items (e.g. vases, figurines, etc.)
    * Lighting (e.g. candles, lanterns, etc.)
    * Textiles (e.g. throw pillows, blankets, etc.)
2. Kitchen and Dining:
    * Cookware and utensils
    * Tableware (e.g. plates, cups, etc.)
    * Kitchen decor (e.g. signs, magnets, etc.)
    * Food and drink items (e.g. tea, coffee, etc.)
3. Fashion and Accessories:
    * Jewelry (e.g. necklaces, earrings, etc.)
    * Handbags and wallets
    * Clothing and accessories (e.g. scarves, hats, etc.)
4. Stationery and Gifts:
    * Cards and gift wrap
    * Stationery (e.g. notebooks, pens, etc.)
    * Gift items (e.g. mugs, keychains, etc.)
5. Toys and Games:
    * Toys (e.g. stuffed animals, puzzles, etc.)
    * Games and puzzles
6. Seasonal and Holiday:
    * Christmas decorations and gifts
    * Easter decorations and gifts
    * Other seasonal items (e.g. Halloween, etc.)
7. Personal Care and Wellness:
    * Beauty and personal care items (e.g. skincare, haircare, etc.)
    * Wellness and self-care items (e.g. essential oils, etc.)
8. Outdoor and Garden:
    * Garden decor and accessories
    * Outdoor furniture and decor
    * Gardening tools and supplies

Note that some products may fit into multiple categories, but I have assigned them to the one that seems most relevant.</code></pre>
<p>Claude 3.5 v2 Output</p>
<pre><code>Based on these product descriptions, I would suggest the following main product categories:

1. Home Decor
- Candle holders
- Picture frames
- Wall art &amp; signs
- Clocks
- Cushions &amp; covers
- Storage items
- Decorative objects

2. Jewelry &amp; Accessories
- Necklaces
- Bracelets
- Earrings
- Hair accessories
- Bag charms
- Key rings

3. Garden &amp; Outdoor
- Plant pots
- Garden tools
- Outdoor decorations
- Bird houses
- Garden markers

4. Kitchen &amp; Dining
- Tea sets
- Mugs
- Kitchen storage
- Cutlery
- Baking accessories
- Tea towels

5. Stationery &amp; Paper Goods
- Notebooks
- Gift wrap
- Cards
- Paper decorations
- Writing sets

6. Party &amp; Celebrations
- Party supplies
- Gift bags
- Christmas decorations
- Easter items
- Birthday items

7. Children's Items
- Toys
- Children's tableware
- School supplies
- Kids' accessories

8. Fashion Accessories
- Bags
- Purses
- Scarves
- Travel accessories

9. Bath &amp; Beauty
- Bathroom accessories
- Toiletry bags
- Beauty items

10. Lighting
- Lamps
- String lights
- Tea lights
- Lanterns

These categories cover the main types of products in the list while providing logical groupings for customers to browse.</code></pre>
<div id="cell-30" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> [</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Home Decor'</span>,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Kitchen and Dining'</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Fashion Accessories'</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Stationary and Gifts'</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Toys and Games'</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Seasonal and Holiday'</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Personal Care and Wellness'</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Outdoor and Garden'</span>,   </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(categories)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>8</code></pre>
</div>
</div>
</section>
<section id="annotate-category-to-description" class="level4">
<h4 class="anchored" data-anchor-id="annotate-category-to-description">Annotate <code>Category</code> to <code>Description</code></h4>
<div id="cell-32" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># #loop through descriptions in batches of batch_size</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># res_texts = []</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># batch_size = 100</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># for i in tqdm(range(0, len(descriptions), batch_size)):</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     batch = descriptions[i:i+batch_size]</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     d = "\n".join(batch)</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     inp = f'''Categorize the following product descriptions into {", ".join(categories)} or Others, if they do not fall into any. </span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Only answer in the following format:</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># "product description of product #1"|"product category classified into"</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co"># "product description of product #2"|"product category classified into"</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ...</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co"># "product description of product #n"|"product category classified into"</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Here are the product descriptions:</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co"># {d}</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># '''</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     while True:</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="co">#         res = call_claude('You are a product categorizer at a retail website', inp)</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co">#         # if res['generation_token_count'] &gt; 1: #for llama</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co">#         if res['usage']['output_tokens'] &gt; 1:</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="co">#             break</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a><span class="co">#         else:</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co">#             print('Retrying...')</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="co">#             time.sleep(2)</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="co">#     res_text = res['content'][0]['text'].strip().split('\n')</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="co">#         #for llama</span></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a><span class="co">#         # .replace('[SYS]','').replace('&lt;&lt;SYS&gt;&gt;','')\</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a><span class="co">#         # .replace('[/SYS]','').replace('&lt;&lt;/SYS&gt;&gt;','')\</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="co">#     if res_text!='':</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a><span class="co">#         res_texts.extend(res_text)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-33" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># with open('../data/sales_prediction/product_description_category.csv','w') as f:</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     f.write('"product_description"|"category"\n')</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     for i in res_texts:</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co">#         f.write(f'{i}\n')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-34" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>product_description_category <span class="op">=</span> pd.read_csv(<span class="st">'../data/sales_prediction/product_description_category.csv'</span>,</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>                                           sep<span class="op">=</span><span class="st">'|'</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#clean product_description</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>product_description_category[<span class="st">'Description'</span>] <span class="op">=</span> descriptions</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>product_description_category.category.value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>category
Home Decor                    0.328636
Kitchen and Dining            0.195885
Fashion Accessories           0.138670
Stationary and Gifts          0.116122
Seasonal and Holiday          0.087373
Personal Care and Wellness    0.047351
Toys and Games                0.045096
Outdoor and Garden            0.032976
Others                        0.007892
Name: proportion, dtype: float64</code></pre>
</div>
</div>
<div id="cell-35" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>feature_transaction_cat <span class="op">=</span> feature_transaction.merge(product_description_category,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>                                                    how<span class="op">=</span><span class="st">'inner'</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                                                    on <span class="op">=</span> <span class="st">'Description'</span>,)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>feature_transaction.shape, feature_transaction_cat.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>((240338, 10), (240338, 12))</code></pre>
</div>
</div>
</section>
</section>
<section id="rfm" class="level3">
<h3 class="anchored" data-anchor-id="rfm">RFM</h3>
<div id="cell-37" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">#convert invoice date to datetime</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>feature_transaction_cat[<span class="st">'InvoiceDate'</span>] <span class="op">=</span> pd.to_datetime(feature_transaction_cat[<span class="st">'InvoiceDate'</span>])</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># last date in feature set</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>current_date <span class="op">=</span> feature_transaction_cat[<span class="st">'InvoiceDate'</span>].<span class="bu">max</span>()</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co">#rfm</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>customer_features <span class="op">=</span> feature_transaction_cat.groupby(<span class="st">'CustomerID'</span>).agg({</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'InvoiceDate'</span>: [</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'recency'</span>, <span class="kw">lambda</span> x: (current_date <span class="op">-</span> x.<span class="bu">max</span>()).days),</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'first_purchase_date'</span>, <span class="st">'min'</span>),</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'purchase_day'</span>, <span class="st">'nunique'</span>),</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'InvoiceNo'</span>: [(<span class="st">'nb_invoice'</span>, <span class="st">'nunique'</span>)],</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Sales'</span>: [</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'total_sales'</span>, <span class="st">'sum'</span>)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'StockCode'</span>: [(<span class="st">'nb_product'</span>, <span class="st">'nunique'</span>)],</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'category'</span>: [(<span class="st">'nb_category'</span>, <span class="st">'nunique'</span>)]</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten column names</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>customer_features.columns <span class="op">=</span> [</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'CustomerID'</span>,</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recency'</span>,</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'first_purchase_date'</span>,</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">'purchase_day'</span>,</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nb_invoice'</span>,</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_sales'</span>,</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nb_product'</span>,</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nb_category'</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-38" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#almost always one purchase a day</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>(customer_features.purchase_day<span class="op">==</span>customer_features.nb_invoice).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>0.977021524141943</code></pre>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>customer_features[<span class="st">'customer_lifetime'</span>] <span class="op">=</span> (current_date <span class="op">-</span> customer_features[<span class="st">'first_purchase_date'</span>]).dt.days</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>customer_features[<span class="st">'avg_purchase_frequency'</span>] <span class="op">=</span> customer_features[<span class="st">'customer_lifetime'</span>] <span class="op">/</span> customer_features[<span class="st">'purchase_day'</span>]</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>customer_features[<span class="st">'avg_purchase_value'</span>] <span class="op">=</span> customer_features[<span class="st">'total_sales'</span>] <span class="op">/</span> customer_features[<span class="st">'purchase_day'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="category-preference" class="level3">
<h3 class="anchored" data-anchor-id="category-preference">Category Preference</h3>
<div id="cell-41" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">#category preference</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>category_sales <span class="op">=</span> feature_transaction_cat.pivot_table(</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    values<span class="op">=</span><span class="st">'Sales'</span>, </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">'CustomerID'</span>, </span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span><span class="st">'category'</span>, </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    aggfunc<span class="op">=</span><span class="st">'sum'</span>, </span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    fill_value<span class="op">=</span><span class="dv">0</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>category_sales.columns <span class="op">=</span> [i.lower().replace(<span class="st">' '</span>,<span class="st">'_'</span>) <span class="cf">for</span> i <span class="kw">in</span> category_sales.columns]</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>customer_features <span class="op">=</span> customer_features.merge(category_sales, on<span class="op">=</span><span class="st">'CustomerID'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>total_sales <span class="op">=</span> customer_features[<span class="st">'total_sales'</span>]</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> category_sales.columns:</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    percentage_col <span class="op">=</span> <span class="ss">f'per_</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    customer_features[percentage_col] <span class="op">=</span> customer_features[col] <span class="op">/</span> total_sales</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-42" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#make sure the categories are not too sparse</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>(customer_features.iloc[:,<span class="op">-</span><span class="dv">9</span>:]<span class="op">==</span><span class="dv">0</span>).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>per_fashion_accessories           0.409831
per_home_decor                    0.081734
per_kitchen_and_dining            0.122455
per_others                        0.765561
per_outdoor_and_garden            0.507853
per_personal_care_and_wellness    0.448226
per_seasonal_and_holiday          0.369401
per_stationary_and_gifts          0.305410
per_toys_and_games                0.487202
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="putting-them-all-together" class="level3">
<h3 class="anchored" data-anchor-id="putting-them-all-together">Putting Them All Together</h3>
<div id="cell-44" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> [</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a> <span class="st">'recency'</span>,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a> <span class="st">'purchase_day'</span>,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a> <span class="st">'total_sales'</span>,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a> <span class="st">'nb_product'</span>,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a> <span class="st">'nb_category'</span>,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a> <span class="st">'customer_lifetime'</span>,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a> <span class="st">'avg_purchase_frequency'</span>,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a> <span class="st">'avg_purchase_value'</span>,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_fashion_accessories'</span>,</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_home_decor'</span>,</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_kitchen_and_dining'</span>,</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_others'</span>,</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_outdoor_and_garden'</span>,</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_personal_care_and_wellness'</span>,</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_seasonal_and_holiday'</span>,</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_stationary_and_gifts'</span>,</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a> <span class="st">'per_toys_and_games'</span>]</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>outcome_variable <span class="op">=</span> <span class="st">'TargetSales'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-45" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>customer_features <span class="op">=</span> customer_features[[ <span class="st">'CustomerID'</span>]<span class="op">+</span>selected_features]</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>customer_features.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">recency</th>
<th data-quarto-table-cell-role="th">purchase_day</th>
<th data-quarto-table-cell-role="th">total_sales</th>
<th data-quarto-table-cell-role="th">nb_product</th>
<th data-quarto-table-cell-role="th">nb_category</th>
<th data-quarto-table-cell-role="th">customer_lifetime</th>
<th data-quarto-table-cell-role="th">avg_purchase_frequency</th>
<th data-quarto-table-cell-role="th">avg_purchase_value</th>
<th data-quarto-table-cell-role="th">per_fashion_accessories</th>
<th data-quarto-table-cell-role="th">per_home_decor</th>
<th data-quarto-table-cell-role="th">per_kitchen_and_dining</th>
<th data-quarto-table-cell-role="th">per_others</th>
<th data-quarto-table-cell-role="th">per_outdoor_and_garden</th>
<th data-quarto-table-cell-role="th">per_personal_care_and_wellness</th>
<th data-quarto-table-cell-role="th">per_seasonal_and_holiday</th>
<th data-quarto-table-cell-role="th">per_stationary_and_gifts</th>
<th data-quarto-table-cell-role="th">per_toys_and_games</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12346</td>
<td>255</td>
<td>1</td>
<td>77183.60</td>
<td>1</td>
<td>1</td>
<td>255</td>
<td>255.000000</td>
<td>77183.600000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12347</td>
<td>59</td>
<td>4</td>
<td>2079.07</td>
<td>65</td>
<td>7</td>
<td>247</td>
<td>61.750000</td>
<td>519.767500</td>
<td>0.145834</td>
<td>0.204168</td>
<td>0.294021</td>
<td>0.000000</td>
<td>0.005628</td>
<td>0.147614</td>
<td>0.000000</td>
<td>0.073013</td>
<td>0.129721</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>12348</td>
<td>5</td>
<td>3</td>
<td>904.44</td>
<td>10</td>
<td>4</td>
<td>248</td>
<td>82.666667</td>
<td>301.480000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.132679</td>
<td>0.000000</td>
<td>0.825970</td>
<td>0.018796</td>
<td>0.022555</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12350</td>
<td>239</td>
<td>1</td>
<td>334.40</td>
<td>17</td>
<td>7</td>
<td>239</td>
<td>239.000000</td>
<td>334.400000</td>
<td>0.240431</td>
<td>0.202751</td>
<td>0.116926</td>
<td>0.172548</td>
<td>0.000000</td>
<td>0.118421</td>
<td>0.000000</td>
<td>0.059211</td>
<td>0.089713</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>12352</td>
<td>2</td>
<td>7</td>
<td>2194.31</td>
<td>47</td>
<td>8</td>
<td>226</td>
<td>32.285714</td>
<td>313.472857</td>
<td>0.000000</td>
<td>0.196531</td>
<td>0.246187</td>
<td>0.474090</td>
<td>0.013535</td>
<td>0.016680</td>
<td>0.008066</td>
<td>0.024404</td>
<td>0.020508</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="merge-features-and-outcome" class="level2">
<h2 class="anchored" data-anchor-id="merge-features-and-outcome">Merge Features and Outcome</h2>
<div id="cell-47" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>customer_features.shape, outcome_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>((3438, 18), (3438, 2))</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> outcome_df.merge(customer_features, on<span class="op">=</span><span class="st">'CustomerID'</span>).drop(<span class="st">'CustomerID'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>(3438, 18)</code></pre>
</div>
</div>
<div id="cell-49" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">#correlations</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>df.iloc[:,<span class="dv">1</span>:].corr()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">recency</th>
<th data-quarto-table-cell-role="th">purchase_day</th>
<th data-quarto-table-cell-role="th">total_sales</th>
<th data-quarto-table-cell-role="th">nb_product</th>
<th data-quarto-table-cell-role="th">nb_category</th>
<th data-quarto-table-cell-role="th">customer_lifetime</th>
<th data-quarto-table-cell-role="th">avg_purchase_frequency</th>
<th data-quarto-table-cell-role="th">avg_purchase_value</th>
<th data-quarto-table-cell-role="th">per_fashion_accessories</th>
<th data-quarto-table-cell-role="th">per_home_decor</th>
<th data-quarto-table-cell-role="th">per_kitchen_and_dining</th>
<th data-quarto-table-cell-role="th">per_others</th>
<th data-quarto-table-cell-role="th">per_outdoor_and_garden</th>
<th data-quarto-table-cell-role="th">per_personal_care_and_wellness</th>
<th data-quarto-table-cell-role="th">per_seasonal_and_holiday</th>
<th data-quarto-table-cell-role="th">per_stationary_and_gifts</th>
<th data-quarto-table-cell-role="th">per_toys_and_games</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">recency</td>
<td>1.000000</td>
<td>-0.299308</td>
<td>-0.132344</td>
<td>-0.287415</td>
<td>-0.326772</td>
<td>0.298853</td>
<td>0.893973</td>
<td>0.008823</td>
<td>-0.020861</td>
<td>0.022013</td>
<td>0.057244</td>
<td>-0.016069</td>
<td>0.071268</td>
<td>-0.082792</td>
<td>-0.085681</td>
<td>-0.017813</td>
<td>-0.009686</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">purchase_day</td>
<td>-0.299308</td>
<td>1.000000</td>
<td>0.540253</td>
<td>0.690345</td>
<td>0.304621</td>
<td>0.332109</td>
<td>-0.331543</td>
<td>0.027488</td>
<td>0.030683</td>
<td>0.018684</td>
<td>0.025269</td>
<td>0.004299</td>
<td>-0.019992</td>
<td>-0.035665</td>
<td>-0.020392</td>
<td>-0.045384</td>
<td>-0.028187</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">total_sales</td>
<td>-0.132344</td>
<td>0.540253</td>
<td>1.000000</td>
<td>0.400467</td>
<td>0.137064</td>
<td>0.156018</td>
<td>-0.148762</td>
<td>0.361138</td>
<td>0.016511</td>
<td>-0.013819</td>
<td>0.047834</td>
<td>0.006398</td>
<td>-0.029353</td>
<td>-0.011937</td>
<td>-0.016724</td>
<td>-0.029181</td>
<td>-0.013139</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">nb_product</td>
<td>-0.287415</td>
<td>0.690345</td>
<td>0.400467</td>
<td>1.000000</td>
<td>0.555551</td>
<td>0.265594</td>
<td>-0.294923</td>
<td>0.061039</td>
<td>-0.003137</td>
<td>-0.017516</td>
<td>0.035615</td>
<td>-0.006842</td>
<td>-0.026371</td>
<td>-0.005309</td>
<td>-0.016586</td>
<td>0.026716</td>
<td>-0.010069</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">nb_category</td>
<td>-0.326772</td>
<td>0.304621</td>
<td>0.137064</td>
<td>0.555551</td>
<td>1.000000</td>
<td>0.224232</td>
<td>-0.321596</td>
<td>0.019955</td>
<td>0.004863</td>
<td>-0.138372</td>
<td>-0.039363</td>
<td>0.055555</td>
<td>0.041405</td>
<td>0.075882</td>
<td>0.015498</td>
<td>0.152869</td>
<td>0.111150</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">customer_lifetime</td>
<td>0.298853</td>
<td>0.332109</td>
<td>0.156018</td>
<td>0.265594</td>
<td>0.224232</td>
<td>1.000000</td>
<td>0.358431</td>
<td>0.014933</td>
<td>0.011220</td>
<td>0.066111</td>
<td>0.069175</td>
<td>-0.019971</td>
<td>0.029726</td>
<td>-0.127865</td>
<td>-0.120399</td>
<td>-0.050320</td>
<td>-0.036484</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">avg_purchase_frequency</td>
<td>0.893973</td>
<td>-0.331543</td>
<td>-0.148762</td>
<td>-0.294923</td>
<td>-0.321596</td>
<td>0.358431</td>
<td>1.000000</td>
<td>0.009157</td>
<td>-0.016093</td>
<td>0.027208</td>
<td>0.037053</td>
<td>-0.027413</td>
<td>0.060369</td>
<td>-0.070352</td>
<td>-0.074799</td>
<td>-0.000546</td>
<td>-0.010612</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">avg_purchase_value</td>
<td>0.008823</td>
<td>0.027488</td>
<td>0.361138</td>
<td>0.061039</td>
<td>0.019955</td>
<td>0.014933</td>
<td>0.009157</td>
<td>1.000000</td>
<td>-0.003187</td>
<td>-0.056690</td>
<td>0.076862</td>
<td>0.015427</td>
<td>-0.028884</td>
<td>0.004225</td>
<td>-0.000200</td>
<td>-0.012729</td>
<td>-0.002396</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">per_fashion_accessories</td>
<td>-0.020861</td>
<td>0.030683</td>
<td>0.016511</td>
<td>-0.003137</td>
<td>0.004863</td>
<td>0.011220</td>
<td>-0.016093</td>
<td>-0.003187</td>
<td>1.000000</td>
<td>-0.254015</td>
<td>-0.177775</td>
<td>-0.010436</td>
<td>-0.082834</td>
<td>-0.038493</td>
<td>-0.124719</td>
<td>-0.068166</td>
<td>-0.051486</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">per_home_decor</td>
<td>0.022013</td>
<td>0.018684</td>
<td>-0.013819</td>
<td>-0.017516</td>
<td>-0.138372</td>
<td>0.066111</td>
<td>0.027208</td>
<td>-0.056690</td>
<td>-0.254015</td>
<td>1.000000</td>
<td>-0.481983</td>
<td>-0.155784</td>
<td>-0.080637</td>
<td>-0.158837</td>
<td>-0.165964</td>
<td>-0.262313</td>
<td>-0.245759</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">per_kitchen_and_dining</td>
<td>0.057244</td>
<td>0.025269</td>
<td>0.047834</td>
<td>0.035615</td>
<td>-0.039363</td>
<td>0.069175</td>
<td>0.037053</td>
<td>0.076862</td>
<td>-0.177775</td>
<td>-0.481983</td>
<td>1.000000</td>
<td>-0.013075</td>
<td>-0.144698</td>
<td>-0.117031</td>
<td>-0.204235</td>
<td>-0.173386</td>
<td>-0.143931</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">per_others</td>
<td>-0.016069</td>
<td>0.004299</td>
<td>0.006398</td>
<td>-0.006842</td>
<td>0.055555</td>
<td>-0.019971</td>
<td>-0.027413</td>
<td>0.015427</td>
<td>-0.010436</td>
<td>-0.155784</td>
<td>-0.013075</td>
<td>1.000000</td>
<td>-0.062652</td>
<td>0.014794</td>
<td>-0.047940</td>
<td>-0.033975</td>
<td>-0.040421</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">per_outdoor_and_garden</td>
<td>0.071268</td>
<td>-0.019992</td>
<td>-0.029353</td>
<td>-0.026371</td>
<td>0.041405</td>
<td>0.029726</td>
<td>0.060369</td>
<td>-0.028884</td>
<td>-0.082834</td>
<td>-0.080637</td>
<td>-0.144698</td>
<td>-0.062652</td>
<td>1.000000</td>
<td>-0.045639</td>
<td>-0.077947</td>
<td>-0.057297</td>
<td>-0.001034</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">per_personal_care_and_wellness</td>
<td>-0.082792</td>
<td>-0.035665</td>
<td>-0.011937</td>
<td>-0.005309</td>
<td>0.075882</td>
<td>-0.127865</td>
<td>-0.070352</td>
<td>0.004225</td>
<td>-0.038493</td>
<td>-0.158837</td>
<td>-0.117031</td>
<td>0.014794</td>
<td>-0.045639</td>
<td>1.000000</td>
<td>-0.057926</td>
<td>-0.025871</td>
<td>-0.017022</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">per_seasonal_and_holiday</td>
<td>-0.085681</td>
<td>-0.020392</td>
<td>-0.016724</td>
<td>-0.016586</td>
<td>0.015498</td>
<td>-0.120399</td>
<td>-0.074799</td>
<td>-0.000200</td>
<td>-0.124719</td>
<td>-0.165964</td>
<td>-0.204235</td>
<td>-0.047940</td>
<td>-0.077947</td>
<td>-0.057926</td>
<td>1.000000</td>
<td>-0.019418</td>
<td>-0.042970</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">per_stationary_and_gifts</td>
<td>-0.017813</td>
<td>-0.045384</td>
<td>-0.029181</td>
<td>0.026716</td>
<td>0.152869</td>
<td>-0.050320</td>
<td>-0.000546</td>
<td>-0.012729</td>
<td>-0.068166</td>
<td>-0.262313</td>
<td>-0.173386</td>
<td>-0.033975</td>
<td>-0.057297</td>
<td>-0.025871</td>
<td>-0.019418</td>
<td>1.000000</td>
<td>0.172039</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">per_toys_and_games</td>
<td>-0.009686</td>
<td>-0.028187</td>
<td>-0.013139</td>
<td>-0.010069</td>
<td>0.111150</td>
<td>-0.036484</td>
<td>-0.010612</td>
<td>-0.002396</td>
<td>-0.051486</td>
<td>-0.245759</td>
<td>-0.143931</td>
<td>-0.040421</td>
<td>-0.001034</td>
<td>-0.017022</td>
<td>-0.042970</td>
<td>0.172039</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-50" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">#target and most predictive variable</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>df[df.TargetSales<span class="op">&lt;=</span><span class="dv">25_000</span>].plot.scatter(x<span class="op">=</span><span class="st">'TargetSales'</span>,y<span class="op">=</span><span class="st">'total_sales'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sales_prediction_files/figure-html/cell-34-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-test-splits" class="level2">
<h2 class="anchored" data-anchor-id="train-test-splits">Train-Test Splits</h2>
<p>We randomly split the dataset into train and test sets at 80/20 ratio. We also confirm the distribution of <code>TargetSales</code> is similar across percentiles and only different at the upper end.</p>
<div id="cell-53" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">#split into train-valid sets</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>train_df, test_df <span class="op">=</span> train_test_split(df,</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>                                      test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>                                      random_state<span class="op">=</span><span class="dv">112</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-54" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>pd.concat([train_df.TargetSales.describe(percentiles<span class="op">=</span>[i<span class="op">/</span><span class="dv">10</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]).reset_index(),</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>test_df.TargetSales.describe(percentiles<span class="op">=</span>[i<span class="op">/</span><span class="dv">10</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]).reset_index(),], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">index</th>
<th data-quarto-table-cell-role="th">TargetSales</th>
<th data-quarto-table-cell-role="th">index</th>
<th data-quarto-table-cell-role="th">TargetSales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>count</td>
<td>2750.000000</td>
<td>count</td>
<td>688.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>mean</td>
<td>642.650436</td>
<td>mean</td>
<td>760.558808</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>std</td>
<td>4015.305436</td>
<td>std</td>
<td>4024.524400</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>min</td>
<td>0.000000</td>
<td>min</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0%</td>
<td>0.000000</td>
<td>0%</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>10%</td>
<td>0.000000</td>
<td>10%</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>20%</td>
<td>0.000000</td>
<td>20%</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>30%</td>
<td>0.000000</td>
<td>30%</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>40%</td>
<td>0.000000</td>
<td>40%</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>50%</td>
<td>91.350000</td>
<td>50%</td>
<td>113.575000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>60%</td>
<td>260.308000</td>
<td>60%</td>
<td>277.836000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>70%</td>
<td>426.878000</td>
<td>70%</td>
<td>418.187000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>80%</td>
<td>694.164000</td>
<td>80%</td>
<td>759.582000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>90%</td>
<td>1272.997000</td>
<td>90%</td>
<td>1255.670000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>max</td>
<td>168469.600000</td>
<td>max</td>
<td>77099.380000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="baseline-regression" class="level2">
<h2 class="anchored" data-anchor-id="baseline-regression">Baseline Regression</h2>
<p>The most naive solution is to predict <code>TargetSales</code> based on the features. We use a stacked ensemble of LightGBM, CatBoost, XGBoost, Random Forest and Extra Trees via AutoGluon. We train with <code>good_quality</code> preset, stated to be “Stronger than any other AutoML Framework”, for speedy training and inference but feel free to try more performant option. We exclude the neural-network models as they require further preprocessing of the features.</p>
<p>We use an industry-grade, non-parametric model to be as close to a real use case as possible and make a point that our methodology works not only in a toy-dataset setup.</p>
<div id="cell-57" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>preset <span class="op">=</span> <span class="st">'good_quality'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-58" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">'TargetSales'</span>).fit(train_df[selected_features <span class="op">+</span> [<span class="st">'TargetSales'</span>]], </span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>                                                      presets<span class="op">=</span>preset,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>                                                      excluded_model_types<span class="op">=</span>[<span class="st">'NN_TORCH'</span>,<span class="st">'FASTAI'</span>,<span class="st">'KNN'</span>],</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>                                                      )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No path specified. Models will be saved in: "AutogluonModels/ag-20241126_101003"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.9.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024
CPU Count:          64
Memory Avail:       470.86 GB / 480.23 GB (98.0%)
Disk Space Avail:   1541.48 GB / 1968.52 GB (78.3%)
===================================================
Presets specified: ['good_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.
    You can avoid this risk by setting `save_bag_folds=True`.
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
    Running DyStack for up to 900s of the 3600s of remaining time (25%).
2024-11-26 10:10:03,806 INFO util.py:154 -- Outdated packages:
  ipywidgets==7.6.5 found, needs ipywidgets&gt;=8
Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.
    Running DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.
2024-11-26 10:10:06,936 INFO worker.py:1743 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265 
        Context path: "AutogluonModels/ag-20241126_101003/ds_sub_fit/sub_fit_ho"
(_dystack pid=83268) Running DyStack sub-fit ...
(_dystack pid=83268) Beginning AutoGluon training ... Time limit = 896s
(_dystack pid=83268) AutoGluon will save models to "AutogluonModels/ag-20241126_101003/ds_sub_fit/sub_fit_ho"
(_dystack pid=83268) Train Data Rows:    2444
(_dystack pid=83268) Train Data Columns: 17
(_dystack pid=83268) Label Column:       TargetSales
(_dystack pid=83268) Problem Type:       regression
(_dystack pid=83268) Preprocessing data ...
(_dystack pid=83268) Using Feature Generators to preprocess the data ...
(_dystack pid=83268) Fitting AutoMLPipelineFeatureGenerator...
(_dystack pid=83268)    Available Memory:                    481311.53 MB
(_dystack pid=83268)    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)
(_dystack pid=83268)    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
(_dystack pid=83268)    Stage 1 Generators:
(_dystack pid=83268)        Fitting AsTypeFeatureGenerator...
(_dystack pid=83268)    Stage 2 Generators:
(_dystack pid=83268)        Fitting FillNaFeatureGenerator...
(_dystack pid=83268)    Stage 3 Generators:
(_dystack pid=83268)        Fitting IdentityFeatureGenerator...
(_dystack pid=83268)    Stage 4 Generators:
(_dystack pid=83268)        Fitting DropUniqueFeatureGenerator...
(_dystack pid=83268)    Stage 5 Generators:
(_dystack pid=83268)        Fitting DropDuplicatesFeatureGenerator...
(_dystack pid=83268)    Types of features in original data (raw dtype, special dtypes):
(_dystack pid=83268)        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
(_dystack pid=83268)        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
(_dystack pid=83268)    Types of features in processed data (raw dtype, special dtypes):
(_dystack pid=83268)        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
(_dystack pid=83268)        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
(_dystack pid=83268)    0.0s = Fit runtime
(_dystack pid=83268)    17 features in original data used to generate 17 features in processed data.
(_dystack pid=83268)    Train Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)
(_dystack pid=83268) Data preprocessing and feature engineering runtime = 0.05s ...
(_dystack pid=83268) AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'
(_dystack pid=83268)    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
(_dystack pid=83268)    To change this, specify the eval_metric parameter of Predictor()
(_dystack pid=83268) User-specified model hyperparameters to be fit:
(_dystack pid=83268) {
(_dystack pid=83268)    'NN_TORCH': {},
(_dystack pid=83268)    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
(_dystack pid=83268)    'CAT': {},
(_dystack pid=83268)    'XGB': {},
(_dystack pid=83268)    'FASTAI': {},
(_dystack pid=83268)    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
(_dystack pid=83268)    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
(_dystack pid=83268) }
(_dystack pid=83268) AutoGluon will fit 2 stack levels (L1 to L2) ...
(_dystack pid=83268) Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
(_dystack pid=83268) Fitting 7 L1 models ...
(_dystack pid=83268) Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 596.87s of the 895.53s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3990.4801   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    1.93s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: LightGBM_BAG_L1 ... Training model for up to 592.65s of the 891.31s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3921.7042   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    2.22s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 588.21s of the 886.87s of remaining time.
(_dystack pid=83268)    -4516.1791   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.96s    = Training   runtime
(_dystack pid=83268)    0.18s    = Validation runtime
(_dystack pid=83268) Fitting model: CatBoost_BAG_L1 ... Training model for up to 586.98s of the 885.63s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3857.3111   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    3.16s    = Training   runtime
(_dystack pid=83268)    0.03s    = Validation runtime
(_dystack pid=83268) Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 581.54s of the 880.2s of remaining time.
(_dystack pid=83268)    -3900.3038   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.82s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting model: XGBoost_BAG_L1 ... Training model for up to 580.49s of the 879.15s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3941.3599   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    1.94s    = Training   runtime
(_dystack pid=83268)    0.03s    = Validation runtime
(_dystack pid=83268) Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 576.34s of the 875.0s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3912.54     = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    3.68s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 869.04s of remaining time.
(_dystack pid=83268)    Ensemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}
(_dystack pid=83268)    -3835.4224   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.02s    = Training   runtime
(_dystack pid=83268)    0.0s     = Validation runtime
(_dystack pid=83268) Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
(_dystack pid=83268) Fitting 7 L2 models ...
(_dystack pid=83268) Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 868.99s of the 868.99s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3941.7891   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    1.85s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: LightGBM_BAG_L2 ... Training model for up to 864.91s of the 864.91s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>(_ray_fit pid=93902) [1000] valid_set's rmse: 4314.99</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>(_dystack pid=83268)    -3894.7078   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    2.77s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 859.86s of the 859.85s of remaining time.
(_dystack pid=83268)    -4525.2057   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.97s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting model: CatBoost_BAG_L2 ... Training model for up to 858.63s of the 858.62s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3904.7749   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    2.19s    = Training   runtime
(_dystack pid=83268)    0.03s    = Validation runtime
(_dystack pid=83268) Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 854.22s of the 854.21s of remaining time.
(_dystack pid=83268)    -3952.2022   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.82s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting model: XGBoost_BAG_L2 ... Training model for up to 853.14s of the 853.13s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3929.2019   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    3.11s    = Training   runtime
(_dystack pid=83268)    0.04s    = Validation runtime
(_dystack pid=83268) Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 847.75s of the 847.74s of remaining time.
(_dystack pid=83268)    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
(_dystack pid=83268)    -3912.6409   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    4.46s    = Training   runtime
(_dystack pid=83268)    0.02s    = Validation runtime
(_dystack pid=83268) Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 841.06s of remaining time.
(_dystack pid=83268)    Ensemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}
(_dystack pid=83268)    -3823.1639   = Validation score   (-root_mean_squared_error)
(_dystack pid=83268)    0.03s    = Training   runtime
(_dystack pid=83268)    0.0s     = Validation runtime
(_dystack pid=83268) AutoGluon training complete, total runtime = 54.61s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1766.1 rows/s (306 batch size)
(_dystack pid=83268) Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
(_dystack pid=83268) Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
(_dystack pid=83268)    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
(_dystack pid=83268)    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
(_dystack pid=83268)    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
(_dystack pid=83268) Fitting 1 L1 models ...
(_dystack pid=83268) Fitting model: LightGBMXT_BAG_L1_FULL ...
(_dystack pid=83268)    1.17s    = Training   runtime
(_dystack pid=83268) Fitting 1 L1 models ...
(_dystack pid=83268) Fitting model: LightGBM_BAG_L1_FULL ...
(_dystack pid=83268)    0.19s    = Training   runtime
(_dystack pid=83268) Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    0.96s    = Training   runtime
(_dystack pid=83268)    0.18s    = Validation runtime
(_dystack pid=83268) Fitting 1 L1 models ...
(_dystack pid=83268) Fitting model: CatBoost_BAG_L1_FULL ...
(_dystack pid=83268)    0.99s    = Training   runtime
(_dystack pid=83268) Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    0.82s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting 1 L1 models ...
(_dystack pid=83268) Fitting model: XGBoost_BAG_L1_FULL ...
(_dystack pid=83268)    0.18s    = Training   runtime
(_dystack pid=83268) Fitting 1 L1 models ...
(_dystack pid=83268) Fitting model: LightGBMLarge_BAG_L1_FULL ...
(_dystack pid=83268)    0.33s    = Training   runtime
(_dystack pid=83268) Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    Ensemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}
(_dystack pid=83268)    0.02s    = Training   runtime
(_dystack pid=83268) Fitting 1 L2 models ...
(_dystack pid=83268) Fitting model: LightGBMXT_BAG_L2_FULL ...
(_dystack pid=83268)    0.21s    = Training   runtime
(_dystack pid=83268) Fitting 1 L2 models ...
(_dystack pid=83268) Fitting model: LightGBM_BAG_L2_FULL ...
(_dystack pid=83268)    0.31s    = Training   runtime
(_dystack pid=83268) Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    0.97s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting 1 L2 models ...
(_dystack pid=83268) Fitting model: CatBoost_BAG_L2_FULL ...
(_dystack pid=83268)    0.17s    = Training   runtime
(_dystack pid=83268) Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    0.82s    = Training   runtime
(_dystack pid=83268)    0.17s    = Validation runtime
(_dystack pid=83268) Fitting 1 L2 models ...
(_dystack pid=83268) Fitting model: XGBoost_BAG_L2_FULL ...
(_dystack pid=83268)    0.22s    = Training   runtime
(_dystack pid=83268) Fitting 1 L2 models ...
(_dystack pid=83268) Fitting model: LightGBMLarge_BAG_L2_FULL ...
(_dystack pid=83268)    0.4s     = Training   runtime
(_dystack pid=83268) Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...
(_dystack pid=83268)    Ensemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}
(_dystack pid=83268)    0.03s    = Training   runtime
(_dystack pid=83268) Updated best model to "WeightedEnsemble_L3_FULL" (Previously "WeightedEnsemble_L3"). AutoGluon will default to using "WeightedEnsemble_L3_FULL" for predict() and predict_proba().
(_dystack pid=83268) Refit complete, total runtime = 4.84s ... Best model: "WeightedEnsemble_L3_FULL"
(_dystack pid=83268) TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101003/ds_sub_fit/sub_fit_ho")
(_dystack pid=83268) Deleting DyStack predictor artifacts (clean_up_fits=True) ...
Leaderboard on holdout data (DyStack):
                          model  score_holdout    score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0          CatBoost_BAG_L1_FULL    -803.899801 -3857.311112  root_mean_squared_error        0.004578            NaN  0.994905                 0.004578                     NaN           0.994905            1       True          4
1      WeightedEnsemble_L2_FULL    -813.259482 -3835.422447  root_mean_squared_error        0.130354            NaN  2.022119                 0.002616                     NaN           0.018397            2       True          8
2          CatBoost_BAG_L2_FULL    -838.233626 -3904.774934  root_mean_squared_error        0.272134            NaN  4.816257                 0.005706                     NaN           0.166114            2       True         12
3   RandomForestMSE_BAG_L1_FULL    -847.825565 -4516.179095  root_mean_squared_error        0.121127       0.175681  0.964108                 0.121127                0.175681           0.964108            1       True          3
4     ExtraTreesMSE_BAG_L2_FULL    -890.912998 -3952.202176  root_mean_squared_error        0.389130            NaN  5.466693                 0.122702                0.169496           0.816550            2       True         13
5     ExtraTreesMSE_BAG_L1_FULL    -922.896541 -3900.303809  root_mean_squared_error        0.120866       0.170631  0.819227                 0.120866                0.170631           0.819227            1       True          5
6      WeightedEnsemble_L3_FULL    -977.887954 -3823.163850  root_mean_squared_error        0.274239            NaN  4.992532                 0.003509                     NaN           0.028692            3       True         16
7          LightGBM_BAG_L1_FULL   -1086.123687 -3921.704247  root_mean_squared_error        0.002294            NaN  0.189590                 0.002294                     NaN           0.189590            1       True          2
8   RandomForestMSE_BAG_L2_FULL   -1090.066132 -4525.205744  root_mean_squared_error        0.383968            NaN  5.621844                 0.117540                0.169827           0.971701            2       True         11
9        LightGBMXT_BAG_L1_FULL   -1230.340360 -3990.480139  root_mean_squared_error        0.003167            NaN  1.170255                 0.003167                     NaN           1.170255            1       True          1
10       LightGBMXT_BAG_L2_FULL   -1234.815155 -3941.789134  root_mean_squared_error        0.269577            NaN  4.864584                 0.003149                     NaN           0.214441            2       True          9
11    LightGBMLarge_BAG_L1_FULL   -1345.024278 -3912.540001  root_mean_squared_error        0.004652            NaN  0.334220                 0.004652                     NaN           0.334220            1       True          7
12    LightGBMLarge_BAG_L2_FULL   -1640.347524 -3912.640942  root_mean_squared_error        0.273687            NaN  5.046485                 0.007259                     NaN           0.396342            2       True         15
13         LightGBM_BAG_L2_FULL   -1743.255667 -3894.707823  root_mean_squared_error        0.270730            NaN  4.963841                 0.004302                     NaN           0.313698            2       True         10
14          XGBoost_BAG_L1_FULL   -2245.433966 -3941.359884  root_mean_squared_error        0.009745            NaN  0.177837                 0.009745                     NaN           0.177837            1       True          6
15          XGBoost_BAG_L2_FULL   -2454.083373 -3929.201875  root_mean_squared_error        0.278816            NaN  4.869000                 0.012388                     NaN           0.218857            2       True         14
    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)
    67s  = DyStack   runtime |  3533s    = Remaining runtime
Starting main fit with num_stack_levels=0.
    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`
Beginning AutoGluon training ... Time limit = 3533s
AutoGluon will save models to "AutogluonModels/ag-20241126_101003"
Train Data Rows:    2750
Train Data Columns: 17
Label Column:       TargetSales
Problem Type:       regression
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
    Available Memory:                    481140.60 MB
    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)
    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
    Stage 1 Generators:
        Fitting AsTypeFeatureGenerator...
    Stage 2 Generators:
        Fitting FillNaFeatureGenerator...
    Stage 3 Generators:
        Fitting IdentityFeatureGenerator...
    Stage 4 Generators:
        Fitting DropUniqueFeatureGenerator...
    Stage 5 Generators:
        Fitting DropDuplicatesFeatureGenerator...
    Types of features in original data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    Types of features in processed data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    0.0s = Fit runtime
    17 features in original data used to generate 17 features in processed data.
    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.07s ...
AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'
    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
    To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
    'NN_TORCH': {},
    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
    'CAT': {},
    'XGB': {},
    'FASTAI': {},
    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
}
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 7 L1 models ...
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3532.88s of the 3532.87s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -3713.1197   = Validation score   (-root_mean_squared_error)
    4.46s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 3526.09s of the 3526.09s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -3635.1505   = Validation score   (-root_mean_squared_error)
    3.79s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3520.01s of the 3520.01s of remaining time.
    -4135.0334   = Validation score   (-root_mean_squared_error)
    0.86s    = Training   runtime
    0.18s    = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 3518.9s of the 3518.9s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -3669.0125   = Validation score   (-root_mean_squared_error)
    12.43s   = Training   runtime
    0.03s    = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3504.11s of the 3504.11s of remaining time.
    -3678.3921   = Validation score   (-root_mean_squared_error)
    0.9s     = Training   runtime
    0.18s    = Validation runtime
Fitting model: XGBoost_BAG_L1 ... Training model for up to 3502.97s of the 3502.97s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -3785.5048   = Validation score   (-root_mean_squared_error)
    2.1s     = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3498.6s of the 3498.6s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -3704.5742   = Validation score   (-root_mean_squared_error)
    3.22s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3493.14s of remaining time.
    Ensemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}
    -3608.5561   = Validation score   (-root_mean_squared_error)
    0.02s    = Training   runtime
    0.0s     = Validation runtime
AutoGluon training complete, total runtime = 39.85s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4595.8 rows/s (344 batch size)
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBMXT_BAG_L1_FULL ...
    1.45s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1_FULL ...
    0.44s    = Training   runtime
Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.86s    = Training   runtime
    0.18s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: CatBoost_BAG_L1_FULL ...
    0.89s    = Training   runtime
Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.9s     = Training   runtime
    0.18s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: XGBoost_BAG_L1_FULL ...
    0.54s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBMLarge_BAG_L1_FULL ...
    0.41s    = Training   runtime
Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}
    0.02s    = Training   runtime
Updated best model to "WeightedEnsemble_L2_FULL" (Previously "WeightedEnsemble_L2"). AutoGluon will default to using "WeightedEnsemble_L2_FULL" for predict() and predict_proba().
Refit complete, total runtime = 4.11s ... Best model: "WeightedEnsemble_L2_FULL"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101003")</code></pre>
</div>
</div>
<div id="cell-59" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_baseline'</span>] <span class="op">=</span> predictor.predict(test_df[selected_features])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-60" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>metric_baseline <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_baseline'</span>])</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>metric_baseline[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'baseline'</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>metric_baseline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>{'root_mean_squared_error': 3162.478744240967,
 'mean_squared_error': 10001271.807775924,
 'mean_absolute_error': 715.6442657130541,
 'r2': 0.3816166296854987,
 'pearsonr': 0.6190719671013133,
 'spearmanr': 0.47008461549340863,
 'median_absolute_error': 232.98208312988282,
 'earths_mover_distance': 287.77728784026124,
 'model': 'baseline'}</code></pre>
</div>
</div>
</section>
<section id="regression-on-winsorized-outcome" class="level2">
<h2 class="anchored" data-anchor-id="regression-on-winsorized-outcome">Regression on Winsorized Outcome</h2>
<p>One possible approach to deal with long/fat-tailed outcome is to train on a winsorized outcome. This may lead to better performance when tested on a winsorized outcome but not so much on original outcome.</p>
<div id="cell-63" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>outlier_per <span class="op">=</span> <span class="fl">0.99</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>outlier_cap_train <span class="op">=</span> train_df[<span class="st">'TargetSales'</span>].quantile(outlier_per)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>outlier_cap_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>7180.805199999947</code></pre>
</div>
</div>
<div id="cell-64" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co">#winsorize</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">'TargetSales_win'</span>] <span class="op">=</span> train_df[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x: outlier_cap_train <span class="cf">if</span> x<span class="op">&gt;</span> outlier_cap_train <span class="cf">else</span> x)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'TargetSales_win'</span>] <span class="op">=</span> test_df[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x: outlier_cap_train <span class="cf">if</span> x<span class="op">&gt;</span> outlier_cap_train <span class="cf">else</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-65" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">'TargetSales_win'</span>).fit(train_df[selected_features<span class="op">+</span>[<span class="st">'TargetSales_win'</span>]],</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>                                                      presets<span class="op">=</span>preset,</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                                                      excluded_model_types<span class="op">=</span>[<span class="st">'NN_TORCH'</span>,<span class="st">'FASTAI'</span>,<span class="st">'KNN'</span>],</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>                                                      )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No path specified. Models will be saved in: "AutogluonModels/ag-20241126_101154"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.9.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024
CPU Count:          64
Memory Avail:       469.75 GB / 480.23 GB (97.8%)
Disk Space Avail:   1541.40 GB / 1968.52 GB (78.3%)
===================================================
Presets specified: ['good_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.
    You can avoid this risk by setting `save_bag_folds=True`.
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
    Running DyStack for up to 900s of the 3600s of remaining time (25%).
        Context path: "AutogluonModels/ag-20241126_101154/ds_sub_fit/sub_fit_ho"
Leaderboard on holdout data (DyStack):
                          model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0           XGBoost_BAG_L2_FULL    -673.227470 -706.566643  root_mean_squared_error        0.290126            NaN  5.287011                 0.017494                     NaN           0.256777            2       True         14
1          CatBoost_BAG_L2_FULL    -685.276375 -679.668006  root_mean_squared_error        0.278921            NaN  5.648248                 0.006289                     NaN           0.618015            2       True         12
2     ExtraTreesMSE_BAG_L2_FULL    -686.432329 -688.280166  root_mean_squared_error        0.390370            NaN  5.851508                 0.117738                0.175184           0.821275            2       True         13
3      WeightedEnsemble_L2_FULL    -687.292057 -677.748155  root_mean_squared_error        0.147735            NaN  3.111673                 0.004223                     NaN           0.018202            2       True          8
4          CatBoost_BAG_L1_FULL    -688.830702 -682.216238  root_mean_squared_error        0.010066            NaN  0.742727                 0.010066                     NaN           0.742727            1       True          4
5   RandomForestMSE_BAG_L2_FULL    -690.155342 -702.819447  root_mean_squared_error        0.382087            NaN  6.004801                 0.109455                0.173669           0.974567            2       True         11
6     LightGBMLarge_BAG_L2_FULL    -699.457560 -701.790157  root_mean_squared_error        0.282755            NaN  5.677221                 0.010123                     NaN           0.646987            2       True         15
7      WeightedEnsemble_L3_FULL    -699.646914 -664.915201  root_mean_squared_error        0.300374            NaN  6.563785                 0.003960                     NaN           0.028939            3       True         16
8   RandomForestMSE_BAG_L1_FULL    -700.107179 -708.557877  root_mean_squared_error        0.118200       0.179320  0.993047                 0.118200                0.179320           0.993047            1       True          3
9     ExtraTreesMSE_BAG_L1_FULL    -701.853556 -688.997247  root_mean_squared_error        0.115165       0.170742  0.812660                 0.115165                0.170742           0.812660            1       True          5
10          XGBoost_BAG_L1_FULL    -717.776000 -710.501170  root_mean_squared_error        0.014938            NaN  0.129418                 0.014938                     NaN           0.129418            1       True          6
11       LightGBMXT_BAG_L2_FULL    -723.560168 -701.334719  root_mean_squared_error        0.277760            NaN  5.320158                 0.005128                     NaN           0.289924            2       True          9
12         LightGBM_BAG_L1_FULL    -726.112842 -700.802863  root_mean_squared_error        0.002237            NaN  0.163236                 0.002237                     NaN           0.163236            1       True          2
13         LightGBM_BAG_L2_FULL    -728.829307 -669.578190  root_mean_squared_error        0.296413            NaN  6.534846                 0.023781                     NaN           1.504612            2       True         10
14       LightGBMXT_BAG_L1_FULL    -733.594747 -704.073534  root_mean_squared_error        0.003345            NaN  1.408667                 0.003345                     NaN           1.408667            1       True          1
15    LightGBMLarge_BAG_L1_FULL    -766.964045 -715.782974  root_mean_squared_error        0.008682            NaN  0.780480                 0.008682                     NaN           0.780480            1       True          7
    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)
    82s  = DyStack   runtime |  3518s    = Remaining runtime
Starting main fit with num_stack_levels=0.
    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`
Beginning AutoGluon training ... Time limit = 3518s
AutoGluon will save models to "AutogluonModels/ag-20241126_101154"
Train Data Rows:    2750
Train Data Columns: 17
Label Column:       TargetSales_win
Problem Type:       regression
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
    Available Memory:                    480645.68 MB
    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)
    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
    Stage 1 Generators:
        Fitting AsTypeFeatureGenerator...
    Stage 2 Generators:
        Fitting FillNaFeatureGenerator...
    Stage 3 Generators:
        Fitting IdentityFeatureGenerator...
    Stage 4 Generators:
        Fitting DropUniqueFeatureGenerator...
    Stage 5 Generators:
        Fitting DropDuplicatesFeatureGenerator...
    Types of features in original data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    Types of features in processed data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    0.0s = Fit runtime
    17 features in original data used to generate 17 features in processed data.
    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.06s ...
AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'
    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
    To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
    'NN_TORCH': {},
    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
    'CAT': {},
    'XGB': {},
    'FASTAI': {},
    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
}
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 7 L1 models ...
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3517.72s of the 3517.71s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -710.5609    = Validation score   (-root_mean_squared_error)
    1.99s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 3513.48s of the 3513.48s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -696.6213    = Validation score   (-root_mean_squared_error)
    2.06s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3509.13s of the 3509.13s of remaining time.
    -706.2702    = Validation score   (-root_mean_squared_error)
    0.84s    = Training   runtime
    0.18s    = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 3508.04s of the 3508.04s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -668.1395    = Validation score   (-root_mean_squared_error)
    3.84s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3501.92s of the 3501.92s of remaining time.
    -688.8913    = Validation score   (-root_mean_squared_error)
    0.63s    = Training   runtime
    0.18s    = Validation runtime
Fitting model: XGBoost_BAG_L1 ... Training model for up to 3501.01s of the 3501.0s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -699.3326    = Validation score   (-root_mean_squared_error)
    2.06s    = Training   runtime
    0.04s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3496.71s of the 3496.71s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -714.8496    = Validation score   (-root_mean_squared_error)
    3.48s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3490.98s of remaining time.
    Ensemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}
    -667.3394    = Validation score   (-root_mean_squared_error)
    0.02s    = Training   runtime
    0.0s     = Validation runtime
AutoGluon training complete, total runtime = 26.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3852.1 rows/s (344 batch size)
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBMXT_BAG_L1_FULL ...
    0.46s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1_FULL ...
    0.44s    = Training   runtime
Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.84s    = Training   runtime
    0.18s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: CatBoost_BAG_L1_FULL ...
    0.4s     = Training   runtime
Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.63s    = Training   runtime
    0.18s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: XGBoost_BAG_L1_FULL ...
    0.12s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBMLarge_BAG_L1_FULL ...
    0.77s    = Training   runtime
Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}
    0.02s    = Training   runtime
Updated best model to "WeightedEnsemble_L2_FULL" (Previously "WeightedEnsemble_L2"). AutoGluon will default to using "WeightedEnsemble_L2_FULL" for predict() and predict_proba().
Refit complete, total runtime = 2.53s ... Best model: "WeightedEnsemble_L2_FULL"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101154")</code></pre>
</div>
</div>
<div id="cell-66" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_winsorized'</span>] <span class="op">=</span> predictor.predict(test_df[selected_features])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-67" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>metric_winsorized <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_winsorized'</span>])</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>metric_winsorized[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'winsorized'</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>metric_winsorized</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>{'root_mean_squared_error': 3623.576377551195,
 'mean_squared_error': 13130305.76394704,
 'mean_absolute_error': 627.7880071099414,
 'r2': 0.18814697894155963,
 'pearsonr': 0.5757989413256978,
 'spearmanr': 0.504301956183441,
 'median_absolute_error': 219.62248107910156,
 'earths_mover_distance': 432.1288432991232,
 'model': 'winsorized'}</code></pre>
</div>
</div>
<div id="cell-68" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>calculate_regression_metrics(test_df[<span class="st">'TargetSales_win'</span>], test_df[<span class="st">'pred_winsorized'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>{'root_mean_squared_error': 673.4846433338375,
 'mean_squared_error': 453581.5648065064,
 'mean_absolute_error': 376.77603327273135,
 'r2': 0.6171771763549553,
 'pearsonr': 0.7865724180212539,
 'spearmanr': 0.504299950810919,
 'median_absolute_error': 218.8311004638672,
 'earths_mover_distance': 181.1168694619127}</code></pre>
</div>
</div>
</section>
<section id="log1p-regression" class="level2">
<h2 class="anchored" data-anchor-id="log1p-regression">Log1p Regression</h2>
<p>Log transformation handles long/fat-tailed distribution and is especially useful for certain models since the transformed distribution is roughly normal. However, it cannot handle zero-valued outcome and oftentimes scientists end up adding 1 to the outcome (so often that <code>numpy</code> even has a function for it). This not only introduces bias to the prediction, but also does not solve the zero-inflation as it becomes one-inflation instead.</p>
<div id="cell-71" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#log</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">'TargetSales_log1p'</span>] <span class="op">=</span> train_df[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(np.log1p)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'TargetSales_log1p'</span>] <span class="op">=</span> test_df[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(np.log1p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-72" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co">#from zero-inflated to one-inflated</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">'TargetSales_log1p'</span>].hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sales_prediction_files/figure-html/cell-48-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-73" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">'TargetSales_log1p'</span>).fit(train_df[selected_features<span class="op">+</span>[<span class="st">'TargetSales_log1p'</span>]],</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>                                                      presets<span class="op">=</span>preset,</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>                                                      excluded_model_types<span class="op">=</span>[<span class="st">'NN_TORCH'</span>,<span class="st">'FASTAI'</span>,<span class="st">'KNN'</span>],</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>                                                      )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No path specified. Models will be saved in: "AutogluonModels/ag-20241126_101346"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.9.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024
CPU Count:          64
Memory Avail:       469.47 GB / 480.23 GB (97.8%)
Disk Space Avail:   1541.30 GB / 1968.52 GB (78.3%)
===================================================
Presets specified: ['good_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.
    You can avoid this risk by setting `save_bag_folds=True`.
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
    Running DyStack for up to 900s of the 3600s of remaining time (25%).
        Context path: "AutogluonModels/ag-20241126_101346/ds_sub_fit/sub_fit_ho"
Leaderboard on holdout data (DyStack):
                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0          CatBoost_BAG_L1_FULL      -2.885523  -2.780750  root_mean_squared_error        0.020686            NaN   0.650833                 0.020686                     NaN           0.650833            1       True          4
1      WeightedEnsemble_L2_FULL      -2.894191  -2.775644  root_mean_squared_error        0.160296            NaN   2.819383                 0.003478                     NaN           0.018452            2       True          8
2   RandomForestMSE_BAG_L2_FULL      -2.894937  -2.808770  root_mean_squared_error        0.435059            NaN   5.443468                 0.124940                0.183134           1.003239            2       True         11
3     ExtraTreesMSE_BAG_L2_FULL      -2.896741  -2.777983  root_mean_squared_error        0.435080            NaN   5.274917                 0.124961                0.172770           0.834688            2       True         13
4        LightGBMXT_BAG_L1_FULL      -2.908863  -2.782297  root_mean_squared_error        0.003337            NaN   1.298610                 0.003337                     NaN           1.298610            1       True          1
5          CatBoost_BAG_L2_FULL      -2.922107  -2.759026  root_mean_squared_error        0.320235            NaN   7.354950                 0.010116                     NaN           2.914721            2       True         12
6          LightGBM_BAG_L2_FULL      -2.931031  -2.759814  root_mean_squared_error        0.325009            NaN   5.217557                 0.014890                     NaN           0.777328            2       True         10
7           XGBoost_BAG_L2_FULL      -2.938193  -2.790059  root_mean_squared_error        0.328456            NaN   4.597451                 0.018338                     NaN           0.157222            2       True         14
8      WeightedEnsemble_L3_FULL      -2.942265  -2.685363  root_mean_squared_error        0.497056            NaN  14.318665                 0.005495                     NaN           0.029343            3       True         16
9     ExtraTreesMSE_BAG_L1_FULL      -2.946022  -2.815757  root_mean_squared_error        0.132796       0.178658   0.851489                 0.132796                0.178658           0.851489            1       True          5
10         LightGBM_BAG_L1_FULL      -2.953480  -2.813496  root_mean_squared_error        0.002430            NaN   0.165181                 0.002430                     NaN           0.165181            1       True          2
11          XGBoost_BAG_L1_FULL      -2.972277  -2.836214  root_mean_squared_error        0.016762            NaN   0.133264                 0.016762                     NaN           0.133264            1       True          6
12    LightGBMLarge_BAG_L2_FULL      -2.977587  -2.794323  root_mean_squared_error        0.356780            NaN   8.470437                 0.046662                     NaN           4.030208            2       True         15
13  RandomForestMSE_BAG_L1_FULL      -2.985264  -2.831375  root_mean_squared_error        0.127529       0.180724   0.979892                 0.127529                0.180724           0.979892            1       True          3
14       LightGBMXT_BAG_L2_FULL      -2.995407  -2.694352  root_mean_squared_error        0.411671            NaN   9.324565                 0.101552                     NaN           4.884336            2       True          9
15    LightGBMLarge_BAG_L1_FULL      -3.050660  -2.862792  root_mean_squared_error        0.006579            NaN   0.360961                 0.006579                     NaN           0.360961            1       True          7
    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)
    173s     = DyStack   runtime |  3427s    = Remaining runtime
Starting main fit with num_stack_levels=0.
    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`
Beginning AutoGluon training ... Time limit = 3427s
AutoGluon will save models to "AutogluonModels/ag-20241126_101346"
Train Data Rows:    2750
Train Data Columns: 17
Label Column:       TargetSales_log1p
Problem Type:       regression
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
    Available Memory:                    480330.83 MB
    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)
    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
    Stage 1 Generators:
        Fitting AsTypeFeatureGenerator...
    Stage 2 Generators:
        Fitting FillNaFeatureGenerator...
    Stage 3 Generators:
        Fitting IdentityFeatureGenerator...
    Stage 4 Generators:
        Fitting DropUniqueFeatureGenerator...
    Stage 5 Generators:
        Fitting DropDuplicatesFeatureGenerator...
    Types of features in original data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    Types of features in processed data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    0.0s = Fit runtime
    17 features in original data used to generate 17 features in processed data.
    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.06s ...
AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'
    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
    To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
    'NN_TORCH': {},
    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
    'CAT': {},
    'XGB': {},
    'FASTAI': {},
    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
}
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 7 L1 models ...
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3427.2s of the 3427.2s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -2.7861  = Validation score   (-root_mean_squared_error)
    1.97s    = Training   runtime
    0.01s    = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 3423.0s of the 3422.99s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -2.8189  = Validation score   (-root_mean_squared_error)
    1.81s    = Training   runtime
    0.01s    = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3418.91s of the 3418.91s of remaining time.
    -2.8468  = Validation score   (-root_mean_squared_error)
    0.82s    = Training   runtime
    0.18s    = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 3417.81s of the 3417.81s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -2.7963  = Validation score   (-root_mean_squared_error)
    1.79s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3413.76s of the 3413.76s of remaining time.
    -2.8191  = Validation score   (-root_mean_squared_error)
    0.65s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: XGBoost_BAG_L1 ... Training model for up to 3412.83s of the 3412.83s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -2.8365  = Validation score   (-root_mean_squared_error)
    1.77s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3408.81s of the 3408.81s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -2.8667  = Validation score   (-root_mean_squared_error)
    3.51s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3403.0s of remaining time.
    Ensemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}
    -2.7845  = Validation score   (-root_mean_squared_error)
    0.02s    = Training   runtime
    0.0s     = Validation runtime
AutoGluon training complete, total runtime = 24.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5481.1 rows/s (344 batch size)
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBMXT_BAG_L1_FULL ...
    0.35s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1_FULL ...
    0.34s    = Training   runtime
Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.82s    = Training   runtime
    0.18s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: CatBoost_BAG_L1_FULL ...
    0.18s    = Training   runtime
Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.65s    = Training   runtime
    0.19s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: XGBoost_BAG_L1_FULL ...
    0.1s     = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBMLarge_BAG_L1_FULL ...
    0.56s    = Training   runtime
Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}
    0.02s    = Training   runtime
Updated best model to "WeightedEnsemble_L2_FULL" (Previously "WeightedEnsemble_L2"). AutoGluon will default to using "WeightedEnsemble_L2_FULL" for predict() and predict_proba().
Refit complete, total runtime = 1.94s ... Best model: "WeightedEnsemble_L2_FULL"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101346")</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_log1p'</span>] <span class="op">=</span> predictor.predict(test_df[selected_features])</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_log1p_expm1'</span>] <span class="op">=</span> test_df[<span class="st">'pred_log1p'</span>].<span class="bu">map</span>(np.expm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-75" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>metric_log1p <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_log1p_expm1'</span>])</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>metric_log1p[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'log1p'</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>metric_log1p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>{'root_mean_squared_error': 3725.342295894091,
 'mean_squared_error': 13878175.221577456,
 'mean_absolute_error': 618.9768466651894,
 'r2': 0.14190585634701047,
 'pearsonr': 0.5817166874396966,
 'spearmanr': 0.5338156315937898,
 'median_absolute_error': 89.55495441784018,
 'earths_mover_distance': 581.0494444960044,
 'model': 'log1p'}</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>calculate_regression_metrics(test_df[<span class="st">'TargetSales_log1p'</span>], test_df[<span class="st">'pred_log1p'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>{'root_mean_squared_error': 2.720047847858299,
 'mean_squared_error': 7.398660294638562,
 'mean_absolute_error': 2.418601533469381,
 'r2': 0.30252750020590236,
 'pearsonr': 0.5507740732825224,
 'spearmanr': 0.5338156315937898,
 'median_absolute_error': 2.349368453025818,
 'earths_mover_distance': 1.8552344547363062}</code></pre>
</div>
</div>
</section>
<section id="hurdle-model" class="level2">
<h2 class="anchored" data-anchor-id="hurdle-model">Hurdle Model</h2>
<p>Hurdle model is a two-stage approach that handles zero inflation by first having a classification model to predict if the outcome is zero or not, then a regression model, trained only on examples with actual non-zero outcomes, to fit a log-transformed outcome. When retransforming the predictions from log to non-log numbers, we perform correction of underestimation using Duan’s method. During inference time, we multiply the predictions from the classification and regression model.</p>
<section id="binary-classification" class="level3">
<h3 class="anchored" data-anchor-id="binary-classification">Binary Classification</h3>
<div id="cell-80" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">'has_purchase'</span>] <span class="op">=</span> train_df.TargetSales.<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">&gt;</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'has_purchase'</span>] <span class="op">=</span> test_df.TargetSales.<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">&gt;</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-81" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">'has_purchase'</span>].mean(), test_df[<span class="st">'has_purchase'</span>].mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>(0.5141818181818182, 0.5305232558139535)</code></pre>
</div>
</div>
<div id="cell-82" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>predictor_cls <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">'has_purchase'</span>).fit(train_df[selected_features<span class="op">+</span>[<span class="st">'has_purchase'</span>]],</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>                                                      presets<span class="op">=</span>preset,</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>                                                      excluded_model_types<span class="op">=</span>[<span class="st">'NN_TORCH'</span>,<span class="st">'FASTAI'</span>,<span class="st">'KNN'</span>],</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>                                                      )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No path specified. Models will be saved in: "AutogluonModels/ag-20241126_101706"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.9.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024
CPU Count:          64
Memory Avail:       469.22 GB / 480.23 GB (97.7%)
Disk Space Avail:   1541.17 GB / 1968.52 GB (78.3%)
===================================================
Presets specified: ['good_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.
    You can avoid this risk by setting `save_bag_folds=True`.
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
    Running DyStack for up to 900s of the 3600s of remaining time (25%).
        Context path: "AutogluonModels/ag-20241126_101706/ds_sub_fit/sub_fit_ho"
Leaderboard on holdout data (DyStack):
                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0           LightGBM_BAG_L1_FULL       0.699346   0.686989    accuracy        0.002175            NaN  0.108046                 0.002175                     NaN           0.108046            1       True          2
1           CatBoost_BAG_L1_FULL       0.699346   0.698036    accuracy        0.003567            NaN  0.608703                 0.003567                     NaN           0.608703            1       True          5
2       WeightedEnsemble_L2_FULL       0.699346   0.698036    accuracy        0.005767            NaN  0.782679                 0.002200                     NaN           0.173977            2       True         10
3     ExtraTreesEntr_BAG_L1_FULL       0.692810   0.675123    accuracy        0.122157       0.179918  1.000016                 0.122157                0.179918           1.000016            1       True          7
4         LightGBMXT_BAG_L2_FULL       0.692810   0.701718    accuracy        0.547326            NaN  7.217974                 0.004018                     NaN           0.180956            2       True         11
5           CatBoost_BAG_L2_FULL       0.692810   0.707447    accuracy        0.549285            NaN  7.561007                 0.005977                     NaN           0.523989            2       True         15
6       WeightedEnsemble_L3_FULL       0.692810   0.707856    accuracy        0.551327            NaN  7.873676                 0.002042                     NaN           0.312670            3       True         20
7     ExtraTreesGini_BAG_L1_FULL       0.689542   0.673077    accuracy        0.129358       0.181783  1.053820                 0.129358                0.181783           1.053820            1       True          6
8   RandomForestEntr_BAG_L1_FULL       0.683007   0.654255    accuracy        0.117779       0.174219  1.047733                 0.117779                0.174219           1.047733            1       True          4
9     ExtraTreesGini_BAG_L2_FULL       0.679739   0.684534    accuracy        0.663375            NaN  8.053752                 0.120067                0.179437           1.016734            2       True         16
10  RandomForestGini_BAG_L2_FULL       0.679739   0.684943    accuracy        0.678078            NaN  8.181539                 0.134771                0.179112           1.144521            2       True         13
11          LightGBM_BAG_L2_FULL       0.676471   0.706219    accuracy        0.547352            NaN  7.223828                 0.004044                     NaN           0.186810            2       True         12
12    ExtraTreesEntr_BAG_L2_FULL       0.676471   0.679624    accuracy        0.672358            NaN  8.049679                 0.129050                0.180169           1.012661            2       True         17
13           XGBoost_BAG_L1_FULL       0.673203   0.687398    accuracy        0.015491            NaN  0.139807                 0.015491                     NaN           0.139807            1       True          8
14           XGBoost_BAG_L2_FULL       0.673203   0.702946    accuracy        0.555419            NaN  7.180053                 0.012111                     NaN           0.143035            2       True         18
15  RandomForestEntr_BAG_L2_FULL       0.673203   0.684534    accuracy        0.659769            NaN  8.097150                 0.116461                0.173954           1.060132            2       True         14
16        LightGBMXT_BAG_L1_FULL       0.666667   0.694354    accuracy        0.003664            NaN  1.090716                 0.003664                     NaN           1.090716            1       True          1
17     LightGBMLarge_BAG_L1_FULL       0.663399   0.673895    accuracy        0.009468            NaN  0.803435                 0.009468                     NaN           0.803435            1       True          9
18  RandomForestGini_BAG_L1_FULL       0.660131   0.666121    accuracy        0.139650       0.181133  1.184743                 0.139650                0.181133           1.184743            1       True          3
19     LightGBMLarge_BAG_L2_FULL       0.656863   0.704992    accuracy        0.551465            NaN  7.941736                 0.008157                     NaN           0.904718            2       True         19
    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)
    69s  = DyStack   runtime |  3531s    = Remaining runtime
Starting main fit with num_stack_levels=0.
    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`
Beginning AutoGluon training ... Time limit = 3531s
AutoGluon will save models to "AutogluonModels/ag-20241126_101706"
Train Data Rows:    2750
Train Data Columns: 17
Label Column:       has_purchase
Problem Type:       binary
Preprocessing data ...
Selected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
    Available Memory:                    480097.88 MB
    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)
    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
    Stage 1 Generators:
        Fitting AsTypeFeatureGenerator...
    Stage 2 Generators:
        Fitting FillNaFeatureGenerator...
    Stage 3 Generators:
        Fitting IdentityFeatureGenerator...
    Stage 4 Generators:
        Fitting DropUniqueFeatureGenerator...
    Stage 5 Generators:
        Fitting DropDuplicatesFeatureGenerator...
    Types of features in original data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    Types of features in processed data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    0.0s = Fit runtime
    17 features in original data used to generate 17 features in processed data.
    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.06s ...
AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'
    To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
    'NN_TORCH': {},
    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
    'CAT': {},
    'XGB': {},
    'FASTAI': {},
    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
}
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 9 L1 models ...
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3530.48s of the 3530.47s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    0.6964   = Validation score   (accuracy)
    1.94s    = Training   runtime
    0.01s    = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 3526.32s of the 3526.31s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    0.6884   = Validation score   (accuracy)
    2.1s     = Training   runtime
    0.02s    = Validation runtime
Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3521.91s of the 3521.91s of remaining time.
    0.6615   = Validation score   (accuracy)
    0.91s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3520.72s of the 3520.72s of remaining time.
    0.6644   = Validation score   (accuracy)
    0.95s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 3519.49s of the 3519.49s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    0.6935   = Validation score   (accuracy)
    1.93s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3515.32s of the 3515.32s of remaining time.
    0.6738   = Validation score   (accuracy)
    0.96s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3514.06s of the 3514.05s of remaining time.
    0.6716   = Validation score   (accuracy)
    0.85s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: XGBoost_BAG_L1 ... Training model for up to 3512.95s of the 3512.94s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    0.6789   = Validation score   (accuracy)
    1.85s    = Training   runtime
    0.04s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3508.82s of the 3508.82s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    0.6738   = Validation score   (accuracy)
    5.08s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3501.48s of remaining time.
    Ensemble Weights: {'LightGBMXT_BAG_L1': 1.0}
    0.6964   = Validation score   (accuracy)
    0.18s    = Training   runtime
    0.0s     = Validation runtime
AutoGluon training complete, total runtime = 29.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 26150.7 rows/s (344 batch size)
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBMXT_BAG_L1_FULL ...
    0.33s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1_FULL ...
    0.35s    = Training   runtime
Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.91s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.95s    = Training   runtime
    0.19s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: CatBoost_BAG_L1_FULL ...
    0.1s     = Training   runtime
Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.96s    = Training   runtime
    0.19s    = Validation runtime
Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.85s    = Training   runtime
    0.19s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: XGBoost_BAG_L1_FULL ...
    0.12s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBMLarge_BAG_L1_FULL ...
    1.07s    = Training   runtime
Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'LightGBMXT_BAG_L1': 1.0}
    0.18s    = Training   runtime
Updated best model to "LightGBMXT_BAG_L1_FULL" (Previously "WeightedEnsemble_L2"). AutoGluon will default to using "LightGBMXT_BAG_L1_FULL" for predict() and predict_proba().
Refit complete, total runtime = 2.44s ... Best model: "LightGBMXT_BAG_L1_FULL"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101706")</code></pre>
</div>
</div>
<div id="cell-83" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_binary'</span>] <span class="op">=</span> predictor_cls.predict(test_df[selected_features])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-84" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>caluclate_classification_metrics(test_df[<span class="st">'has_purchase'</span>], test_df[<span class="st">'pred_binary'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>{'accuracy': 0.6918604651162791,
 'precision': 0.6941069004479309,
 'recall': 0.6918604651162791,
 'f1_score': 0.6921418829824787,
 'confusion_matrix': array([[229,  94],
        [118, 247]])}</code></pre>
</div>
</div>
</section>
<section id="regression-on-non-zero-outcome" class="level3">
<h3 class="anchored" data-anchor-id="regression-on-non-zero-outcome">Regression on Non-Zero Outcome</h3>
<div id="cell-86" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>train_df_nonzero <span class="op">=</span> train_df[train_df.has_purchase<span class="op">==</span><span class="dv">1</span>].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>test_df_nonzero <span class="op">=</span> test_df[test_df.has_purchase<span class="op">==</span><span class="dv">1</span>].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>train_df_nonzero.shape, test_df_nonzero.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>((1414, 21), (365, 26))</code></pre>
</div>
</div>
<div id="cell-87" class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co">#log</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>train_df_nonzero[<span class="st">'TargetSales_log'</span>] <span class="op">=</span> train_df_nonzero[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(np.log)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>test_df_nonzero[<span class="st">'TargetSales_log'</span>] <span class="op">=</span> test_df_nonzero[<span class="st">'TargetSales'</span>].<span class="bu">map</span>(np.log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-88" class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>train_df_nonzero[<span class="st">'TargetSales_log'</span>].hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sales_prediction_files/figure-html/cell-60-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-89" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>predictor_reg <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">'TargetSales_log'</span>).fit(train_df_nonzero[selected_features<span class="op">+</span>[<span class="st">'TargetSales_log'</span>]],</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>                                                      presets<span class="op">=</span>preset,</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>                                                      excluded_model_types<span class="op">=</span>[<span class="st">'NN_TORCH'</span>,<span class="st">'FASTAI'</span>,<span class="st">'KNN'</span>],</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>                                                      )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No path specified. Models will be saved in: "AutogluonModels/ag-20241126_101847"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.9.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024
CPU Count:          64
Memory Avail:       468.57 GB / 480.23 GB (97.6%)
Disk Space Avail:   1541.01 GB / 1968.52 GB (78.3%)
===================================================
Presets specified: ['good_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.
    You can avoid this risk by setting `save_bag_folds=True`.
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
    Running DyStack for up to 900s of the 3600s of remaining time (25%).
        Context path: "AutogluonModels/ag-20241126_101847/ds_sub_fit/sub_fit_ho"
Leaderboard on holdout data (DyStack):
                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0     ExtraTreesMSE_BAG_L1_FULL      -0.839346  -0.781522  root_mean_squared_error        0.123006       0.141352  0.799363                 0.123006                0.141352           0.799363            1       True          5
1     ExtraTreesMSE_BAG_L2_FULL      -0.853589  -0.787303  root_mean_squared_error        0.436013            NaN  8.134050                 0.129594                0.145573           0.830991            2       True         13
2      WeightedEnsemble_L3_FULL      -0.857556  -0.768871  root_mean_squared_error        0.332279            NaN  8.055929                 0.005146                     NaN           0.027863            3       True         16
3   RandomForestMSE_BAG_L1_FULL      -0.861175  -0.804629  root_mean_squared_error        0.119744       0.147896  0.923559                 0.119744                0.147896           0.923559            1       True          3
4      WeightedEnsemble_L2_FULL      -0.862117  -0.769820  root_mean_squared_error        0.150238            NaN  2.038445                 0.004235                     NaN           0.016720            2       True          8
5        LightGBMXT_BAG_L1_FULL      -0.864283  -0.782882  root_mean_squared_error        0.002448            NaN  1.338318                 0.002448                     NaN           1.338318            1       True          1
6          CatBoost_BAG_L2_FULL      -0.866735  -0.782409  root_mean_squared_error        0.313627            NaN  7.518480                 0.007208                     NaN           0.215421            2       True         12
7   RandomForestMSE_BAG_L2_FULL      -0.867588  -0.801697  root_mean_squared_error        0.425690            NaN  8.229896                 0.119271                0.143491           0.926836            2       True         11
8        LightGBMXT_BAG_L2_FULL      -0.867632  -0.795484  root_mean_squared_error        0.310434            NaN  7.486937                 0.004015                     NaN           0.183877            2       True          9
9           XGBoost_BAG_L2_FULL      -0.867990  -0.801243  root_mean_squared_error        0.319756            NaN  7.634992                 0.013337                     NaN           0.331932            2       True         14
10         LightGBM_BAG_L2_FULL      -0.869884  -0.797155  root_mean_squared_error        0.313795            NaN  7.696134                 0.007376                     NaN           0.393075            2       True         10
11         LightGBM_BAG_L1_FULL      -0.872511  -0.786431  root_mean_squared_error        0.001964            NaN  0.186059                 0.001964                     NaN           0.186059            1       True          2
12         CatBoost_BAG_L1_FULL      -0.876613  -0.774745  root_mean_squared_error        0.006662            NaN  0.856986                 0.006662                     NaN           0.856986            1       True          4
13          XGBoost_BAG_L1_FULL      -0.908105  -0.786510  root_mean_squared_error        0.014371            NaN  0.179318                 0.014371                     NaN           0.179318            1       True          6
14    LightGBMLarge_BAG_L2_FULL      -0.929002  -0.811482  root_mean_squared_error        0.315722            NaN  7.913350                 0.009303                     NaN           0.610290            2       True         15
15    LightGBMLarge_BAG_L1_FULL      -0.943116  -0.811385  root_mean_squared_error        0.038224            NaN  3.019457                 0.038224                     NaN           3.019457            1       True          7
    1    = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)
    89s  = DyStack   runtime |  3511s    = Remaining runtime
Starting main fit with num_stack_levels=1.
    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`
Beginning AutoGluon training ... Time limit = 3511s
AutoGluon will save models to "AutogluonModels/ag-20241126_101847"
Train Data Rows:    1414
Train Data Columns: 17
Label Column:       TargetSales_log
Problem Type:       regression
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
    Available Memory:                    479435.26 MB
    Train Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)
    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
    Stage 1 Generators:
        Fitting AsTypeFeatureGenerator...
    Stage 2 Generators:
        Fitting FillNaFeatureGenerator...
    Stage 3 Generators:
        Fitting IdentityFeatureGenerator...
    Stage 4 Generators:
        Fitting DropUniqueFeatureGenerator...
    Stage 5 Generators:
        Fitting DropDuplicatesFeatureGenerator...
    Types of features in original data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    Types of features in processed data (raw dtype, special dtypes):
        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]
        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']
    0.0s = Fit runtime
    17 features in original data used to generate 17 features in processed data.
    Train Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.05s ...
AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'
    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
    To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
    'NN_TORCH': {},
    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
    'CAT': {},
    'XGB': {},
    'FASTAI': {},
    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
}
AutoGluon will fit 2 stack levels (L1 to L2) ...
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 7 L1 models ...
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2339.93s of the 3510.77s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.7909  = Validation score   (-root_mean_squared_error)
    1.87s    = Training   runtime
    0.01s    = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 2335.79s of the 3506.63s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.7919  = Validation score   (-root_mean_squared_error)
    1.94s    = Training   runtime
    0.01s    = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 2331.57s of the 3502.41s of remaining time.
    -0.8074  = Validation score   (-root_mean_squared_error)
    0.77s    = Training   runtime
    0.15s    = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 2330.53s of the 3501.37s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.783   = Validation score   (-root_mean_squared_error)
    1.93s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2326.32s of the 3497.16s of remaining time.
    -0.7902  = Validation score   (-root_mean_squared_error)
    0.62s    = Training   runtime
    0.15s    = Validation runtime
Fitting model: XGBoost_BAG_L1 ... Training model for up to 2325.45s of the 3496.29s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.8026  = Validation score   (-root_mean_squared_error)
    1.72s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2321.49s of the 3492.33s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.8166  = Validation score   (-root_mean_squared_error)
    3.35s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3486.65s of remaining time.
    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}
    -0.78    = Validation score   (-root_mean_squared_error)
    0.02s    = Training   runtime
    0.0s     = Validation runtime
Excluded models: ['FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)
Fitting 7 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3486.56s of the 3486.55s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.7869  = Validation score   (-root_mean_squared_error)
    3.2s     = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 3481.11s of the 3481.1s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.7932  = Validation score   (-root_mean_squared_error)
    2.25s    = Training   runtime
    0.02s    = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 3476.56s of the 3476.55s of remaining time.
    -0.8097  = Validation score   (-root_mean_squared_error)
    0.71s    = Training   runtime
    0.15s    = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 3475.61s of the 3475.6s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.7847  = Validation score   (-root_mean_squared_error)
    5.45s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 3467.92s of the 3467.91s of remaining time.
    -0.795   = Validation score   (-root_mean_squared_error)
    0.62s    = Training   runtime
    0.15s    = Validation runtime
Fitting model: XGBoost_BAG_L2 ... Training model for up to 3467.07s of the 3467.06s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.8102  = Validation score   (-root_mean_squared_error)
    2.17s    = Training   runtime
    0.03s    = Validation runtime
Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3462.61s of the 3462.6s of remaining time.
    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.00%)
    -0.8107  = Validation score   (-root_mean_squared_error)
    11.18s   = Training   runtime
    0.05s    = Validation runtime
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3449.17s of remaining time.
    Ensemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}
    -0.7746  = Validation score   (-root_mean_squared_error)
    0.03s    = Training   runtime
    0.0s     = Validation runtime
AutoGluon training complete, total runtime = 61.72s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 754.0 rows/s (177 batch size)
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
    Models trained in this way will have the suffix "_FULL" and have NaN validation score.
    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
    To learn more, refer to the `.refit_full` method docstring which explains how "_FULL" models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBMXT_BAG_L1_FULL ...
    0.35s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1_FULL ...
    0.35s    = Training   runtime
Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.77s    = Training   runtime
    0.15s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: CatBoost_BAG_L1_FULL ...
    0.29s    = Training   runtime
Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...
    0.62s    = Training   runtime
    0.15s    = Validation runtime
Fitting 1 L1 models ...
Fitting model: XGBoost_BAG_L1_FULL ...
    0.09s    = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBMLarge_BAG_L1_FULL ...
    0.63s    = Training   runtime
Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}
    0.02s    = Training   runtime
Fitting 1 L2 models ...
Fitting model: LightGBMXT_BAG_L2_FULL ...
    0.7s     = Training   runtime
Fitting 1 L2 models ...
Fitting model: LightGBM_BAG_L2_FULL ...
    0.43s    = Training   runtime
Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...
    0.71s    = Training   runtime
    0.15s    = Validation runtime
Fitting 1 L2 models ...
Fitting model: CatBoost_BAG_L2_FULL ...
    0.39s    = Training   runtime
Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...
    0.62s    = Training   runtime
    0.15s    = Validation runtime
Fitting 1 L2 models ...
Fitting model: XGBoost_BAG_L2_FULL ...
    0.19s    = Training   runtime
Fitting 1 L2 models ...
Fitting model: LightGBMLarge_BAG_L2_FULL ...
    2.56s    = Training   runtime
Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...
    Ensemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}
    0.03s    = Training   runtime
Updated best model to "WeightedEnsemble_L3_FULL" (Previously "WeightedEnsemble_L3"). AutoGluon will default to using "WeightedEnsemble_L3_FULL" for predict() and predict_proba().
Refit complete, total runtime = 6.78s ... Best model: "WeightedEnsemble_L3_FULL"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20241126_101847")</code></pre>
</div>
</div>
<div id="cell-90" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>test_df_nonzero[<span class="st">'pred_log'</span>] <span class="op">=</span> predictor_reg.predict(test_df_nonzero[selected_features])</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>test_df_nonzero[<span class="st">'pred_log_exp'</span>] <span class="op">=</span> test_df_nonzero[<span class="st">'pred_log'</span>].<span class="bu">map</span>(np.exp)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_log'</span>] <span class="op">=</span> predictor_reg.predict(test_df[selected_features])</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_log_exp'</span>] <span class="op">=</span> test_df[<span class="st">'pred_log'</span>].<span class="bu">map</span>(np.exp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-91" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>calculate_regression_metrics(test_df_nonzero[<span class="st">'TargetSales'</span>], test_df_nonzero[<span class="st">'pred_log_exp'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>{'root_mean_squared_error': 4330.443144695726,
 'mean_squared_error': 18752737.82944221,
 'mean_absolute_error': 880.0418223064565,
 'r2': 0.3647576298877435,
 'pearsonr': 0.6756393928483335,
 'spearmanr': 0.5762190201444638,
 'median_absolute_error': 243.0658528752748,
 'earths_mover_distance': 546.7166312173882}</code></pre>
</div>
</div>
<div id="cell-92" class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_hurdle'</span>] <span class="op">=</span> test_df.pred_binary <span class="op">*</span> test_df.pred_log_exp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-93" class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>metric_hurdle <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_hurdle'</span>])</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>metric_hurdle[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'hurdle'</span></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>metric_hurdle</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>{'root_mean_squared_error': 3171.760744960863,
 'mean_squared_error': 10060066.22327469,
 'mean_absolute_error': 584.9162934881963,
 'r2': 0.3779813431428882,
 'pearsonr': 0.6769697889999318,
 'spearmanr': 0.5107083593715698,
 'median_absolute_error': 199.1780137692856,
 'earths_mover_distance': 286.381442541919,
 'model': 'hurdle'}</code></pre>
</div>
</div>
</section>
<section id="duans-method" class="level3">
<h3 class="anchored" data-anchor-id="duans-method"><a href="https://www.jstor.org/stable/2288126">Duan’s Method</a></h3>
<p>When predicting a log-transformed outcome, we typically want to re-transform the predictions to non-log numbers by applying the exponential function. However, this ignores a small bias due to the error term in the process.</p>
<p><span class="math display">\[ln(y) = f(X) + \epsilon\]</span></p>
<p>where * <span class="math inline">\(y\)</span> is actual outcome. * <span class="math inline">\(X\)</span> is the features. * <span class="math inline">\(f(.)\)</span> is a trained model. * <span class="math inline">\(\epsilon\)</span> is the error term.</p>
<p>when re-transforming <span class="math display">\[
\begin{align}
y &amp;= exp(ln(y)) \\
&amp;= exp(f(X) + \epsilon ) \\
&amp;= exp(f(X)) \cdot exp(\epsilon) \\
E[y] &amp;= E[exp(f(X))] \cdot E[exp(\epsilon)]
\end{align}
\]</span></p>
<p>Duan estimates the E[<span class="math inline">\(exp(\epsilon)\)</span>] as <span class="math display">\[
\begin{align}
\hat \lambda &amp;= E[exp(ln(y) - ln(\hat y))]
\end{align}
\]</span></p>
<p>where * <span class="math inline">\(\hat \lambda\)</span> is the Duan’s smearing estimator of the bias from re-transformation <span class="math inline">\(E[exp(\epsilon)]\)</span> * <span class="math inline">\(\hat y\)</span> is the prediction aka <span class="math inline">\(f(X)\)</span></p>
<div id="cell-96" class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>train_df_nonzero[<span class="st">'pred_log'</span>] <span class="op">=</span> predictor_reg.predict(train_df_nonzero[selected_features])</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>train_df_nonzero[<span class="st">'pred_log_exp'</span>] <span class="op">=</span> train_df_nonzero[<span class="st">'pred_log'</span>].<span class="bu">map</span>(np.exp)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>smearing_estimator <span class="op">=</span> np.mean(np.exp(train_df_nonzero[<span class="st">'TargetSales_log'</span>] <span class="op">-</span> train_df_nonzero[<span class="st">'pred_log'</span>]))</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>smearing_estimator</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<pre><code>1.2280991653046711</code></pre>
</div>
</div>
<div id="cell-97" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_log_exp_corrected'</span>] <span class="op">=</span> test_df[<span class="st">'pred_log_exp'</span>] <span class="op">*</span> smearing_estimator</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_hurdle_corrected'</span>] <span class="op">=</span> test_df.pred_binary <span class="op">*</span> test_df.pred_log_exp_corrected</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-98" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>metric_hurdle_corrected <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_hurdle_corrected'</span>])</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>metric_hurdle_corrected[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'hurdle_corrected'</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>metric_hurdle_corrected</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>{'root_mean_squared_error': 3055.3207868281233,
 'mean_squared_error': 9334985.110424023,
 'mean_absolute_error': 613.3946643257099,
 'r2': 0.42281345159207295,
 'pearsonr': 0.6769697889999318,
 'spearmanr': 0.5107083593715698,
 'median_absolute_error': 232.55557358084502,
 'earths_mover_distance': 241.61839859133218,
 'model': 'hurdle_corrected'}</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>We can see that the <code>hurdle_corrected</code> method performs best across all metrics except for 1) mean absolute error where it performs about 5% worse than <code>hurdle</code> method without the correction and 2) median absolute error where it only performs better than baseline regression and 3) Spearman’s rank correlation where it underperforms <code>log1p</code> by 4%; correlations are tied between the two Hurdle methods by definition since we multiply Duan’s smearing estimator to <code>hurdle</code> predictions to get <code>hurdle_corrected</code>.</p>
<div id="cell-101" class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>metric_df <span class="op">=</span> pd.DataFrame([metric_baseline,</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>                       metric_winsorized,</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>                       metric_log1p,</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>                       metric_hurdle,</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>                       metric_hurdle_corrected,])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-102" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>rank_df <span class="op">=</span> metric_df.copy()</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> metric_df.columns.tolist()[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">in</span> [<span class="st">'r2'</span>, <span class="st">'pearsonr'</span>, <span class="st">'spearmanr'</span>]:</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>        rank_df[<span class="ss">f'</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">_rank'</span>] <span class="op">=</span> rank_df[col].rank(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>        rank_df[<span class="ss">f'</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">_rank'</span>] <span class="op">=</span> rank_df[col].rank(ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>rank_df <span class="op">=</span> rank_df.drop(metric_df.columns.tolist()[:<span class="op">-</span><span class="dv">1</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>rank_df[<span class="st">'avg_rank'</span>] <span class="op">=</span> rank_df.iloc[:,<span class="dv">1</span>:].mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>rank_df.transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">model</td>
<td>baseline</td>
<td>winsorized</td>
<td>log1p</td>
<td>hurdle</td>
<td>hurdle_corrected</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">root_mean_squared_error_rank</td>
<td>2.0</td>
<td>4.0</td>
<td>5.0</td>
<td>3.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_squared_error_rank</td>
<td>2.0</td>
<td>4.0</td>
<td>5.0</td>
<td>3.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean_absolute_error_rank</td>
<td>5.0</td>
<td>4.0</td>
<td>3.0</td>
<td>1.0</td>
<td>2.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">r2_rank</td>
<td>2.0</td>
<td>4.0</td>
<td>5.0</td>
<td>3.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">pearsonr_rank</td>
<td>3.0</td>
<td>5.0</td>
<td>4.0</td>
<td>1.5</td>
<td>1.5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">spearmanr_rank</td>
<td>5.0</td>
<td>4.0</td>
<td>1.0</td>
<td>2.5</td>
<td>2.5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">median_absolute_error_rank</td>
<td>5.0</td>
<td>3.0</td>
<td>1.0</td>
<td>2.0</td>
<td>4.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">earths_mover_distance_rank</td>
<td>3.0</td>
<td>4.0</td>
<td>5.0</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">avg_rank</td>
<td>3.375</td>
<td>4.0</td>
<td>3.625</td>
<td>2.25</td>
<td>1.75</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-103" class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>metric_df.transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">root_mean_squared_error</td>
<td>3162.478744</td>
<td>3623.576378</td>
<td>3725.342296</td>
<td>3171.760745</td>
<td>3055.320787</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean_squared_error</td>
<td>10001271.807776</td>
<td>13130305.763947</td>
<td>13878175.221577</td>
<td>10060066.223275</td>
<td>9334985.110424</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_absolute_error</td>
<td>715.644266</td>
<td>627.788007</td>
<td>618.976847</td>
<td>584.916293</td>
<td>613.394664</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">r2</td>
<td>0.381617</td>
<td>0.188147</td>
<td>0.141906</td>
<td>0.377981</td>
<td>0.422813</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">pearsonr</td>
<td>0.619072</td>
<td>0.575799</td>
<td>0.581717</td>
<td>0.67697</td>
<td>0.67697</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">spearmanr</td>
<td>0.470085</td>
<td>0.504302</td>
<td>0.533816</td>
<td>0.510708</td>
<td>0.510708</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">median_absolute_error</td>
<td>232.982083</td>
<td>219.622481</td>
<td>89.554954</td>
<td>199.178014</td>
<td>232.555574</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">earths_mover_distance</td>
<td>287.777288</td>
<td>432.128843</td>
<td>581.049444</td>
<td>286.381443</td>
<td>241.618399</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">model</td>
<td>baseline</td>
<td>winsorized</td>
<td>log1p</td>
<td>hurdle</td>
<td>hurdle_corrected</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="why-hurdle-outperforms-hurdle_corrected-in-mae" class="level3">
<h3 class="anchored" data-anchor-id="why-hurdle-outperforms-hurdle_corrected-in-mae">Why <code>hurdle</code> Outperforms <code>hurdle_corrected</code> in MAE?</h3>
<p>Duan’s method adjusts for underestimation from retransformation of log outcome. This could lead to smaller extreme errors but more less extreme ones. We verify this hypothesis by comparing mean absolute error before and after transformation for errors originally under and over 99th percentile. We confirm that is the case for this problem.</p>
<div id="cell-106" class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>err_hurdle <span class="op">=</span> (test_df[<span class="st">'TargetSales'</span>] <span class="op">-</span> test_df[<span class="st">'pred_hurdle'</span>]).<span class="bu">abs</span>()</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>err_hurdle_corrected <span class="op">=</span> (test_df[<span class="st">'TargetSales'</span>] <span class="op">-</span> test_df[<span class="st">'pred_hurdle_corrected'</span>]).<span class="bu">abs</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-107" class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>err_hurdle.describe(percentiles<span class="op">=</span>[<span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.75</span>, <span class="fl">.9</span>, <span class="fl">.95</span>, <span class="fl">.99</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>count      688.000000
mean       584.916293
std       3119.628924
min          0.000000
25%          0.000000
50%        199.178014
75%        475.603446
90%        862.530026
95%       1237.540954
99%       6763.777844
max      55731.205996
dtype: float64</code></pre>
</div>
</div>
<div id="cell-108" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>err_hurdle[err_hurdle<span class="op">&lt;</span><span class="fl">6763.777844</span>].mean(),<span class="op">\</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>err_hurdle[err_hurdle<span class="op">&gt;</span><span class="fl">6763.777844</span>].mean(),</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>(355.4918014848842, 22904.641872667555)</code></pre>
</div>
</div>
<div id="cell-109" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>err_hurdle_corrected[err_hurdle<span class="op">&lt;</span><span class="fl">6763.777844</span>].mean(),<span class="op">\</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>err_hurdle_corrected[err_hurdle<span class="op">&gt;</span><span class="fl">6763.777844</span>].mean(),</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<pre><code>(392.7718802742851, 22076.839798471465)</code></pre>
</div>
</div>
</section>
<section id="why-log1p-performs-so-much-better-than-others-in-medae" class="level3">
<h3 class="anchored" data-anchor-id="why-log1p-performs-so-much-better-than-others-in-medae">Why <code>log1p</code> Performs So Much Better than Others in MedAE?</h3>
<p>It is for similar reasons that <code>hurdle</code> outperforms <code>hurdle_corrected</code> in MedAE; however, <code>log1p</code> performs twice better than other approaches (it also slightly outperforms <code>hurdle</code> models in Spearman’s rank correlation), especially the Hurdle models which should be modeling the non-zero outcomes in the same manner. This is because Hurdle models depend not only on the regression but the classification model. We can see that if the classification model were perfect (instead of the current f1 = 0.69), other metrics also improved but not nearly as drastic as MedAE and Spearman’s rank correlation.</p>
<div id="cell-112" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'pred_hurdle_corrected_perfect_cls'</span>] <span class="op">=</span> test_df.has_purchase <span class="op">*</span> test_df.pred_log_exp_corrected</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>metric_hurdle_corrected_perfect_cls <span class="op">=</span> calculate_regression_metrics(test_df[<span class="st">'TargetSales'</span>], test_df[<span class="st">'pred_hurdle_corrected_perfect_cls'</span>])</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>metric_hurdle_corrected_perfect_cls[<span class="st">'model'</span>] <span class="op">=</span> <span class="st">'hurdle_corrected_perfect_cls'</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>metric_df2 <span class="op">=</span> pd.DataFrame([metric_baseline,</span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>                       metric_winsorized,</span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a>                       metric_log1p,</span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a>                       metric_hurdle,</span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a>                       metric_hurdle_corrected,</span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a>                       metric_hurdle_corrected_perfect_cls,])</span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a>metric_df2.transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">root_mean_squared_error</td>
<td>3162.478744</td>
<td>3623.576378</td>
<td>3725.342296</td>
<td>3171.760745</td>
<td>3055.320787</td>
<td>3030.854831</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean_squared_error</td>
<td>10001271.807776</td>
<td>13130305.763947</td>
<td>13878175.221577</td>
<td>10060066.223275</td>
<td>9334985.110424</td>
<td>9186081.006625</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_absolute_error</td>
<td>715.644266</td>
<td>627.788007</td>
<td>618.976847</td>
<td>584.916293</td>
<td>613.394664</td>
<td>479.558294</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">r2</td>
<td>0.381617</td>
<td>0.188147</td>
<td>0.141906</td>
<td>0.377981</td>
<td>0.422813</td>
<td>0.43202</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">pearsonr</td>
<td>0.619072</td>
<td>0.575799</td>
<td>0.581717</td>
<td>0.67697</td>
<td>0.67697</td>
<td>0.687639</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">spearmanr</td>
<td>0.470085</td>
<td>0.504302</td>
<td>0.533816</td>
<td>0.510708</td>
<td>0.510708</td>
<td>0.929419</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">median_absolute_error</td>
<td>232.982083</td>
<td>219.622481</td>
<td>89.554954</td>
<td>199.178014</td>
<td>232.555574</td>
<td>34.991964</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">earths_mover_distance</td>
<td>287.777288</td>
<td>432.128843</td>
<td>581.049444</td>
<td>286.381443</td>
<td>241.618399</td>
<td>234.587018</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">model</td>
<td>baseline</td>
<td>winsorized</td>
<td>log1p</td>
<td>hurdle</td>
<td>hurdle_corrected</td>
<td>hurdle_corrected_perfect_cls</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="why-baseline-regression-performs-best-at-aggregate-level" class="level3">
<h3 class="anchored" data-anchor-id="why-baseline-regression-performs-best-at-aggregate-level">Why Baseline Regression Performs Best at Aggregate Level</h3>
<p>If we look at aggregated mean or sum of actual sales vs predicted sales, baseline regression performs best by far. This is due to the fact that without any constraints a regressor only minimizes the MSE loss and usually ends up predicting values around the mean to balance between under- and over-predictions. However, this level of prediction is often not very useful as a single point and more often done by in a time series setup.</p>
<div id="cell-115" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>test_df[[<span class="st">'TargetSales'</span>,<span class="st">'pred_baseline'</span>,<span class="st">'pred_winsorized'</span>,<span class="st">'pred_log1p_expm1'</span>,<span class="st">'pred_hurdle'</span>,<span class="st">'pred_hurdle_corrected'</span>]].mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>TargetSales              760.558808
pred_baseline            791.043945
pred_winsorized          508.281555
pred_log1p_expm1         186.200281
pred_hurdle              527.286811
pred_hurdle_corrected    647.560493
dtype: float64</code></pre>
</div>
</div>
<div id="cell-116" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>test_df[[<span class="st">'TargetSales'</span>,<span class="st">'pred_baseline'</span>,<span class="st">'pred_winsorized'</span>,<span class="st">'pred_log1p_expm1'</span>,<span class="st">'pred_hurdle'</span>,<span class="st">'pred_hurdle_corrected'</span>]].<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="123">
<pre><code>TargetSales              523264.460000
pred_baseline            544238.250000
pred_winsorized          349697.718750
pred_log1p_expm1         128105.793618
pred_hurdle              362773.326124
pred_hurdle_corrected    445521.619008
dtype: float64</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/cstorm125\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>