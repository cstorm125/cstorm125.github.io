{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Zero-inflated and Long/fat-tailed Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details how to predict a real-number outcome that is zero-inflated and long/fat-tailed such as sales prediction in retail. We provide baseline regression, regression trained using winsorized outcome, regression trained on log(y+1) outcome, and hurdle regression with and without Duan's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import boto3\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score, median_absolute_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, wasserstein_distance\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'root_mean_squared_error': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mean_squared_error': mean_squared_error(y_true, y_pred),\n",
    "        'mean_absolute_error': mean_absolute_error(y_true, y_pred),\n",
    "        'r2': r2_score(y_true, y_pred),\n",
    "        'pearsonr': pearsonr(y_true, y_pred)[0],  \n",
    "        'spearmanr': spearmanr(y_true, y_pred)[0],\n",
    "        'median_absolute_error': median_absolute_error(y_true, y_pred),\n",
    "        'earths_mover_distance': wasserstein_distance(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def caluclate_classification_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def string_to_yearmon(date):\n",
    "    date = date.split()\n",
    "    date = date[0].split('/') + date[1].split(':')\n",
    "    date = date[2] + '-' + date[0].zfill(2) #+ '-' + date[1].zfill(2) + ' ' + date[3].zfill(2) + ':' + date[4].zfill(2)\n",
    "    return date\n",
    "\n",
    "def call_llama(system_prompt, input):\n",
    "    template = f\"\"\"<s>[INST] <<SYS>>{system_prompt}<</SYS>>{input}[/INST]\"\"\"\n",
    "    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n",
    "    body = json.dumps({\n",
    "        \"prompt\": template,\n",
    "        \"temperature\": 0.,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_gen_len\": 2048,\n",
    "    })\n",
    "    response = client.invoke_model(\n",
    "        body=body,\n",
    "        modelId='us.meta.llama3-2-90b-instruct-v1:0',\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body\n",
    "\n",
    "def call_claude(system_prompt, input):\n",
    "    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n",
    "    body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 2048,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_prompt + '\\n' + input,\n",
    "                    }\n",
    "                    ]\n",
    "                }\n",
    "                ]\n",
    "        }  \n",
    "    )  \n",
    "\n",
    "    \n",
    "    response = client.invoke_model(body=body, \n",
    "                                   modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
    "                                   contentType='application/json',\n",
    "                                   accept='application/json')\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "   \n",
    "    return response_body\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "class Winsorizer:\n",
    "    def __init__(self, cols, percentile=99):\n",
    "        self.cols = cols  # List of columns to apply winsorization to\n",
    "        self.percentile = percentile  # Percentile to define the outliers\n",
    "        self.lower_bounds = {}  # To store the lower quantiles\n",
    "        self.upper_bounds = {}  # To store the upper quantiles\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit the winsorizer to the data, remembering the quantiles.\"\"\"\n",
    "        for col in self.cols:\n",
    "            lower = df[col].quantile(1 - self.percentile / 100)\n",
    "            upper = df[col].quantile(self.percentile / 100)\n",
    "            self.lower_bounds[col] = lower\n",
    "            self.upper_bounds[col] = upper\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Apply winsorization to a new DataFrame using the learned quantiles.\"\"\"\n",
    "        for col in self.cols:\n",
    "            lower = self.lower_bounds[col]\n",
    "            upper = self.upper_bounds[col]\n",
    "            df[col] = np.clip(df[col], lower, upper)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Fit the model and apply winsorization to the same DataFrame.\"\"\"\n",
    "        self.fit(df)\n",
    "        return self.transform(df)\n",
    "\n",
    "def calculate_vif(df, cols):\n",
    "    X = df[cols]\n",
    "    X_with_const = add_constant(X)  # Add constant for VIF calculation\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['feature'] = X_with_const.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [UCI Online Retail](https://archive.ics.uci.edu/dataset/352/online+retail) dataset, which are transactions from a UK-based, non-store online retail from 2010-12-01 and 2011-12-09. We perform the following data processing:\n",
    "\n",
    "1. Remove transactions without `CustomerID`; from 541,909 to 406,829 transactions\n",
    "2. Filter out transactions where either `UnitPrice` or `Quantity` is less than zero; from 406,829 to 397,884 transactions\n",
    "3. Fill in missing product `Description` with value `UNKNOWN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541909, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_retail = fetch_ucirepo(id=352) \n",
    "transaction_df = online_retail['data']['original']\n",
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406829, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create yearmon for train-valid split\n",
    "transaction_df['yearmon'] = transaction_df.InvoiceDate.map(string_to_yearmon)\n",
    "\n",
    "#get rid of transactions without cid\n",
    "transaction_df = transaction_df[~transaction_df.CustomerID.isna()].reset_index(drop=True)\n",
    "\n",
    "#fill in unknown descriptions\n",
    "transaction_df.Description = transaction_df.Description.fillna('UNKNOWN')\n",
    "\n",
    "#convert customer id to string\n",
    "transaction_df['CustomerID'] = transaction_df['CustomerID'].map(lambda x: str(int(x)))\n",
    "\n",
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo      0.0\n",
       "StockCode      0.0\n",
       "Description    0.0\n",
       "Quantity       0.0\n",
       "InvoiceDate    0.0\n",
       "UnitPrice      0.0\n",
       "CustomerID     0.0\n",
       "Country        0.0\n",
       "yearmon        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if still na\n",
    "transaction_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397884, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simplify by filtering unit price and quantity to be non-zero (get rid of discounts, cancellations, etc)\n",
    "transaction_df = transaction_df[(transaction_df.UnitPrice>0)&\\\n",
    "                                (transaction_df.Quantity>0)].reset_index(drop=True)\n",
    "#add sales\n",
    "transaction_df['Sales'] = transaction_df.UnitPrice * transaction_df.Quantity\n",
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation and Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We formulate the problem as predicting the sales (`TargetSales`) during Q4 2011 for each customers who bought at least one item during Q1-Q3 2011. Note that we are interested in predicting the **actual sales number per customer** as accurately as possible; this is common for marketing use cases such as determining what spend threshold to give each customer in a promotion, targeting customers for upselling, or detecting early signs of churns.\n",
    "\n",
    "We transform the transaction dataset into a customer-level dataset where we calculate features using transactions between 2011-01 to 2011-09 and outcome using transactions between 2011-10 to 2011-12, summing `Quantity` times `UnitPrice`. We left-join the customers in feature set to outcome set. This will result in the zero-inflated nature of the outcome as not all customers will come back in Q4. The distribution of non-zero sales is naturally long/fat-tailed with a few customers having extraordinarily high amount of sales in Q4. This resulted in a customer-level dataset with 3,438 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240338, 10), (131389, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_period = {'start': '2011-01', 'end': '2011-09'}\n",
    "outcome_period = {'start': '2011-10', 'end': '2011-12'}\n",
    "\n",
    "feature_transaction = transaction_df[(transaction_df.yearmon>=feature_period['start'])&\\\n",
    "                                      (transaction_df.yearmon<=feature_period['end'])]\n",
    "outcome_transaction = transaction_df[(transaction_df.yearmon>=outcome_period['start'])&\\\n",
    "                                      (transaction_df.yearmon<=outcome_period['end'])]\n",
    "feature_transaction.shape, outcome_transaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12347</td>\n",
       "      <td>1519.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12349</td>\n",
       "      <td>1757.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12352</td>\n",
       "      <td>311.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12356</td>\n",
       "      <td>58.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12357</td>\n",
       "      <td>6207.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>18276</td>\n",
       "      <td>335.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>18277</td>\n",
       "      <td>110.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>18282</td>\n",
       "      <td>77.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>18283</td>\n",
       "      <td>974.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>18287</td>\n",
       "      <td>1072.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID    Sales\n",
       "0         12347  1519.14\n",
       "1         12349  1757.55\n",
       "2         12352   311.73\n",
       "3         12356    58.35\n",
       "4         12357  6207.67\n",
       "...         ...      ...\n",
       "2555      18276   335.86\n",
       "2556      18277   110.38\n",
       "2557      18282    77.84\n",
       "2558      18283   974.21\n",
       "2559      18287  1072.00\n",
       "\n",
       "[2560 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregate sales during outcome period\n",
    "outcome_sales = outcome_transaction.groupby('CustomerID').Sales.sum().reset_index()\n",
    "outcome_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>77183.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>2079.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348</td>\n",
       "      <td>904.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12350</td>\n",
       "      <td>334.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12352</td>\n",
       "      <td>2194.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>18280</td>\n",
       "      <td>180.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>18281</td>\n",
       "      <td>80.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>18282</td>\n",
       "      <td>100.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>18283</td>\n",
       "      <td>1120.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>18287</td>\n",
       "      <td>765.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3438 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID     Sales\n",
       "0         12346  77183.60\n",
       "1         12347   2079.07\n",
       "2         12348    904.44\n",
       "3         12350    334.40\n",
       "4         12352   2194.31\n",
       "...         ...       ...\n",
       "3433      18280    180.60\n",
       "3434      18281     80.82\n",
       "3435      18282    100.21\n",
       "3436      18283   1120.67\n",
       "3437      18287    765.28\n",
       "\n",
       "[3438 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregate sales during feature period\n",
    "feature_sales = feature_transaction.groupby('CustomerID').Sales.sum().reset_index()\n",
    "feature_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>TargetSales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>1519.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12350</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12352</td>\n",
       "      <td>311.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>18280</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>18281</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>18282</td>\n",
       "      <td>77.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>18283</td>\n",
       "      <td>974.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>18287</td>\n",
       "      <td>1072.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3438 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  TargetSales\n",
       "0         12346         0.00\n",
       "1         12347      1519.14\n",
       "2         12348         0.00\n",
       "3         12350         0.00\n",
       "4         12352       311.73\n",
       "...         ...          ...\n",
       "3433      18280         0.00\n",
       "3434      18281         0.00\n",
       "3435      18282        77.84\n",
       "3436      18283       974.21\n",
       "3437      18287      1072.00\n",
       "\n",
       "[3438 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge to get TargetSales including those who spent during feature period but not during outcome (zeroes)\n",
    "outcome_df = feature_sales[['CustomerID']].merge(outcome_sales, on='CustomerID', how='left')\n",
    "outcome_df['Sales'] = outcome_df['Sales'].fillna(0)\n",
    "outcome_df.columns = ['CustomerID', 'TargetSales']\n",
    "outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3438.000000\n",
       "mean        666.245829\n",
       "std        4016.843037\n",
       "min           0.000000\n",
       "0%            0.000000\n",
       "10%           0.000000\n",
       "20%           0.000000\n",
       "30%           0.000000\n",
       "40%           0.000000\n",
       "50%         102.005000\n",
       "60%         263.006000\n",
       "70%         425.790000\n",
       "80%         705.878000\n",
       "90%        1273.611000\n",
       "max      168469.600000\n",
       "Name: TargetSales, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm zero-inflated, long/fat-tailed\n",
    "outcome_df.TargetSales.describe(percentiles=[i/10 for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confirm zero-inflated, long/fat-tailed\n",
    "outcome_df[outcome_df.TargetSales<=10_000].TargetSales.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent a customer using traditional RFM features namely recency of purchase, purchase days, total sales, number of distinct products purchased, number of distinct category purchased, customer tenure within 2011, average purchase frequency, average purchase value, and percentage of purchase across all 9 categories. This is based on data from Q1-Q3 2011.\n",
    "\n",
    "Since the [UCI Online Retail](https://archive.ics.uci.edu/dataset/352/online+retail) dataset does not have a category but only contains descriptions over 3,000 items, we use `LLaMA 3.2 90B` to infer categories based on randomly selected 1,000 descriptions. This is to make the category preference representation for each customer, which is more tractable than including features about all 3,000+ items. After that, we use the same model to label a category for each description. The categories are:\n",
    "\n",
    "1. Home Decor\n",
    "2. Kitchen and Dining\n",
    "3. Fashion Accessories\n",
    "4. Stationary and Gifts\n",
    "5. Toys and Games\n",
    "6. Seasonal and Holiday\n",
    "7. Personal Care and Wellness\n",
    "8. Outdoor and Garden\n",
    "9. Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify `Description` into `Category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3548"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_transaction.Description.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get `Category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JUMBO BAG PINK POLKADOT', 'BLUE POLKADOT WRAP', 'RED RETROSPOT WRAP ', 'RECYCLING BAG RETROSPOT ', 'RED RETROSPOT SHOPPER BAG']\n",
      "['MODERN FLORAL STATIONERY SET' 'PURPLE BERTIE GLASS BEAD BAG CHARM'\n",
      " 'PARTY INVITES SPACEMAN' 'MONTANA DIAMOND CLUSTER EARRINGS'\n",
      " 'SKULLS  DESIGN  COTTON TOTE BAG']\n"
     ]
    }
   ],
   "source": [
    "descriptions = feature_transaction.Description.unique().tolist()\n",
    "print(descriptions[:5])\n",
    "\n",
    "#randomize descriptions with seed 112 to get which categories we should use\n",
    "np.random.seed(112)\n",
    "random_descriptions = np.random.choice(descriptions, 1000, replace=False)\n",
    "print(random_descriptions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = call_llama(\n",
    "#     'You are a product categorization assistant at a retail website.',\n",
    "#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\\n'.join(random_descriptions)\n",
    "#     )\n",
    "\n",
    "# print(res['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = call_claude(\n",
    "#     'You are a product categorization assistant at a retail website.',\n",
    "#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\\n'.join(random_descriptions)\n",
    "#     )\n",
    "\n",
    "# print(res['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLaMA 3.2 90B Output:\n",
    "```\n",
    "<<SYS>>Based on the product descriptions, I would categorize them into the following categories:\n",
    "\n",
    "1. Home Decor:\n",
    "\t* Wall art\n",
    "\t* Decorative items (e.g. vases, figurines, etc.)\n",
    "\t* Lighting (e.g. candles, lanterns, etc.)\n",
    "\t* Textiles (e.g. throw pillows, blankets, etc.)\n",
    "2. Kitchen and Dining:\n",
    "\t* Cookware and utensils\n",
    "\t* Tableware (e.g. plates, cups, etc.)\n",
    "\t* Kitchen decor (e.g. signs, magnets, etc.)\n",
    "\t* Food and drink items (e.g. tea, coffee, etc.)\n",
    "3. Fashion and Accessories:\n",
    "\t* Jewelry (e.g. necklaces, earrings, etc.)\n",
    "\t* Handbags and wallets\n",
    "\t* Clothing and accessories (e.g. scarves, hats, etc.)\n",
    "4. Stationery and Gifts:\n",
    "\t* Cards and gift wrap\n",
    "\t* Stationery (e.g. notebooks, pens, etc.)\n",
    "\t* Gift items (e.g. mugs, keychains, etc.)\n",
    "5. Toys and Games:\n",
    "\t* Toys (e.g. stuffed animals, puzzles, etc.)\n",
    "\t* Games and puzzles\n",
    "6. Seasonal and Holiday:\n",
    "\t* Christmas decorations and gifts\n",
    "\t* Easter decorations and gifts\n",
    "\t* Other seasonal items (e.g. Halloween, etc.)\n",
    "7. Personal Care and Wellness:\n",
    "\t* Beauty and personal care items (e.g. skincare, haircare, etc.)\n",
    "\t* Wellness and self-care items (e.g. essential oils, etc.)\n",
    "8. Outdoor and Garden:\n",
    "\t* Garden decor and accessories\n",
    "\t* Outdoor furniture and decor\n",
    "\t* Gardening tools and supplies\n",
    "\n",
    "Note that some products may fit into multiple categories, but I have assigned them to the one that seems most relevant.\n",
    "```\n",
    "\n",
    "Claude 3.5 v2 Output\n",
    "```\n",
    "Based on these product descriptions, I would suggest the following main product categories:\n",
    "\n",
    "1. Home Decor\n",
    "- Candle holders\n",
    "- Picture frames\n",
    "- Wall art & signs\n",
    "- Clocks\n",
    "- Cushions & covers\n",
    "- Storage items\n",
    "- Decorative objects\n",
    "\n",
    "2. Jewelry & Accessories\n",
    "- Necklaces\n",
    "- Bracelets\n",
    "- Earrings\n",
    "- Hair accessories\n",
    "- Bag charms\n",
    "- Key rings\n",
    "\n",
    "3. Garden & Outdoor\n",
    "- Plant pots\n",
    "- Garden tools\n",
    "- Outdoor decorations\n",
    "- Bird houses\n",
    "- Garden markers\n",
    "\n",
    "4. Kitchen & Dining\n",
    "- Tea sets\n",
    "- Mugs\n",
    "- Kitchen storage\n",
    "- Cutlery\n",
    "- Baking accessories\n",
    "- Tea towels\n",
    "\n",
    "5. Stationery & Paper Goods\n",
    "- Notebooks\n",
    "- Gift wrap\n",
    "- Cards\n",
    "- Paper decorations\n",
    "- Writing sets\n",
    "\n",
    "6. Party & Celebrations\n",
    "- Party supplies\n",
    "- Gift bags\n",
    "- Christmas decorations\n",
    "- Easter items\n",
    "- Birthday items\n",
    "\n",
    "7. Children's Items\n",
    "- Toys\n",
    "- Children's tableware\n",
    "- School supplies\n",
    "- Kids' accessories\n",
    "\n",
    "8. Fashion Accessories\n",
    "- Bags\n",
    "- Purses\n",
    "- Scarves\n",
    "- Travel accessories\n",
    "\n",
    "9. Bath & Beauty\n",
    "- Bathroom accessories\n",
    "- Toiletry bags\n",
    "- Beauty items\n",
    "\n",
    "10. Lighting\n",
    "- Lamps\n",
    "- String lights\n",
    "- Tea lights\n",
    "- Lanterns\n",
    "\n",
    "These categories cover the main types of products in the list while providing logical groupings for customers to browse.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\n",
    "    'Home Decor',\n",
    "    'Kitchen and Dining',\n",
    "    'Fashion Accessories',\n",
    "    'Stationary and Gifts',\n",
    "    'Toys and Games',\n",
    "    'Seasonal and Holiday',\n",
    "    'Personal Care and Wellness',\n",
    "    'Outdoor and Garden',   \n",
    "]\n",
    "\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate `Category` to `Description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loop through descriptions in batches of batch_size\n",
    "# res_texts = []\n",
    "# batch_size = 100\n",
    "# for i in tqdm(range(0, len(descriptions), batch_size)):\n",
    "#     batch = descriptions[i:i+batch_size]\n",
    "#     d = \"\\n\".join(batch)\n",
    "#     inp = f'''Categorize the following product descriptions into {\", \".join(categories)} or Others, if they do not fall into any. \n",
    "# Only answer in the following format:\n",
    "\n",
    "# \"product description of product #1\"|\"product category classified into\"\n",
    "# \"product description of product #2\"|\"product category classified into\"\n",
    "# ...\n",
    "# \"product description of product #n\"|\"product category classified into\"\n",
    "\n",
    "# Here are the product descriptions:\n",
    "# {d}\n",
    "# '''\n",
    "#     while True:\n",
    "#         res = call_claude('You are a product categorizer at a retail website', inp)\n",
    "#         # if res['generation_token_count'] > 1: #for llama\n",
    "#         if res['usage']['output_tokens'] > 1:\n",
    "#             break\n",
    "#         else:\n",
    "#             print('Retrying...')\n",
    "#             time.sleep(2)\n",
    "#     res_text = res['content'][0]['text'].strip().split('\\n')\n",
    "#         #for llama\n",
    "#         # .replace('[SYS]','').replace('<<SYS>>','')\\\n",
    "#         # .replace('[/SYS]','').replace('<</SYS>>','')\\\n",
    "#     if res_text!='':\n",
    "#         res_texts.extend(res_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/sales_prediction/product_description_category.csv','w') as f:\n",
    "#     f.write('\"product_description\"|\"category\"\\n')\n",
    "#     for i in res_texts:\n",
    "#         f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Home Decor                    0.328636\n",
       "Kitchen and Dining            0.195885\n",
       "Fashion Accessories           0.138670\n",
       "Stationary and Gifts          0.116122\n",
       "Seasonal and Holiday          0.087373\n",
       "Personal Care and Wellness    0.047351\n",
       "Toys and Games                0.045096\n",
       "Outdoor and Garden            0.032976\n",
       "Others                        0.007892\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_description_category = pd.read_csv('../data/sales_prediction/product_description_category.csv',\n",
    "                                           sep='|')\n",
    "\n",
    "#clean product_description\n",
    "product_description_category['Description'] = descriptions\n",
    "product_description_category.category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240338, 10), (240338, 12))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_transaction_cat = feature_transaction.merge(product_description_category,\n",
    "                                                    how='inner',\n",
    "                                                    on = 'Description',)\n",
    "feature_transaction.shape, feature_transaction_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert invoice date to datetime\n",
    "feature_transaction_cat['InvoiceDate'] = pd.to_datetime(feature_transaction_cat['InvoiceDate'])\n",
    "\n",
    "# last date in feature set\n",
    "current_date = feature_transaction_cat['InvoiceDate'].max()\n",
    "\n",
    "#rfm\n",
    "customer_features = feature_transaction_cat.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': [\n",
    "        ('recency', lambda x: (current_date - x.max()).days),\n",
    "        ('first_purchase_date', 'min'),\n",
    "        ('purchase_day', 'nunique'),\n",
    "    ],\n",
    "    'InvoiceNo': [('nb_invoice', 'nunique')],\n",
    "    'Sales': [\n",
    "        ('total_sales', 'sum')\n",
    "    ],\n",
    "    'StockCode': [('nb_product', 'nunique')],\n",
    "    'category': [('nb_category', 'nunique')]\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "customer_features.columns = [\n",
    "    'CustomerID',\n",
    "    'recency',\n",
    "    'first_purchase_date',\n",
    "    'purchase_day',\n",
    "    'nb_invoice',\n",
    "    'total_sales',\n",
    "    'nb_product',\n",
    "    'nb_category'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977021524141943"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#almost always one purchase a day\n",
    "(customer_features.purchase_day==customer_features.nb_invoice).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features['customer_lifetime'] = (current_date - customer_features['first_purchase_date']).dt.days\n",
    "customer_features['avg_purchase_frequency'] = customer_features['customer_lifetime'] / customer_features['purchase_day']\n",
    "customer_features['avg_purchase_value'] = customer_features['total_sales'] / customer_features['purchase_day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category preference\n",
    "category_sales = feature_transaction_cat.pivot_table(\n",
    "    values='Sales', \n",
    "    index='CustomerID', \n",
    "    columns='category', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "category_sales.columns = [i.lower().replace(' ','_') for i in category_sales.columns]\n",
    "customer_features = customer_features.merge(category_sales, on='CustomerID', how='left')\n",
    "\n",
    "total_sales = customer_features['total_sales']\n",
    "for col in category_sales.columns:\n",
    "    percentage_col = f'per_{col}'\n",
    "    customer_features[percentage_col] = customer_features[col] / total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per_fashion_accessories           0.409831\n",
       "per_home_decor                    0.081734\n",
       "per_kitchen_and_dining            0.122455\n",
       "per_others                        0.765561\n",
       "per_outdoor_and_garden            0.507853\n",
       "per_personal_care_and_wellness    0.448226\n",
       "per_seasonal_and_holiday          0.369401\n",
       "per_stationary_and_gifts          0.305410\n",
       "per_toys_and_games                0.487202\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure the categories are not too sparse\n",
    "(customer_features.iloc[:,-9:]==0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Them All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    " 'recency',\n",
    " 'purchase_day',\n",
    " 'total_sales',\n",
    " 'nb_product',\n",
    " 'nb_category',\n",
    " 'customer_lifetime',\n",
    " 'avg_purchase_frequency',\n",
    " 'avg_purchase_value',\n",
    " 'per_fashion_accessories',\n",
    " 'per_home_decor',\n",
    " 'per_kitchen_and_dining',\n",
    " 'per_others',\n",
    " 'per_outdoor_and_garden',\n",
    " 'per_personal_care_and_wellness',\n",
    " 'per_seasonal_and_holiday',\n",
    " 'per_stationary_and_gifts',\n",
    " 'per_toys_and_games']\n",
    "\n",
    "outcome_variable = 'TargetSales'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>recency</th>\n",
       "      <th>purchase_day</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>nb_product</th>\n",
       "      <th>nb_category</th>\n",
       "      <th>customer_lifetime</th>\n",
       "      <th>avg_purchase_frequency</th>\n",
       "      <th>avg_purchase_value</th>\n",
       "      <th>per_fashion_accessories</th>\n",
       "      <th>per_home_decor</th>\n",
       "      <th>per_kitchen_and_dining</th>\n",
       "      <th>per_others</th>\n",
       "      <th>per_outdoor_and_garden</th>\n",
       "      <th>per_personal_care_and_wellness</th>\n",
       "      <th>per_seasonal_and_holiday</th>\n",
       "      <th>per_stationary_and_gifts</th>\n",
       "      <th>per_toys_and_games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>77183.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>77183.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>2079.07</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>247</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>519.767500</td>\n",
       "      <td>0.145834</td>\n",
       "      <td>0.204168</td>\n",
       "      <td>0.294021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>0.129721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>904.44</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>301.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825970</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.022555</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12350</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>334.40</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>239</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>334.400000</td>\n",
       "      <td>0.240431</td>\n",
       "      <td>0.202751</td>\n",
       "      <td>0.116926</td>\n",
       "      <td>0.172548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.089713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12352</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2194.31</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>226</td>\n",
       "      <td>32.285714</td>\n",
       "      <td>313.472857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196531</td>\n",
       "      <td>0.246187</td>\n",
       "      <td>0.474090</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>0.020508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerID  recency  purchase_day  total_sales  nb_product  nb_category  \\\n",
       "0      12346      255             1     77183.60           1            1   \n",
       "1      12347       59             4      2079.07          65            7   \n",
       "2      12348        5             3       904.44          10            4   \n",
       "3      12350      239             1       334.40          17            7   \n",
       "4      12352        2             7      2194.31          47            8   \n",
       "\n",
       "   customer_lifetime  avg_purchase_frequency  avg_purchase_value  \\\n",
       "0                255              255.000000        77183.600000   \n",
       "1                247               61.750000          519.767500   \n",
       "2                248               82.666667          301.480000   \n",
       "3                239              239.000000          334.400000   \n",
       "4                226               32.285714          313.472857   \n",
       "\n",
       "   per_fashion_accessories  per_home_decor  per_kitchen_and_dining  \\\n",
       "0                 0.000000        0.000000                1.000000   \n",
       "1                 0.145834        0.204168                0.294021   \n",
       "2                 0.000000        0.000000                0.000000   \n",
       "3                 0.240431        0.202751                0.116926   \n",
       "4                 0.000000        0.196531                0.246187   \n",
       "\n",
       "   per_others  per_outdoor_and_garden  per_personal_care_and_wellness  \\\n",
       "0    0.000000                0.000000                        0.000000   \n",
       "1    0.000000                0.005628                        0.147614   \n",
       "2    0.132679                0.000000                        0.825970   \n",
       "3    0.172548                0.000000                        0.118421   \n",
       "4    0.474090                0.013535                        0.016680   \n",
       "\n",
       "   per_seasonal_and_holiday  per_stationary_and_gifts  per_toys_and_games  \n",
       "0                  0.000000                  0.000000            0.000000  \n",
       "1                  0.000000                  0.073013            0.129721  \n",
       "2                  0.018796                  0.022555            0.000000  \n",
       "3                  0.000000                  0.059211            0.089713  \n",
       "4                  0.008066                  0.024404            0.020508  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_features = customer_features[[ 'CustomerID']+selected_features]\n",
    "customer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Features and Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3438, 18), (3438, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_features.shape, outcome_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3438, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = outcome_df.merge(customer_features, on='CustomerID').drop('CustomerID', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>purchase_day</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>nb_product</th>\n",
       "      <th>nb_category</th>\n",
       "      <th>customer_lifetime</th>\n",
       "      <th>avg_purchase_frequency</th>\n",
       "      <th>avg_purchase_value</th>\n",
       "      <th>per_fashion_accessories</th>\n",
       "      <th>per_home_decor</th>\n",
       "      <th>per_kitchen_and_dining</th>\n",
       "      <th>per_others</th>\n",
       "      <th>per_outdoor_and_garden</th>\n",
       "      <th>per_personal_care_and_wellness</th>\n",
       "      <th>per_seasonal_and_holiday</th>\n",
       "      <th>per_stationary_and_gifts</th>\n",
       "      <th>per_toys_and_games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recency</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.299308</td>\n",
       "      <td>-0.132344</td>\n",
       "      <td>-0.287415</td>\n",
       "      <td>-0.326772</td>\n",
       "      <td>0.298853</td>\n",
       "      <td>0.893973</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>-0.020861</td>\n",
       "      <td>0.022013</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>-0.016069</td>\n",
       "      <td>0.071268</td>\n",
       "      <td>-0.082792</td>\n",
       "      <td>-0.085681</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.009686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_day</th>\n",
       "      <td>-0.299308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540253</td>\n",
       "      <td>0.690345</td>\n",
       "      <td>0.304621</td>\n",
       "      <td>0.332109</td>\n",
       "      <td>-0.331543</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.025269</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.035665</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>-0.045384</td>\n",
       "      <td>-0.028187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sales</th>\n",
       "      <td>-0.132344</td>\n",
       "      <td>0.540253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400467</td>\n",
       "      <td>0.137064</td>\n",
       "      <td>0.156018</td>\n",
       "      <td>-0.148762</td>\n",
       "      <td>0.361138</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>0.047834</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>-0.029353</td>\n",
       "      <td>-0.011937</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>-0.029181</td>\n",
       "      <td>-0.013139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_product</th>\n",
       "      <td>-0.287415</td>\n",
       "      <td>0.690345</td>\n",
       "      <td>0.400467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555551</td>\n",
       "      <td>0.265594</td>\n",
       "      <td>-0.294923</td>\n",
       "      <td>0.061039</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>-0.017516</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>-0.026371</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.016586</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>-0.010069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_category</th>\n",
       "      <td>-0.326772</td>\n",
       "      <td>0.304621</td>\n",
       "      <td>0.137064</td>\n",
       "      <td>0.555551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>-0.321596</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>-0.138372</td>\n",
       "      <td>-0.039363</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>0.041405</td>\n",
       "      <td>0.075882</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.152869</td>\n",
       "      <td>0.111150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_lifetime</th>\n",
       "      <td>0.298853</td>\n",
       "      <td>0.332109</td>\n",
       "      <td>0.156018</td>\n",
       "      <td>0.265594</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358431</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.069175</td>\n",
       "      <td>-0.019971</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>-0.127865</td>\n",
       "      <td>-0.120399</td>\n",
       "      <td>-0.050320</td>\n",
       "      <td>-0.036484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_purchase_frequency</th>\n",
       "      <td>0.893973</td>\n",
       "      <td>-0.331543</td>\n",
       "      <td>-0.148762</td>\n",
       "      <td>-0.294923</td>\n",
       "      <td>-0.321596</td>\n",
       "      <td>0.358431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>-0.016093</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>-0.027413</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>-0.070352</td>\n",
       "      <td>-0.074799</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.010612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_purchase_value</th>\n",
       "      <td>0.008823</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.361138</td>\n",
       "      <td>0.061039</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003187</td>\n",
       "      <td>-0.056690</td>\n",
       "      <td>0.076862</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>-0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_fashion_accessories</th>\n",
       "      <td>-0.020861</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>-0.016093</td>\n",
       "      <td>-0.003187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.254015</td>\n",
       "      <td>-0.177775</td>\n",
       "      <td>-0.010436</td>\n",
       "      <td>-0.082834</td>\n",
       "      <td>-0.038493</td>\n",
       "      <td>-0.124719</td>\n",
       "      <td>-0.068166</td>\n",
       "      <td>-0.051486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_home_decor</th>\n",
       "      <td>0.022013</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>-0.017516</td>\n",
       "      <td>-0.138372</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>-0.056690</td>\n",
       "      <td>-0.254015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.481983</td>\n",
       "      <td>-0.155784</td>\n",
       "      <td>-0.080637</td>\n",
       "      <td>-0.158837</td>\n",
       "      <td>-0.165964</td>\n",
       "      <td>-0.262313</td>\n",
       "      <td>-0.245759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_kitchen_and_dining</th>\n",
       "      <td>0.057244</td>\n",
       "      <td>0.025269</td>\n",
       "      <td>0.047834</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>-0.039363</td>\n",
       "      <td>0.069175</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.076862</td>\n",
       "      <td>-0.177775</td>\n",
       "      <td>-0.481983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>-0.144698</td>\n",
       "      <td>-0.117031</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.173386</td>\n",
       "      <td>-0.143931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_others</th>\n",
       "      <td>-0.016069</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>-0.019971</td>\n",
       "      <td>-0.027413</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>-0.010436</td>\n",
       "      <td>-0.155784</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>-0.047940</td>\n",
       "      <td>-0.033975</td>\n",
       "      <td>-0.040421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_outdoor_and_garden</th>\n",
       "      <td>0.071268</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.029353</td>\n",
       "      <td>-0.026371</td>\n",
       "      <td>0.041405</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>-0.082834</td>\n",
       "      <td>-0.080637</td>\n",
       "      <td>-0.144698</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045639</td>\n",
       "      <td>-0.077947</td>\n",
       "      <td>-0.057297</td>\n",
       "      <td>-0.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_personal_care_and_wellness</th>\n",
       "      <td>-0.082792</td>\n",
       "      <td>-0.035665</td>\n",
       "      <td>-0.011937</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>0.075882</td>\n",
       "      <td>-0.127865</td>\n",
       "      <td>-0.070352</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>-0.038493</td>\n",
       "      <td>-0.158837</td>\n",
       "      <td>-0.117031</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>-0.045639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057926</td>\n",
       "      <td>-0.025871</td>\n",
       "      <td>-0.017022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_seasonal_and_holiday</th>\n",
       "      <td>-0.085681</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>-0.016586</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>-0.120399</td>\n",
       "      <td>-0.074799</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.124719</td>\n",
       "      <td>-0.165964</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.047940</td>\n",
       "      <td>-0.077947</td>\n",
       "      <td>-0.057926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019418</td>\n",
       "      <td>-0.042970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_stationary_and_gifts</th>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.045384</td>\n",
       "      <td>-0.029181</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.152869</td>\n",
       "      <td>-0.050320</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>-0.068166</td>\n",
       "      <td>-0.262313</td>\n",
       "      <td>-0.173386</td>\n",
       "      <td>-0.033975</td>\n",
       "      <td>-0.057297</td>\n",
       "      <td>-0.025871</td>\n",
       "      <td>-0.019418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_toys_and_games</th>\n",
       "      <td>-0.009686</td>\n",
       "      <td>-0.028187</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-0.010069</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>-0.036484</td>\n",
       "      <td>-0.010612</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>-0.051486</td>\n",
       "      <td>-0.245759</td>\n",
       "      <td>-0.143931</td>\n",
       "      <td>-0.040421</td>\n",
       "      <td>-0.001034</td>\n",
       "      <td>-0.017022</td>\n",
       "      <td>-0.042970</td>\n",
       "      <td>0.172039</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 recency  purchase_day  total_sales  \\\n",
       "recency                         1.000000     -0.299308    -0.132344   \n",
       "purchase_day                   -0.299308      1.000000     0.540253   \n",
       "total_sales                    -0.132344      0.540253     1.000000   \n",
       "nb_product                     -0.287415      0.690345     0.400467   \n",
       "nb_category                    -0.326772      0.304621     0.137064   \n",
       "customer_lifetime               0.298853      0.332109     0.156018   \n",
       "avg_purchase_frequency          0.893973     -0.331543    -0.148762   \n",
       "avg_purchase_value              0.008823      0.027488     0.361138   \n",
       "per_fashion_accessories        -0.020861      0.030683     0.016511   \n",
       "per_home_decor                  0.022013      0.018684    -0.013819   \n",
       "per_kitchen_and_dining          0.057244      0.025269     0.047834   \n",
       "per_others                     -0.016069      0.004299     0.006398   \n",
       "per_outdoor_and_garden          0.071268     -0.019992    -0.029353   \n",
       "per_personal_care_and_wellness -0.082792     -0.035665    -0.011937   \n",
       "per_seasonal_and_holiday       -0.085681     -0.020392    -0.016724   \n",
       "per_stationary_and_gifts       -0.017813     -0.045384    -0.029181   \n",
       "per_toys_and_games             -0.009686     -0.028187    -0.013139   \n",
       "\n",
       "                                nb_product  nb_category  customer_lifetime  \\\n",
       "recency                          -0.287415    -0.326772           0.298853   \n",
       "purchase_day                      0.690345     0.304621           0.332109   \n",
       "total_sales                       0.400467     0.137064           0.156018   \n",
       "nb_product                        1.000000     0.555551           0.265594   \n",
       "nb_category                       0.555551     1.000000           0.224232   \n",
       "customer_lifetime                 0.265594     0.224232           1.000000   \n",
       "avg_purchase_frequency           -0.294923    -0.321596           0.358431   \n",
       "avg_purchase_value                0.061039     0.019955           0.014933   \n",
       "per_fashion_accessories          -0.003137     0.004863           0.011220   \n",
       "per_home_decor                   -0.017516    -0.138372           0.066111   \n",
       "per_kitchen_and_dining            0.035615    -0.039363           0.069175   \n",
       "per_others                       -0.006842     0.055555          -0.019971   \n",
       "per_outdoor_and_garden           -0.026371     0.041405           0.029726   \n",
       "per_personal_care_and_wellness   -0.005309     0.075882          -0.127865   \n",
       "per_seasonal_and_holiday         -0.016586     0.015498          -0.120399   \n",
       "per_stationary_and_gifts          0.026716     0.152869          -0.050320   \n",
       "per_toys_and_games               -0.010069     0.111150          -0.036484   \n",
       "\n",
       "                                avg_purchase_frequency  avg_purchase_value  \\\n",
       "recency                                       0.893973            0.008823   \n",
       "purchase_day                                 -0.331543            0.027488   \n",
       "total_sales                                  -0.148762            0.361138   \n",
       "nb_product                                   -0.294923            0.061039   \n",
       "nb_category                                  -0.321596            0.019955   \n",
       "customer_lifetime                             0.358431            0.014933   \n",
       "avg_purchase_frequency                        1.000000            0.009157   \n",
       "avg_purchase_value                            0.009157            1.000000   \n",
       "per_fashion_accessories                      -0.016093           -0.003187   \n",
       "per_home_decor                                0.027208           -0.056690   \n",
       "per_kitchen_and_dining                        0.037053            0.076862   \n",
       "per_others                                   -0.027413            0.015427   \n",
       "per_outdoor_and_garden                        0.060369           -0.028884   \n",
       "per_personal_care_and_wellness               -0.070352            0.004225   \n",
       "per_seasonal_and_holiday                     -0.074799           -0.000200   \n",
       "per_stationary_and_gifts                     -0.000546           -0.012729   \n",
       "per_toys_and_games                           -0.010612           -0.002396   \n",
       "\n",
       "                                per_fashion_accessories  per_home_decor  \\\n",
       "recency                                       -0.020861        0.022013   \n",
       "purchase_day                                   0.030683        0.018684   \n",
       "total_sales                                    0.016511       -0.013819   \n",
       "nb_product                                    -0.003137       -0.017516   \n",
       "nb_category                                    0.004863       -0.138372   \n",
       "customer_lifetime                              0.011220        0.066111   \n",
       "avg_purchase_frequency                        -0.016093        0.027208   \n",
       "avg_purchase_value                            -0.003187       -0.056690   \n",
       "per_fashion_accessories                        1.000000       -0.254015   \n",
       "per_home_decor                                -0.254015        1.000000   \n",
       "per_kitchen_and_dining                        -0.177775       -0.481983   \n",
       "per_others                                    -0.010436       -0.155784   \n",
       "per_outdoor_and_garden                        -0.082834       -0.080637   \n",
       "per_personal_care_and_wellness                -0.038493       -0.158837   \n",
       "per_seasonal_and_holiday                      -0.124719       -0.165964   \n",
       "per_stationary_and_gifts                      -0.068166       -0.262313   \n",
       "per_toys_and_games                            -0.051486       -0.245759   \n",
       "\n",
       "                                per_kitchen_and_dining  per_others  \\\n",
       "recency                                       0.057244   -0.016069   \n",
       "purchase_day                                  0.025269    0.004299   \n",
       "total_sales                                   0.047834    0.006398   \n",
       "nb_product                                    0.035615   -0.006842   \n",
       "nb_category                                  -0.039363    0.055555   \n",
       "customer_lifetime                             0.069175   -0.019971   \n",
       "avg_purchase_frequency                        0.037053   -0.027413   \n",
       "avg_purchase_value                            0.076862    0.015427   \n",
       "per_fashion_accessories                      -0.177775   -0.010436   \n",
       "per_home_decor                               -0.481983   -0.155784   \n",
       "per_kitchen_and_dining                        1.000000   -0.013075   \n",
       "per_others                                   -0.013075    1.000000   \n",
       "per_outdoor_and_garden                       -0.144698   -0.062652   \n",
       "per_personal_care_and_wellness               -0.117031    0.014794   \n",
       "per_seasonal_and_holiday                     -0.204235   -0.047940   \n",
       "per_stationary_and_gifts                     -0.173386   -0.033975   \n",
       "per_toys_and_games                           -0.143931   -0.040421   \n",
       "\n",
       "                                per_outdoor_and_garden  \\\n",
       "recency                                       0.071268   \n",
       "purchase_day                                 -0.019992   \n",
       "total_sales                                  -0.029353   \n",
       "nb_product                                   -0.026371   \n",
       "nb_category                                   0.041405   \n",
       "customer_lifetime                             0.029726   \n",
       "avg_purchase_frequency                        0.060369   \n",
       "avg_purchase_value                           -0.028884   \n",
       "per_fashion_accessories                      -0.082834   \n",
       "per_home_decor                               -0.080637   \n",
       "per_kitchen_and_dining                       -0.144698   \n",
       "per_others                                   -0.062652   \n",
       "per_outdoor_and_garden                        1.000000   \n",
       "per_personal_care_and_wellness               -0.045639   \n",
       "per_seasonal_and_holiday                     -0.077947   \n",
       "per_stationary_and_gifts                     -0.057297   \n",
       "per_toys_and_games                           -0.001034   \n",
       "\n",
       "                                per_personal_care_and_wellness  \\\n",
       "recency                                              -0.082792   \n",
       "purchase_day                                         -0.035665   \n",
       "total_sales                                          -0.011937   \n",
       "nb_product                                           -0.005309   \n",
       "nb_category                                           0.075882   \n",
       "customer_lifetime                                    -0.127865   \n",
       "avg_purchase_frequency                               -0.070352   \n",
       "avg_purchase_value                                    0.004225   \n",
       "per_fashion_accessories                              -0.038493   \n",
       "per_home_decor                                       -0.158837   \n",
       "per_kitchen_and_dining                               -0.117031   \n",
       "per_others                                            0.014794   \n",
       "per_outdoor_and_garden                               -0.045639   \n",
       "per_personal_care_and_wellness                        1.000000   \n",
       "per_seasonal_and_holiday                             -0.057926   \n",
       "per_stationary_and_gifts                             -0.025871   \n",
       "per_toys_and_games                                   -0.017022   \n",
       "\n",
       "                                per_seasonal_and_holiday  \\\n",
       "recency                                        -0.085681   \n",
       "purchase_day                                   -0.020392   \n",
       "total_sales                                    -0.016724   \n",
       "nb_product                                     -0.016586   \n",
       "nb_category                                     0.015498   \n",
       "customer_lifetime                              -0.120399   \n",
       "avg_purchase_frequency                         -0.074799   \n",
       "avg_purchase_value                             -0.000200   \n",
       "per_fashion_accessories                        -0.124719   \n",
       "per_home_decor                                 -0.165964   \n",
       "per_kitchen_and_dining                         -0.204235   \n",
       "per_others                                     -0.047940   \n",
       "per_outdoor_and_garden                         -0.077947   \n",
       "per_personal_care_and_wellness                 -0.057926   \n",
       "per_seasonal_and_holiday                        1.000000   \n",
       "per_stationary_and_gifts                       -0.019418   \n",
       "per_toys_and_games                             -0.042970   \n",
       "\n",
       "                                per_stationary_and_gifts  per_toys_and_games  \n",
       "recency                                        -0.017813           -0.009686  \n",
       "purchase_day                                   -0.045384           -0.028187  \n",
       "total_sales                                    -0.029181           -0.013139  \n",
       "nb_product                                      0.026716           -0.010069  \n",
       "nb_category                                     0.152869            0.111150  \n",
       "customer_lifetime                              -0.050320           -0.036484  \n",
       "avg_purchase_frequency                         -0.000546           -0.010612  \n",
       "avg_purchase_value                             -0.012729           -0.002396  \n",
       "per_fashion_accessories                        -0.068166           -0.051486  \n",
       "per_home_decor                                 -0.262313           -0.245759  \n",
       "per_kitchen_and_dining                         -0.173386           -0.143931  \n",
       "per_others                                     -0.033975           -0.040421  \n",
       "per_outdoor_and_garden                         -0.057297           -0.001034  \n",
       "per_personal_care_and_wellness                 -0.025871           -0.017022  \n",
       "per_seasonal_and_holiday                       -0.019418           -0.042970  \n",
       "per_stationary_and_gifts                        1.000000            0.172039  \n",
       "per_toys_and_games                              0.172039            1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlations\n",
    "df.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TargetSales', ylabel='total_sales'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#target and most predictive variable\n",
    "df[df.TargetSales<=25_000].plot.scatter(x='TargetSales',y='total_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly split the dataset into train and test sets at 80/20 ratio. We also confirm the distribution of `TargetSales` is similar across percentiles and only different at the upper end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train-valid sets\n",
    "train_df, test_df = train_test_split(df,\n",
    "                                      test_size=0.2, \n",
    "                                      random_state=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>TargetSales</th>\n",
       "      <th>index</th>\n",
       "      <th>TargetSales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2750.000000</td>\n",
       "      <td>count</td>\n",
       "      <td>688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>642.650436</td>\n",
       "      <td>mean</td>\n",
       "      <td>760.558808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>4015.305436</td>\n",
       "      <td>std</td>\n",
       "      <td>4024.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50%</td>\n",
       "      <td>91.350000</td>\n",
       "      <td>50%</td>\n",
       "      <td>113.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60%</td>\n",
       "      <td>260.308000</td>\n",
       "      <td>60%</td>\n",
       "      <td>277.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70%</td>\n",
       "      <td>426.878000</td>\n",
       "      <td>70%</td>\n",
       "      <td>418.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80%</td>\n",
       "      <td>694.164000</td>\n",
       "      <td>80%</td>\n",
       "      <td>759.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90%</td>\n",
       "      <td>1272.997000</td>\n",
       "      <td>90%</td>\n",
       "      <td>1255.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max</td>\n",
       "      <td>168469.600000</td>\n",
       "      <td>max</td>\n",
       "      <td>77099.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index    TargetSales  index   TargetSales\n",
       "0   count    2750.000000  count    688.000000\n",
       "1    mean     642.650436   mean    760.558808\n",
       "2     std    4015.305436    std   4024.524400\n",
       "3     min       0.000000    min      0.000000\n",
       "4      0%       0.000000     0%      0.000000\n",
       "5     10%       0.000000    10%      0.000000\n",
       "6     20%       0.000000    20%      0.000000\n",
       "7     30%       0.000000    30%      0.000000\n",
       "8     40%       0.000000    40%      0.000000\n",
       "9     50%      91.350000    50%    113.575000\n",
       "10    60%     260.308000    60%    277.836000\n",
       "11    70%     426.878000    70%    418.187000\n",
       "12    80%     694.164000    80%    759.582000\n",
       "13    90%    1272.997000    90%   1255.670000\n",
       "14    max  168469.600000    max  77099.380000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),\n",
    "test_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most naive solution is to predict `TargetSales` based on the features. We use a stacked ensemble of LightGBM, CatBoost, XGBoost, Random Forest and Extra Trees via AutoGluon. We train with `good_quality` preset, stated to be \"Stronger than any other AutoML Framework\", for speedy training and inference but feel free to try more performant option. We exclude the neural-network models as they require further preprocessing of the features.\n",
    "\n",
    "We use an industry-grade, non-parametric model to be as close to a real use case as possible and make a point that our methodology works not only in a toy-dataset setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preset = 'good_quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134505\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       470.24 GB / 480.23 GB (97.9%)\n",
      "Disk Space Avail:   1451.64 GB / 1968.52 GB (73.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "2024-12-14 13:45:05,288\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.6.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2444\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    481515.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.62s of the 899.66s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3990.4801\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 593.17s of the 893.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3921.7042\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 587.75s of the 887.78s of remaining time.\n",
      "\t-4516.1791\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 586.59s of the 886.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3857.3111\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 575.99s of the 876.03s of remaining time.\n",
      "\t-3900.3038\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 575.08s of the 875.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3941.3599\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.1s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 568.89s of the 868.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3912.54\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 856.55s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}\n",
      "\t-3835.4224\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 856.47s of the 856.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3941.7891\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 851.87s of the 851.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4314.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3894.7078\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 846.2s of the 846.19s of remaining time.\n",
      "\t-4525.2057\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 845.08s of the 845.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3904.7749\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 839.51s of the 839.5s of remaining time.\n",
      "\t-3952.2022\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 838.57s of the 838.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3929.2019\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 831.87s of the 831.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3912.6409\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 818.17s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}\n",
      "\t-3823.1639\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 81.64s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2283.2 rows/s (306 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.6s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.31s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 3.45s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout    score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_BAG_L1_FULL    -803.899801 -3857.311112  root_mean_squared_error        0.006679            NaN  0.597072                 0.006679                     NaN           0.597072            1       True          4\n",
      "1      WeightedEnsemble_L2_FULL    -813.259482 -3835.422447  root_mean_squared_error        0.120649            NaN  1.485833                 0.002517                     NaN           0.018860            2       True          8\n",
      "2          CatBoost_BAG_L2_FULL    -838.233626 -3904.774934  root_mean_squared_error        0.258556            NaN  3.238374                 0.006184                     NaN           0.173173            2       True         12\n",
      "3   RandomForestMSE_BAG_L1_FULL    -847.825565 -4516.179095  root_mean_squared_error        0.113628       0.174859  0.894842                 0.113628                0.174859           0.894842            1       True          3\n",
      "4     ExtraTreesMSE_BAG_L2_FULL    -890.912998 -3952.202176  root_mean_squared_error        0.360469            NaN  3.743573                 0.108097                0.171160           0.678372            2       True         13\n",
      "5     ExtraTreesMSE_BAG_L1_FULL    -922.896541 -3900.303809  root_mean_squared_error        0.109015       0.173588  0.658955                 0.109015                0.173588           0.658955            1       True          5\n",
      "6      WeightedEnsemble_L3_FULL    -977.887954 -3823.163850  root_mean_squared_error        0.260014            NaN  3.409128                 0.003530                     NaN           0.031533            3       True         16\n",
      "7          LightGBM_BAG_L1_FULL   -1086.123687 -3921.704247  root_mean_squared_error        0.002438            NaN  0.210945                 0.002438                     NaN           0.210945            1       True          2\n",
      "8   RandomForestMSE_BAG_L2_FULL   -1090.066132 -4525.205744  root_mean_squared_error        0.349192            NaN  3.933684                 0.096820                0.174712           0.868483            2       True         11\n",
      "9        LightGBMXT_BAG_L1_FULL   -1230.340360 -3990.480139  root_mean_squared_error        0.002607            NaN  0.245293                 0.002607                     NaN           0.245293            1       True          1\n",
      "10       LightGBMXT_BAG_L2_FULL   -1234.815155 -3941.789134  root_mean_squared_error        0.255407            NaN  3.276018                 0.003035                     NaN           0.210817            2       True          9\n",
      "11    LightGBMLarge_BAG_L1_FULL   -1345.024278 -3912.540001  root_mean_squared_error        0.004740            NaN  0.335057                 0.004740                     NaN           0.335057            1       True          7\n",
      "12    LightGBMLarge_BAG_L2_FULL   -1640.347524 -3912.640942  root_mean_squared_error        0.262513            NaN  3.497248                 0.010141                     NaN           0.432046            2       True         15\n",
      "13         LightGBM_BAG_L2_FULL   -1743.255667 -3894.707823  root_mean_squared_error        0.256483            NaN  3.377595                 0.004111                     NaN           0.312394            2       True         10\n",
      "14          XGBoost_BAG_L1_FULL   -2245.433966 -3941.359884  root_mean_squared_error        0.013265            NaN  0.123036                 0.013265                     NaN           0.123036            1       True          6\n",
      "15          XGBoost_BAG_L2_FULL   -2454.083373 -3929.201875  root_mean_squared_error        0.267445            NaN  3.256454                 0.015073                     NaN           0.191253            2       True         14\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t86s\t = DyStack   runtime |\t3514s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3514s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134505\"\n",
      "Train Data Rows:    2750\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    480433.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3513.91s of the 3513.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 9800.07\n",
      "[2000]\tvalid_set's rmse: 9792.42\n",
      "[3000]\tvalid_set's rmse: 9791.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3713.1197\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3505.33s of the 3505.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 9561.64\n",
      "[2000]\tvalid_set's rmse: 9538.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3635.1505\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3499.08s of the 3499.08s of remaining time.\n",
      "\t-4135.0334\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3497.99s of the 3497.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3669.0125\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.54s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3479.34s of the 3479.34s of remaining time.\n",
      "\t-3678.3921\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3478.41s of the 3478.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3785.5048\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.79s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3472.52s of the 3472.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3704.5742\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3460.51s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}\n",
      "\t-3608.5561\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 53.55s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6308.2 rows/s (344 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.57s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.36s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.81s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}\n",
      "\t0.02s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2.49s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134505\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='TargetSales').fit(train_df[selected_features + ['TargetSales']], \n",
    "                                                      presets=preset,\n",
    "                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_baseline'] = predictor.predict(test_df[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3162.478744240967,\n",
       " 'mean_squared_error': 10001271.807775924,\n",
       " 'mean_absolute_error': 715.6442657130541,\n",
       " 'r2': 0.3816166296854987,\n",
       " 'pearsonr': 0.6190719671013133,\n",
       " 'spearmanr': 0.47008461549340863,\n",
       " 'median_absolute_error': 232.98208312988282,\n",
       " 'earths_mover_distance': 287.77728784026124,\n",
       " 'model': 'baseline'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_baseline = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_baseline'])\n",
    "metric_baseline['model'] = 'baseline'\n",
    "metric_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on Winsorized Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible approach to deal with long/fat-tailed outcome is to train on a winsorized outcome. This may lead to better performance when tested on a winsorized outcome but not so much on original outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7180.805199999947"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_per = 0.99\n",
    "outlier_cap_train = train_df['TargetSales'].quantile(outlier_per)\n",
    "outlier_cap_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winsorize\n",
    "train_df['TargetSales_win'] = train_df['TargetSales'].map(lambda x: outlier_cap_train if x> outlier_cap_train else x)\n",
    "test_df['TargetSales_win'] = test_df['TargetSales'].map(lambda x: outlier_cap_train if x> outlier_cap_train else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134727\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       468.94 GB / 480.23 GB (97.6%)\n",
      "Disk Space Avail:   1451.56 GB / 1968.52 GB (73.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2444\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_win\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    480196.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.8s of the 899.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-704.0735\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 594.77s of the 894.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-700.8029\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 590.42s of the 890.54s of remaining time.\n",
      "\t-708.5579\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 589.41s of the 889.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-682.2162\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.8s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 582.52s of the 882.64s of remaining time.\n",
      "\t-688.9972\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 581.63s of the 881.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-710.5012\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.15s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 576.4s of the 876.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-715.783\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 859.93s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'XGBoost_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.05}\n",
      "\t-677.7482\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 859.84s of the 859.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-701.3347\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 854.32s of the 854.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 622.335\n",
      "[2000]\tvalid_set's rmse: 619.896\n",
      "[3000]\tvalid_set's rmse: 619.36\n",
      "[4000]\tvalid_set's rmse: 619.228\n",
      "[5000]\tvalid_set's rmse: 619.165\n",
      "[6000]\tvalid_set's rmse: 619.15\n",
      "[7000]\tvalid_set's rmse: 619.144\n",
      "[8000]\tvalid_set's rmse: 619.142\n",
      "[9000]\tvalid_set's rmse: 619.14\n",
      "[10000]\tvalid_set's rmse: 619.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-669.5782\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 837.9s of the 837.89s of remaining time.\n",
      "\t-702.8194\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 836.75s of the 836.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-679.668\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 823.27s of the 823.26s of remaining time.\n",
      "\t-688.2802\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 822.32s of the 822.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-706.5666\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 814.89s of the 814.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-701.7902\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 799.67s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.632, 'CatBoost_BAG_L1': 0.158, 'ExtraTreesMSE_BAG_L1': 0.105, 'XGBoost_BAG_L1': 0.105}\n",
      "\t-664.9152\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 100.43s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1980.5 rows/s (306 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.08s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.82s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'XGBoost_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.05}\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.57s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.62s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.632, 'CatBoost_BAG_L1': 0.158, 'ExtraTreesMSE_BAG_L1': 0.105, 'XGBoost_BAG_L1': 0.105}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 5.9s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           XGBoost_BAG_L2_FULL    -673.227470 -706.566643  root_mean_squared_error        0.261725            NaN  3.356293                 0.014406                     NaN           0.243477            2       True         14\n",
      "1          CatBoost_BAG_L2_FULL    -685.276375 -679.668006  root_mean_squared_error        0.253890            NaN  3.729317                 0.006571                     NaN           0.616501            2       True         12\n",
      "2     ExtraTreesMSE_BAG_L2_FULL    -686.432329 -688.280166  root_mean_squared_error        0.384582            NaN  3.796237                 0.137263                0.174881           0.683421            2       True         13\n",
      "3      WeightedEnsemble_L2_FULL    -687.292057 -677.748155  root_mean_squared_error        0.129074            NaN  1.357070                 0.002933                     NaN           0.026227            2       True          8\n",
      "4          CatBoost_BAG_L1_FULL    -688.830702 -682.216238  root_mean_squared_error        0.008315            NaN  0.291358                 0.008315                     NaN           0.291358            1       True          4\n",
      "5   RandomForestMSE_BAG_L2_FULL    -690.155342 -702.819447  root_mean_squared_error        0.358528            NaN  3.991187                 0.111209                0.176151           0.878371            2       True         11\n",
      "6     LightGBMLarge_BAG_L2_FULL    -699.457560 -701.790157  root_mean_squared_error        0.256358            NaN  3.792534                 0.009039                     NaN           0.679718            2       True         15\n",
      "7      WeightedEnsemble_L3_FULL    -699.646914 -664.915201  root_mean_squared_error        0.269660            NaN  4.711405                 0.004106                     NaN           0.030340            3       True         16\n",
      "8   RandomForestMSE_BAG_L1_FULL    -700.107179 -708.557877  root_mean_squared_error        0.111719       0.175315  0.737258                 0.111719                0.175315           0.737258            1       True          3\n",
      "9     ExtraTreesMSE_BAG_L1_FULL    -701.853556 -688.997247  root_mean_squared_error        0.105658       0.176891  0.644825                 0.105658                0.176891           0.644825            1       True          5\n",
      "10          XGBoost_BAG_L1_FULL    -717.776000 -710.501170  root_mean_squared_error        0.008964            NaN  0.078643                 0.008964                     NaN           0.078643            1       True          6\n",
      "11       LightGBMXT_BAG_L2_FULL    -723.560168 -701.334719  root_mean_squared_error        0.251497            NaN  3.444983                 0.004178                     NaN           0.332167            2       True          9\n",
      "12         LightGBM_BAG_L1_FULL    -726.112842 -700.802863  root_mean_squared_error        0.002110            NaN  0.227411                 0.002110                     NaN           0.227411            1       True          2\n",
      "13         LightGBM_BAG_L2_FULL    -728.829307 -669.578190  root_mean_squared_error        0.265554            NaN  4.681065                 0.018236                     NaN           1.568249            2       True         10\n",
      "14       LightGBMXT_BAG_L1_FULL    -733.594747 -704.073534  root_mean_squared_error        0.003205            NaN  0.316018                 0.003205                     NaN           0.316018            1       True          1\n",
      "15    LightGBMLarge_BAG_L1_FULL    -766.964045 -715.782974  root_mean_squared_error        0.007349            NaN  0.817303                 0.007349                     NaN           0.817303            1       True          7\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t107s\t = DyStack   runtime |\t3493s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3493s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134727\"\n",
      "Train Data Rows:    2750\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_win\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    479639.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3492.88s of the 3492.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-710.5609\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3487.59s of the 3487.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-696.6213\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3482.58s of the 3482.58s of remaining time.\n",
      "\t-706.2702\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3481.53s of the 3481.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-668.1395\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.92s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3472.5s of the 3472.5s of remaining time.\n",
      "\t-688.8913\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3471.6s of the 3471.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-699.3326\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3465.77s of the 3465.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-714.8496\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3451.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}\n",
      "\t-667.3394\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 41.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4132.1 rows/s (344 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.67s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}\n",
      "\t0.02s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2.18s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134727\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='TargetSales_win').fit(train_df[selected_features+['TargetSales_win']],\n",
    "                                                      presets=preset,\n",
    "                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_winsorized'] = predictor.predict(test_df[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3623.576377551195,\n",
       " 'mean_squared_error': 13130305.76394704,\n",
       " 'mean_absolute_error': 627.7880071099414,\n",
       " 'r2': 0.18814697894155963,\n",
       " 'pearsonr': 0.5757989413256978,\n",
       " 'spearmanr': 0.504301956183441,\n",
       " 'median_absolute_error': 219.62248107910156,\n",
       " 'earths_mover_distance': 432.1288432991232,\n",
       " 'model': 'winsorized'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_winsorized = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_winsorized'])\n",
    "metric_winsorized['model'] = 'winsorized'\n",
    "metric_winsorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 673.4846433338375,\n",
       " 'mean_squared_error': 453581.5648065064,\n",
       " 'mean_absolute_error': 376.77603327273135,\n",
       " 'r2': 0.6171771763549553,\n",
       " 'pearsonr': 0.7865724180212539,\n",
       " 'spearmanr': 0.504299950810919,\n",
       " 'median_absolute_error': 218.8311004638672,\n",
       " 'earths_mover_distance': 181.1168694619127}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_regression_metrics(test_df['TargetSales_win'], test_df['pred_winsorized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log1p Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log transformation handles long/fat-tailed distribution and is especially useful for certain models since the transformed distribution is roughly normal. However, it cannot handle zero-valued outcome and oftentimes scientists end up adding 1 to the outcome (so often that `numpy` even has a function for it). This not only introduces bias to the prediction, but also does not solve the zero-inflation as it becomes one-inflation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "train_df['TargetSales_log1p'] = train_df['TargetSales'].map(np.log1p)\n",
    "test_df['TargetSales_log1p'] = test_df['TargetSales'].map(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from zero-inflated to one-inflated\n",
    "train_df['TargetSales_log1p'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134958\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       468.19 GB / 480.23 GB (97.5%)\n",
      "Disk Space Avail:   1451.46 GB / 1968.52 GB (73.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2444\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_log1p\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    479431.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.81s of the 899.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7823\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 595.21s of the 895.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8135\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 591.22s of the 891.35s of remaining time.\n",
      "\t-2.8314\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 590.14s of the 890.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7808\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 584.28s of the 884.41s of remaining time.\n",
      "\t-2.8158\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 583.31s of the 883.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8362\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 577.92s of the 878.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8628\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 865.92s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.478, 'LightGBMXT_BAG_L1': 0.435, 'ExtraTreesMSE_BAG_L1': 0.087}\n",
      "\t-2.7756\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 865.86s of the 865.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.69718\n",
      "[2000]\tvalid_set's rmse: 2.65909\n",
      "[3000]\tvalid_set's rmse: 2.65127\n",
      "[4000]\tvalid_set's rmse: 2.64831\n",
      "[5000]\tvalid_set's rmse: 2.64686\n",
      "[6000]\tvalid_set's rmse: 2.64619\n",
      "[7000]\tvalid_set's rmse: 2.64592\n",
      "[8000]\tvalid_set's rmse: 2.64577\n",
      "[9000]\tvalid_set's rmse: 2.64574\n",
      "[10000]\tvalid_set's rmse: 2.64573\n",
      "[1000]\tvalid_set's rmse: 2.69753\n",
      "[2000]\tvalid_set's rmse: 2.65357\n",
      "[3000]\tvalid_set's rmse: 2.64919\n",
      "[4000]\tvalid_set's rmse: 2.64645\n",
      "[5000]\tvalid_set's rmse: 2.64479\n",
      "[6000]\tvalid_set's rmse: 2.64422\n",
      "[7000]\tvalid_set's rmse: 2.6439\n",
      "[8000]\tvalid_set's rmse: 2.64387\n",
      "[9000]\tvalid_set's rmse: 2.64384\n",
      "[10000]\tvalid_set's rmse: 2.64383\n",
      "[1000]\tvalid_set's rmse: 2.71185\n",
      "[2000]\tvalid_set's rmse: 2.66777\n",
      "[3000]\tvalid_set's rmse: 2.65641\n",
      "[4000]\tvalid_set's rmse: 2.65399\n",
      "[5000]\tvalid_set's rmse: 2.65317\n",
      "[6000]\tvalid_set's rmse: 2.65306\n",
      "[7000]\tvalid_set's rmse: 2.65305\n",
      "[1000]\tvalid_set's rmse: 2.73753\n",
      "[2000]\tvalid_set's rmse: 2.69713\n",
      "[3000]\tvalid_set's rmse: 2.68365\n",
      "[4000]\tvalid_set's rmse: 2.67838\n",
      "[5000]\tvalid_set's rmse: 2.67756\n",
      "[6000]\tvalid_set's rmse: 2.67725\n",
      "[7000]\tvalid_set's rmse: 2.67727\n",
      "[1000]\tvalid_set's rmse: 2.51029\n",
      "[2000]\tvalid_set's rmse: 2.46542\n",
      "[3000]\tvalid_set's rmse: 2.45449\n",
      "[4000]\tvalid_set's rmse: 2.45128\n",
      "[5000]\tvalid_set's rmse: 2.44983\n",
      "[6000]\tvalid_set's rmse: 2.44947\n",
      "[7000]\tvalid_set's rmse: 2.44914\n",
      "[8000]\tvalid_set's rmse: 2.44909\n",
      "[9000]\tvalid_set's rmse: 2.4491\n",
      "[10000]\tvalid_set's rmse: 2.44914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6944\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.47s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 813.19s of the 813.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.64699\n",
      "[2000]\tvalid_set's rmse: 2.64384\n",
      "[3000]\tvalid_set's rmse: 2.64347\n",
      "[4000]\tvalid_set's rmse: 2.64345\n",
      "[1000]\tvalid_set's rmse: 2.6483\n",
      "[1000]\tvalid_set's rmse: 2.87823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.7598\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.99s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 803.1s of the 803.09s of remaining time.\n",
      "\t-2.8088\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 802.07s of the 802.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.759\t = Validation score   (-root_mean_squared_error)\n",
      "\t92.85s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 709.08s of the 709.07s of remaining time.\n",
      "\t-2.778\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 708.14s of the 708.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7901\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 701.58s of the 701.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.76447\n",
      "[1000]\tvalid_set's rmse: 2.80146\n",
      "[2000]\tvalid_set's rmse: 2.8014\n",
      "[3000]\tvalid_set's rmse: 2.8014\n",
      "[4000]\tvalid_set's rmse: 2.8014\n",
      "[1000]\tvalid_set's rmse: 2.88446\n",
      "[2000]\tvalid_set's rmse: 2.88439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.7943\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.94s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 655.49s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.72, 'CatBoost_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.04, 'LightGBM_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n",
      "\t-2.6854\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 244.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1078.2 rows/s (306 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.08s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.37s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.478, 'LightGBMXT_BAG_L1': 0.435, 'ExtraTreesMSE_BAG_L1': 0.087}\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t4.94s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.76s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t3.03s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t3.93s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.72, 'CatBoost_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.04, 'LightGBM_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 14.81s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_BAG_L1_FULL      -2.885523  -2.780750  root_mean_squared_error        0.019700            NaN   0.210621                 0.019700                     NaN           0.210621            1       True          4\n",
      "1      WeightedEnsemble_L2_FULL      -2.894191  -2.775644  root_mean_squared_error        0.155056            NaN   1.140924                 0.002549                     NaN           0.019073            2       True          8\n",
      "2   RandomForestMSE_BAG_L2_FULL      -2.894937  -2.808770  root_mean_squared_error        0.407366            NaN   3.299085                 0.126307                0.179813           0.754930            2       True         11\n",
      "3     ExtraTreesMSE_BAG_L2_FULL      -2.896741  -2.777983  root_mean_squared_error        0.400050            NaN   3.203568                 0.118991                0.182625           0.659413            2       True         13\n",
      "4        LightGBMXT_BAG_L1_FULL      -2.908863  -2.782297  root_mean_squared_error        0.002410            NaN   0.229015                 0.002410                     NaN           0.229015            1       True          1\n",
      "5          CatBoost_BAG_L2_FULL      -2.922107  -2.759026  root_mean_squared_error        0.290997            NaN   5.576536                 0.009938                     NaN           3.032381            2       True         12\n",
      "6          LightGBM_BAG_L2_FULL      -2.931031  -2.759814  root_mean_squared_error        0.291885            NaN   3.309105                 0.010826                     NaN           0.764950            2       True         10\n",
      "7           XGBoost_BAG_L2_FULL      -2.938193  -2.790059  root_mean_squared_error        0.292573            NaN   2.701340                 0.011514                     NaN           0.157185            2       True         14\n",
      "8      WeightedEnsemble_L3_FULL      -2.942265  -2.685363  root_mean_squared_error        0.414771            NaN  12.371993                 0.005430                     NaN           0.029768            3       True         16\n",
      "9     ExtraTreesMSE_BAG_L1_FULL      -2.946022  -2.815757  root_mean_squared_error        0.130396       0.183574   0.682215                 0.130396                0.183574           0.682215            1       True          5\n",
      "10         LightGBM_BAG_L1_FULL      -2.953480  -2.813496  root_mean_squared_error        0.001765            NaN   0.174514                 0.001765                     NaN           0.174514            1       True          2\n",
      "11          XGBoost_BAG_L1_FULL      -2.972277  -2.836214  root_mean_squared_error        0.010018            NaN   0.076469                 0.010018                     NaN           0.076469            1       True          6\n",
      "12    LightGBMLarge_BAG_L2_FULL      -2.977587  -2.794323  root_mean_squared_error        0.327995            NaN   6.475816                 0.046936                     NaN           3.931662            2       True         15\n",
      "13  RandomForestMSE_BAG_L1_FULL      -2.985264  -2.831375  root_mean_squared_error        0.111768       0.181522   0.798739                 0.111768                0.181522           0.798739            1       True          3\n",
      "14       LightGBMXT_BAG_L2_FULL      -2.995407  -2.694352  root_mean_squared_error        0.340065            NaN   7.488428                 0.059006                     NaN           4.944273            2       True          9\n",
      "15    LightGBMLarge_BAG_L1_FULL      -3.050660  -2.862792  root_mean_squared_error        0.005002            NaN   0.372581                 0.005002                     NaN           0.372581            1       True          7\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t260s\t = DyStack   runtime |\t3340s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3340s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_134958\"\n",
      "Train Data Rows:    2750\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_log1p\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    479126.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3339.69s of the 3339.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7861\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3334.48s of the 3334.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8189\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3329.67s of the 3329.67s of remaining time.\n",
      "\t-2.8468\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3328.66s of the 3328.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7963\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.43s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3323.13s of the 3323.13s of remaining time.\n",
      "\t-2.8191\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3322.18s of the 3322.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8365\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.51s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3316.57s of the 3316.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8667\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3304.17s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}\n",
      "\t-2.7845\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 35.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6632.0 rows/s (344 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.09s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}\n",
      "\t0.02s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 1.41s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134958\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='TargetSales_log1p').fit(train_df[selected_features+['TargetSales_log1p']],\n",
    "                                                      presets=preset,\n",
    "                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_log1p'] = predictor.predict(test_df[selected_features])\n",
    "test_df['pred_log1p_expm1'] = test_df['pred_log1p'].map(np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3725.342295894091,\n",
       " 'mean_squared_error': 13878175.221577456,\n",
       " 'mean_absolute_error': 618.9768466651894,\n",
       " 'r2': 0.14190585634701047,\n",
       " 'pearsonr': 0.5817166874396966,\n",
       " 'spearmanr': 0.5338156315937898,\n",
       " 'median_absolute_error': 89.55495441784018,\n",
       " 'earths_mover_distance': 581.0494444960044,\n",
       " 'model': 'log1p'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_log1p = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_log1p_expm1'])\n",
    "metric_log1p['model'] = 'log1p'\n",
    "metric_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 2.720047847858299,\n",
       " 'mean_squared_error': 7.398660294638562,\n",
       " 'mean_absolute_error': 2.418601533469381,\n",
       " 'r2': 0.30252750020590236,\n",
       " 'pearsonr': 0.5507740732825224,\n",
       " 'spearmanr': 0.5338156315937898,\n",
       " 'median_absolute_error': 2.349368453025818,\n",
       " 'earths_mover_distance': 1.8552344547363062}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_regression_metrics(test_df['TargetSales_log1p'], test_df['pred_log1p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurdle Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurdle model is a two-stage approach that handles zero inflation by first having a classification model to predict if the outcome is zero or not, then a regression model, trained only on examples with actual non-zero outcomes, to fit a log-transformed outcome. When retransforming the predictions from log to non-log numbers, we perform correction of underestimation using Duan's method. During inference time, we multiply the predictions from the classification and regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['has_purchase'] = train_df.TargetSales.map(lambda x: 1 if x>0 else 0)\n",
    "test_df['has_purchase'] = test_df.TargetSales.map(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5141818181818182, 0.5305232558139535)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['has_purchase'].mean(), test_df['has_purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241214_135456\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       467.88 GB / 480.23 GB (97.4%)\n",
      "Disk Space Avail:   1451.34 GB / 1968.52 GB (73.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2444\n",
      "Train Data Columns: 17\n",
      "Label Column:       has_purchase\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    479111.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.8s of the 899.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6944\t = Validation score   (accuracy)\n",
      "\t4.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 594.97s of the 895.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.687\t = Validation score   (accuracy)\n",
      "\t4.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 590.87s of the 890.99s of remaining time.\n",
      "\t0.6661\t = Validation score   (accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 589.72s of the 889.84s of remaining time.\n",
      "\t0.6543\t = Validation score   (accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 588.58s of the 888.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.698\t = Validation score   (accuracy)\n",
      "\t8.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 580.02s of the 880.14s of remaining time.\n",
      "\t0.6731\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 578.92s of the 879.04s of remaining time.\n",
      "\t0.6751\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 577.82s of the 877.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6874\t = Validation score   (accuracy)\n",
      "\t4.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 572.75s of the 872.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6739\t = Validation score   (accuracy)\n",
      "\t16.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 856.19s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.698\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 855.98s of the 855.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7017\t = Validation score   (accuracy)\n",
      "\t4.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 851.17s of the 851.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7062\t = Validation score   (accuracy)\n",
      "\t4.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 846.46s of the 846.45s of remaining time.\n",
      "\t0.6849\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 845.32s of the 845.31s of remaining time.\n",
      "\t0.6845\t = Validation score   (accuracy)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 844.16s of the 844.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7074\t = Validation score   (accuracy)\n",
      "\t12.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 831.99s of the 831.98s of remaining time.\n",
      "\t0.6845\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 830.87s of the 830.86s of remaining time.\n",
      "\t0.6796\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 829.78s of the 829.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7029\t = Validation score   (accuracy)\n",
      "\t5.77s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 823.88s of the 823.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.705\t = Validation score   (accuracy)\n",
      "\t17.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 806.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.957, 'CatBoost_BAG_L1': 0.043}\n",
      "\t0.7079\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 93.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1613.2 rows/s (306 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.93s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.58s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.89s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.957, 'CatBoost_BAG_L1': 0.043}\n",
      "\t0.34s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 4.63s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBM_BAG_L1_FULL       0.699346   0.686989    accuracy        0.001600            NaN  0.208330                 0.001600                     NaN           0.208330            1       True          2\n",
      "1           CatBoost_BAG_L1_FULL       0.699346   0.698036    accuracy        0.003851            NaN  0.167360                 0.003851                     NaN           0.167360            1       True          5\n",
      "2       WeightedEnsemble_L2_FULL       0.699346   0.698036    accuracy        0.005369            NaN  0.340888                 0.001517                     NaN           0.173529            2       True         10\n",
      "3     ExtraTreesEntr_BAG_L1_FULL       0.692810   0.675123    accuracy        0.128038       0.188885  0.825164                 0.128038                0.188885           0.825164            1       True          7\n",
      "4         LightGBMXT_BAG_L2_FULL       0.692810   0.701718    accuracy        0.585924            NaN  5.335749                 0.003118                     NaN           0.228724            2       True         11\n",
      "5           CatBoost_BAG_L2_FULL       0.692810   0.707447    accuracy        0.588336            NaN  5.688442                 0.005529                     NaN           0.581416            2       True         15\n",
      "6       WeightedEnsemble_L3_FULL       0.692810   0.707856    accuracy        0.591025            NaN  6.027241                 0.002690                     NaN           0.338799            3       True         20\n",
      "7     ExtraTreesGini_BAG_L1_FULL       0.689542   0.673077    accuracy        0.135107       0.184615  0.849001                 0.135107                0.184615           0.849001            1       True          6\n",
      "8   RandomForestEntr_BAG_L1_FULL       0.683007   0.654255    accuracy        0.151755       0.179378  0.880783                 0.151755                0.179378           0.880783            1       True          4\n",
      "9   RandomForestGini_BAG_L2_FULL       0.679739   0.684943    accuracy        0.707727            NaN  5.968028                 0.124921                0.182446           0.861002            2       True         13\n",
      "10    ExtraTreesGini_BAG_L2_FULL       0.679739   0.684534    accuracy        0.714077            NaN  5.943708                 0.131271                0.187909           0.836683            2       True         16\n",
      "11          LightGBM_BAG_L2_FULL       0.676471   0.706219    accuracy        0.585907            NaN  5.337967                 0.003100                     NaN           0.230941            2       True         12\n",
      "12    ExtraTreesEntr_BAG_L2_FULL       0.676471   0.679624    accuracy        0.713373            NaN  5.920607                 0.130566                0.184792           0.813582            2       True         17\n",
      "13           XGBoost_BAG_L1_FULL       0.673203   0.687398    accuracy        0.010908            NaN  0.096438                 0.010908                     NaN           0.096438            1       True          8\n",
      "14           XGBoost_BAG_L2_FULL       0.673203   0.702946    accuracy        0.595513            NaN  5.224690                 0.012707                     NaN           0.117664            2       True         18\n",
      "15  RandomForestEntr_BAG_L2_FULL       0.673203   0.684534    accuracy        0.720246            NaN  6.002285                 0.137439                0.180509           0.895260            2       True         14\n",
      "16        LightGBMXT_BAG_L1_FULL       0.666667   0.694354    accuracy        0.002619            NaN  0.272291                 0.002619                     NaN           0.272291            1       True          1\n",
      "17     LightGBMLarge_BAG_L1_FULL       0.663399   0.673895    accuracy        0.007822            NaN  0.927927                 0.007822                     NaN           0.927927            1       True          9\n",
      "18  RandomForestGini_BAG_L1_FULL       0.660131   0.666121    accuracy        0.141106       0.181869  0.879733                 0.141106                0.181869           0.879733            1       True          3\n",
      "19     LightGBMLarge_BAG_L2_FULL       0.656863   0.704992    accuracy        0.593734            NaN  5.992391                 0.010928                     NaN           0.885365            2       True         19\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t100s\t = DyStack   runtime |\t3500s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3500s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_135456\"\n",
      "Train Data Rows:    2750\n",
      "Train Data Columns: 17\n",
      "Label Column:       has_purchase\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    478823.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3500.15s of the 3500.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6964\t = Validation score   (accuracy)\n",
      "\t4.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3495.79s of the 3495.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6884\t = Validation score   (accuracy)\n",
      "\t4.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3491.61s of the 3491.6s of remaining time.\n",
      "\t0.6615\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3490.43s of the 3490.43s of remaining time.\n",
      "\t0.6644\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3489.34s of the 3489.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6935\t = Validation score   (accuracy)\n",
      "\t7.5s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3481.73s of the 3481.73s of remaining time.\n",
      "\t0.6738\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3480.63s of the 3480.62s of remaining time.\n",
      "\t0.6716\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3479.5s of the 3479.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6789\t = Validation score   (accuracy)\n",
      "\t5.27s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3474.1s of the 3474.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.6738\t = Validation score   (accuracy)\n",
      "\t17.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3456.77s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6964\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 43309.0 rows/s (344 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.93s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.18s\t = Training   runtime\n",
      "Updated best model to \"LightGBMXT_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBMXT_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2.02s ... Best model: \"LightGBMXT_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_135456\")\n"
     ]
    }
   ],
   "source": [
    "predictor_cls = TabularPredictor(label='has_purchase').fit(train_df[selected_features+['has_purchase']],\n",
    "                                                      presets=preset,\n",
    "                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_binary'] = predictor_cls.predict(test_df[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6918604651162791,\n",
       " 'precision': 0.6941069004479309,\n",
       " 'recall': 0.6918604651162791,\n",
       " 'f1_score': 0.6921418829824787,\n",
       " 'confusion_matrix': array([[229,  94],\n",
       "        [118, 247]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caluclate_classification_metrics(test_df['has_purchase'], test_df['pred_binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression on Non-Zero Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1414, 21), (365, 31))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nonzero = train_df[train_df.has_purchase==1].reset_index(drop=True)\n",
    "test_df_nonzero = test_df[test_df.has_purchase==1].reset_index(drop=True)\n",
    "\n",
    "train_df_nonzero.shape, test_df_nonzero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "train_df_nonzero['TargetSales_log'] = train_df_nonzero['TargetSales'].map(np.log)\n",
    "test_df_nonzero['TargetSales_log'] = test_df_nonzero['TargetSales'].map(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_nonzero['TargetSales_log'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241214_161346\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       466.78 GB / 480.23 GB (97.2%)\n",
      "Disk Space Avail:   1450.75 GB / 1968.52 GB (73.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    1256\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_log\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    477983.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.81s of the 899.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7829\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 593.9s of the 894.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7864\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 588.14s of the 888.27s of remaining time.\n",
      "\t-0.8046\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 587.17s of the 887.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7747\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.49s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 579.61s of the 879.74s of remaining time.\n",
      "\t-0.7815\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 578.75s of the 878.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7865\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 573.25s of the 873.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.732165\n",
      "[2000]\tvalid_set's rmse: 0.730646\n",
      "[3000]\tvalid_set's rmse: 0.730279\n",
      "[4000]\tvalid_set's rmse: 0.730248\n",
      "[5000]\tvalid_set's rmse: 0.730238\n",
      "[6000]\tvalid_set's rmse: 0.730238\n",
      "[7000]\tvalid_set's rmse: 0.730238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.8114\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 831.05s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.455, 'ExtraTreesMSE_BAG_L1': 0.227, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.136}\n",
      "\t-0.7698\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 830.98s of the 830.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7955\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 825.34s of the 825.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.776795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.7972\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 817.73s of the 817.72s of remaining time.\n",
      "\t-0.8017\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 816.81s of the 816.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7824\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 811.18s of the 811.18s of remaining time.\n",
      "\t-0.7873\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 810.31s of the 810.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.8012\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.75s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 803.46s of the 803.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.8115\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.94s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 787.41s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.412, 'ExtraTreesMSE_BAG_L1': 0.176, 'LightGBM_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'XGBoost_BAG_L2': 0.118, 'LightGBM_BAG_L2': 0.059}\n",
      "\t-0.7689\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 112.67s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 945.3 rows/s (157 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.38s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t3.38s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.455, 'ExtraTreesMSE_BAG_L1': 0.227, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.136}\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.61s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.84s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.412, 'ExtraTreesMSE_BAG_L1': 0.176, 'LightGBM_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'XGBoost_BAG_L2': 0.118, 'LightGBM_BAG_L2': 0.059}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 7.83s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTreesMSE_BAG_L1_FULL      -0.839346  -0.781522  root_mean_squared_error        0.130818       0.146218  0.616536                 0.130818                0.146218           0.616536            1       True          5\n",
      "1     ExtraTreesMSE_BAG_L2_FULL      -0.853589  -0.787303  root_mean_squared_error        0.446297            NaN  6.640192                 0.132555                0.153409           0.613806            2       True         13\n",
      "2      WeightedEnsemble_L3_FULL      -0.857556  -0.768871  root_mean_squared_error        0.340568            NaN  6.967287                 0.005255                     NaN           0.026960            3       True         16\n",
      "3   RandomForestMSE_BAG_L1_FULL      -0.861175  -0.804629  root_mean_squared_error        0.122124       0.147519  0.702981                 0.122124                0.147519           0.702981            1       True          3\n",
      "4      WeightedEnsemble_L2_FULL      -0.862117  -0.769820  root_mean_squared_error        0.157042            NaN  1.533079                 0.004246                     NaN           0.017303            2       True          8\n",
      "5        LightGBMXT_BAG_L1_FULL      -0.864283  -0.782882  root_mean_squared_error        0.002461            NaN  0.427038                 0.002461                     NaN           0.427038            1       True          1\n",
      "6          CatBoost_BAG_L2_FULL      -0.866735  -0.782409  root_mean_squared_error        0.322393            NaN  6.225857                 0.008651                     NaN           0.199471            2       True         12\n",
      "7   RandomForestMSE_BAG_L2_FULL      -0.867588  -0.801697  root_mean_squared_error        0.442486            NaN  6.695999                 0.128743                0.152188           0.669613            2       True         11\n",
      "8        LightGBMXT_BAG_L2_FULL      -0.867632  -0.795484  root_mean_squared_error        0.317761            NaN  6.431228                 0.004019                     NaN           0.404842            2       True          9\n",
      "9           XGBoost_BAG_L2_FULL      -0.867990  -0.801243  root_mean_squared_error        0.327944            NaN  6.329812                 0.014201                     NaN           0.303426            2       True         14\n",
      "10         LightGBM_BAG_L2_FULL      -0.869884  -0.797155  root_mean_squared_error        0.321112            NaN  6.636901                 0.007370                     NaN           0.610516            2       True         10\n",
      "11         LightGBM_BAG_L1_FULL      -0.872511  -0.786431  root_mean_squared_error        0.001978            NaN  0.396514                 0.001978                     NaN           0.396514            1       True          2\n",
      "12         CatBoost_BAG_L1_FULL      -0.876613  -0.774745  root_mean_squared_error        0.007943            NaN  0.375822                 0.007943                     NaN           0.375822            1       True          4\n",
      "13          XGBoost_BAG_L1_FULL      -0.908105  -0.786510  root_mean_squared_error        0.012056            NaN  0.126903                 0.012056                     NaN           0.126903            1       True          6\n",
      "14    LightGBMLarge_BAG_L2_FULL      -0.929002  -0.811482  root_mean_squared_error        0.322513            NaN  6.862701                 0.008771                     NaN           0.836315            2       True         15\n",
      "15    LightGBMLarge_BAG_L1_FULL      -0.943116  -0.811385  root_mean_squared_error        0.036361            NaN  3.380592                 0.036361                     NaN           3.380592            1       True          7\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t121s\t = DyStack   runtime |\t3479s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3479s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241214_161346\"\n",
      "Train Data Rows:    1414\n",
      "Train Data Columns: 17\n",
      "Label Column:       TargetSales_log\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    478011.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n",
      "\t\t('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2318.53s of the 3478.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7909\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2312.52s of the 3472.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7919\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 2306.77s of the 3466.9s of remaining time.\n",
      "\t-0.8074\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2305.84s of the 3465.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.783\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2299.16s of the 3459.29s of remaining time.\n",
      "\t-0.7902\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2298.3s of the 3458.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.8026\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.14s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2293.07s of the 3453.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.8166\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3438.24s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}\n",
      "\t-0.78\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3438.17s of the 3438.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.741321\n",
      "[2000]\tvalid_set's rmse: 0.735104\n",
      "[1000]\tvalid_set's rmse: 0.756407\n",
      "[1000]\tvalid_set's rmse: 0.712855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.7869\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3428.15s of the 3428.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7932\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 3421.11s of the 3421.1s of remaining time.\n",
      "\t-0.8097\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 3420.15s of the 3420.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.7847\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 3411.04s of the 3411.04s of remaining time.\n",
      "\t-0.795\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 3410.19s of the 3410.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.8102\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.21s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3403.88s of the 3403.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.75982\n",
      "[2000]\tvalid_set's rmse: 0.759573\n",
      "[1000]\tvalid_set's rmse: 0.838684\n",
      "[2000]\tvalid_set's rmse: 0.838386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.8107\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3372.32s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}\n",
      "\t-0.7746\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 106.52s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1175.2 rows/s (177 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.09s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.73s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.83s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.54s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t2.46s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}\n",
      "\t0.04s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 7.11s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_161346\")\n"
     ]
    }
   ],
   "source": [
    "predictor_reg = TabularPredictor(label='TargetSales_log').fit(train_df_nonzero[selected_features+['TargetSales_log']],\n",
    "                                                      presets=preset,\n",
    "                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_nonzero['pred_log'] = predictor_reg.predict(test_df_nonzero[selected_features])\n",
    "test_df_nonzero['pred_log_exp'] = test_df_nonzero['pred_log'].map(np.exp)\n",
    "\n",
    "test_df['pred_log'] = predictor_reg.predict(test_df[selected_features])\n",
    "test_df['pred_log_exp'] = test_df['pred_log'].map(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 4330.443144695726,\n",
       " 'mean_squared_error': 18752737.82944221,\n",
       " 'mean_absolute_error': 880.0418223064565,\n",
       " 'r2': 0.3647576298877435,\n",
       " 'pearsonr': 0.6756393928483335,\n",
       " 'spearmanr': 0.5762190201444638,\n",
       " 'median_absolute_error': 243.0658528752748,\n",
       " 'earths_mover_distance': 546.7166312173882}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_regression_metrics(test_df_nonzero['TargetSales'], test_df_nonzero['pred_log_exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_hurdle'] = test_df.pred_binary * test_df.pred_log_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3171.760744960863,\n",
       " 'mean_squared_error': 10060066.22327469,\n",
       " 'mean_absolute_error': 584.9162934881963,\n",
       " 'r2': 0.3779813431428882,\n",
       " 'pearsonr': 0.6769697889999318,\n",
       " 'spearmanr': 0.5107083593715698,\n",
       " 'median_absolute_error': 199.1780137692856,\n",
       " 'earths_mover_distance': 286.381442541919,\n",
       " 'model': 'hurdle'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_hurdle = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle'])\n",
    "metric_hurdle['model'] = 'hurdle'\n",
    "metric_hurdle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Duan's Method](https://www.jstor.org/stable/2288126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When predicting a log-transformed outcome, we typically want to re-transform the predictions to non-log numbers by applying the exponential function. However, this ignores a small bias due to the error term in the process.\n",
    "\n",
    "$$ln(y) = f(X) + \\epsilon$$\n",
    "\n",
    "where \n",
    "* $y$ is actual outcome.\n",
    "* $X$ is the features.\n",
    "* $f(.)$ is a trained model.\n",
    "* $\\epsilon$ is the error term.\n",
    "\n",
    "when re-transforming\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= exp(ln(y)) \\\\\n",
    "&= exp(f(X) + \\epsilon ) \\\\\n",
    "&= exp(f(X)) \\cdot exp(\\epsilon) \\\\\n",
    "E[y] &= E[exp(f(X))] \\cdot E[exp(\\epsilon)]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Duan estimates the E[$exp(\\epsilon)$] as \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\lambda &= E[exp(ln(y) - ln(\\hat y))]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $\\hat \\lambda$ is the Duan's smearing estimator of the bias from re-transformation $E[exp(\\epsilon)]$\n",
    "* $\\hat y$ is the prediction aka $f(X)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2280991653046711"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\n",
    "train_df_nonzero['pred_log_exp'] = train_df_nonzero['pred_log'].map(np.exp)\n",
    "\n",
    "smearing_estimator = np.mean(np.exp(train_df_nonzero['TargetSales_log'] - train_df_nonzero['pred_log']))\n",
    "smearing_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.exp(train_df_nonzero['TargetSales_log'] - train_df_nonzero['pred_log']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_log_exp_corrected'] = test_df['pred_log_exp'] * smearing_estimator\n",
    "test_df['pred_hurdle_corrected'] = test_df.pred_binary * test_df.pred_log_exp_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3055.3207868281233,\n",
       " 'mean_squared_error': 9334985.110424023,\n",
       " 'mean_absolute_error': 613.3946643257099,\n",
       " 'r2': 0.42281345159207295,\n",
       " 'pearsonr': 0.6769697889999318,\n",
       " 'spearmanr': 0.5107083593715698,\n",
       " 'median_absolute_error': 232.55557358084502,\n",
       " 'earths_mover_distance': 241.61839859133218,\n",
       " 'model': 'hurdle_corrected'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_hurdle_corrected = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected'])\n",
    "metric_hurdle_corrected['model'] = 'hurdle_corrected'\n",
    "metric_hurdle_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption on Independent and Identically Distributed Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not so fast, the formulation of Duan's smearing estimator assumes that estimates of error terms (residuals) for log predictions be independent and identically distributed. Since we are dealing with individual customers, independence can be assumed. However, if we look at the plot of residuals vs predicted log values, we can see that they are not identically distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pred_log', ylabel='residual_log'>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot residual and predicted log value\n",
    "train_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\n",
    "train_df_nonzero['residual_log'] = (train_df_nonzero['pred_log'] - train_df_nonzero['TargetSales_log'])\n",
    "\n",
    "# Create the scatter plot\n",
    "sns.scatterplot(x='pred_log', y='residual_log', data=train_df_nonzero)\n",
    "\n",
    "# Add the Lowess smoothing line\n",
    "sns.regplot(x='pred_log', y='residual_log', data=train_df_nonzero, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although note that [White test](https://en.wikipedia.org/wiki/White_test) does not reject the null hypothesis of the residuals being homoscedastic in reference to the features. This counterintuitive result might stem from the fact that White test is assuming linear or quadratic relationships between outcome and features while the residuals are derived from a stacked ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Test Statistic: 129.31318320644837\n",
      "P-value: 0.8761278601130765\n"
     ]
    }
   ],
   "source": [
    "white_stat, white_p_value, _, _ = het_white(train_df_nonzero['residual_log'], \n",
    "                                            train_df_nonzero[selected_features])\n",
    "print(f\"White Test Statistic: {white_stat}\")\n",
    "print(f\"P-value: {white_p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our choice is to either trust the White test and ~~pretend~~ assume everything is fine; or trust our eyes and replace the non-zero regression model with one that produces iid residuals such as [generalized least squares (GLS)](https://en.wikipedia.org/wiki/Generalized_least_squares) with heteroscedasticity-robust standard errors. In order to satisfy the assumptions of GLS, we perform winsorization, standardization and verify multicollinearity among the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature        VIF\n",
      "0                            const   1.000000\n",
      "1                          recency   3.976800\n",
      "2                     purchase_day   6.193391\n",
      "3                      total_sales   5.837235\n",
      "4                       nb_product   2.386644\n",
      "5                      nb_category   2.691338\n",
      "6                customer_lifetime   2.271404\n",
      "7           avg_purchase_frequency   5.291575\n",
      "8               avg_purchase_value   2.449152\n",
      "9          per_fashion_accessories   5.826894\n",
      "10                  per_home_decor  15.806683\n",
      "11          per_kitchen_and_dining  12.053308\n",
      "12                      per_others   1.779531\n",
      "13          per_outdoor_and_garden   2.729103\n",
      "14  per_personal_care_and_wellness   2.908001\n",
      "15        per_seasonal_and_holiday   4.234883\n",
      "16        per_stationary_and_gifts   4.252687\n",
      "17              per_toys_and_games   3.185269\n",
      "High VIF features:                    feature        VIF\n",
      "10          per_home_decor  15.806683\n",
      "11  per_kitchen_and_dining  12.053308\n"
     ]
    }
   ],
   "source": [
    "train_df_nonzero_processed = train_df_nonzero.copy()\n",
    "\n",
    "#winsorize at 99%\n",
    "winsorizer = Winsorizer(cols=selected_features, percentile=99)\n",
    "winsorizer.fit(train_df_nonzero_processed)\n",
    "train_df_nonzero_processed = winsorizer.transform(train_df_nonzero_processed)\n",
    "\n",
    "#standard scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df_nonzero_processed[selected_features])\n",
    "train_df_nonzero_processed[selected_features] = scaler.transform(train_df_nonzero_processed[selected_features])\n",
    "\n",
    "#check vif\n",
    "vif_data = calculate_vif(train_df_nonzero_processed, selected_features)\n",
    "\n",
    "# Print the VIF for each feature\n",
    "print(vif_data)\n",
    "\n",
    "# Filter out features with high VIF (e.g., VIF > 10 suggests multicollinearity)\n",
    "high_vif_features = vif_data[vif_data['VIF'] > 10]\n",
    "print(\"High VIF features:\", high_vif_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature       VIF\n",
      "0                            const  1.000000\n",
      "1                          recency  3.975755\n",
      "2                     purchase_day  6.193274\n",
      "3                      total_sales  5.835455\n",
      "4                       nb_product  2.355212\n",
      "5                      nb_category  2.238039\n",
      "6                customer_lifetime  2.265888\n",
      "7           avg_purchase_frequency  5.288665\n",
      "8               avg_purchase_value  2.447088\n",
      "9          per_fashion_accessories  1.271944\n",
      "10                  per_home_decor  1.642046\n",
      "11                      per_others  1.172240\n",
      "12          per_outdoor_and_garden  1.122673\n",
      "13  per_personal_care_and_wellness  1.141183\n",
      "14        per_seasonal_and_holiday  1.180130\n",
      "15        per_stationary_and_gifts  1.310125\n",
      "16              per_toys_and_games  1.198112\n",
      "High VIF features: Empty DataFrame\n",
      "Columns: [feature, VIF]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calculate VIF after dropping highly correlated features\n",
    "selected_features_no_corr = [i for i in selected_features if i!='per_kitchen_and_dining']\n",
    "vif_data = calculate_vif(train_df_nonzero_processed.drop('per_kitchen_and_dining',axis=1), \n",
    "                         selected_features_no_corr)\n",
    "\n",
    "# Print the VIF for each feature\n",
    "print(vif_data)\n",
    "\n",
    "# Filter out features with high VIF (e.g., VIF > 10 suggests multicollinearity)\n",
    "high_vif_features = vif_data[vif_data['VIF'] > 10]\n",
    "print(\"High VIF features:\", high_vif_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        TargetSales_log   R-squared:                       0.460\n",
      "Model:                            GLS   Adj. R-squared:                  0.454\n",
      "Method:                 Least Squares   F-statistic:                     75.24\n",
      "Date:                Sat, 14 Dec 2024   Prob (F-statistic):          2.27e-175\n",
      "Time:                        16:56:46   Log-Likelihood:                -1661.3\n",
      "No. Observations:                1414   AIC:                             3357.\n",
      "Df Residuals:                    1397   BIC:                             3446.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                              6.3127      0.021    299.031      0.000       6.271       6.354\n",
      "recency                            0.0054      0.047      0.114      0.909      -0.087       0.098\n",
      "purchase_day                       0.3697      0.046      7.977      0.000       0.279       0.460\n",
      "total_sales                        0.1438      0.049      2.905      0.004       0.047       0.241\n",
      "nb_product                        -0.0293      0.032     -0.929      0.353      -0.091       0.033\n",
      "nb_category                        0.1163      0.034      3.448      0.001       0.050       0.182\n",
      "customer_lifetime                 -0.0170      0.032     -0.524      0.600      -0.081       0.047\n",
      "avg_purchase_frequency            -0.0103      0.052     -0.197      0.844      -0.113       0.092\n",
      "avg_purchase_value                 0.3817      0.034     11.257      0.000       0.315       0.448\n",
      "per_fashion_accessories           -0.0216      0.030     -0.724      0.469      -0.080       0.037\n",
      "per_home_decor                    -0.0063      0.034     -0.188      0.851      -0.072       0.060\n",
      "per_others                        -0.0165      0.023     -0.706      0.480      -0.062       0.029\n",
      "per_outdoor_and_garden            -0.0397      0.022     -1.768      0.077      -0.084       0.004\n",
      "per_personal_care_and_wellness    -0.0042      0.025     -0.167      0.867      -0.054       0.045\n",
      "per_seasonal_and_holiday          -0.0796      0.025     -3.248      0.001      -0.128      -0.032\n",
      "per_stationary_and_gifts           0.0166      0.024      0.698      0.485      -0.030       0.063\n",
      "per_toys_and_games                -0.0230      0.026     -0.900      0.368      -0.073       0.027\n",
      "==============================================================================\n",
      "Omnibus:                      162.402   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1272.986\n",
      "Skew:                           0.198   Prob(JB):                    3.75e-277\n",
      "Kurtosis:                       7.631   Cond. No.                         6.59\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "y = train_df_nonzero_processed['TargetSales_log']\n",
    "X = train_df_nonzero_processed[selected_features_no_corr]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "gls_model = sm.GLS(y, X)\n",
    "gls_results = gls_model.fit(cov_type='HC3')\n",
    "\n",
    "# 4. Print the summary of the regression\n",
    "print(gls_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pred_log_gls', ylabel='residual_log_gls'>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot residual and predicted log value\n",
    "train_df_nonzero_processed['pred_log_gls'] = gls_results.predict(X).reset_index(drop=True)\n",
    "train_df_nonzero_processed['residual_log_gls'] = (train_df_nonzero_processed['pred_log_gls'] - train_df_nonzero_processed['TargetSales_log'])\n",
    "train_df_nonzero_processed.plot.scatter(x='pred_log_gls', y='residual_log_gls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Test Statistic: 135.0623196454856\n",
      "P-value: 0.8343390085729777\n"
     ]
    }
   ],
   "source": [
    "white_stat, white_p_value, _, _ = het_white(train_df_nonzero_processed['residual_log_gls'], \n",
    "                                            X)\n",
    "print(f\"White Test Statistic: {white_stat}\")\n",
    "print(f\"P-value: {white_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess test set\n",
    "test_df_processed = test_df.copy()\n",
    "\n",
    "#winsorize at 99%\n",
    "test_df_processed = winsorizer.transform(test_df_processed)\n",
    "\n",
    "#standard scaling\n",
    "test_df_processed[selected_features] = scaler.transform(test_df_processed[selected_features])\n",
    "\n",
    "#drop highly correlated features\n",
    "test_df_processed = test_df_processed.drop('per_kitchen_and_dining', axis=1)\n",
    "\n",
    "#infer\n",
    "X_test = test_df_processed[selected_features_no_corr]\n",
    "X_test = sm.add_constant(X_test)\n",
    "test_df_processed['pred_log_gls'] = gls_results.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8597808961776598"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smearing_estimator_gls = np.mean(np.exp(train_df_nonzero_processed['TargetSales_log'] - train_df_nonzero_processed['pred_log_gls']))\n",
    "smearing_estimator_gls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 5289.79271849163,\n",
       " 'mean_squared_error': 27981907.004607063,\n",
       " 'mean_absolute_error': 970.7645208697954,\n",
       " 'r2': -0.73013455627538,\n",
       " 'pearsonr': 0.7076845600551718,\n",
       " 'spearmanr': 0.5187878933164471,\n",
       " 'median_absolute_error': 339.03363694351526,\n",
       " 'earths_mover_distance': 556.014141615775,\n",
       " 'model': 'hurdle_gls_corrected'}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['pred_log_exp_gls'] = test_df_processed['pred_log_gls'].map(np.exp)\n",
    "\n",
    "test_df['pred_log_exp_gls_corrected'] = test_df['pred_log_exp_gls'] * smearing_estimator_gls\n",
    "test_df['pred_hurdle_gls_corrected'] = test_df.pred_binary * test_df.pred_log_exp_gls_corrected\n",
    "\n",
    "metric_hurdle_gls_corrected = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_gls_corrected'])\n",
    "metric_hurdle_gls_corrected['model'] = 'hurdle_gls_corrected'\n",
    "metric_hurdle_gls_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `hurdle_corrected` method performs best across all metrics except for 1) mean absolute error where it performs about 5% worse than `hurdle` method without the correction and 2) median absolute error where it only performs better than baseline regression and 3) Spearman's rank correlation where it underperforms `log1p` by 4%; correlations are tied between the two Hurdle methods by definition since we multiply Duan's smearing estimator to `hurdle` predictions to get `hurdle_corrected`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame([metric_baseline,\n",
    "                       metric_winsorized,\n",
    "                       metric_log1p,\n",
    "                       metric_hurdle,\n",
    "                       metric_hurdle_corrected,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>baseline</td>\n",
       "      <td>winsorized</td>\n",
       "      <td>log1p</td>\n",
       "      <td>hurdle</td>\n",
       "      <td>hurdle_corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error_rank</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_squared_error_rank</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_rank</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pearsonr_rank</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearmanr_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_absolute_error_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earths_mover_distance_rank</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rank</th>\n",
       "      <td>3.375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.625</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0           1      2       3  \\\n",
       "model                         baseline  winsorized  log1p  hurdle   \n",
       "root_mean_squared_error_rank       2.0         4.0    5.0     3.0   \n",
       "mean_squared_error_rank            2.0         4.0    5.0     3.0   \n",
       "mean_absolute_error_rank           5.0         4.0    3.0     1.0   \n",
       "r2_rank                            2.0         4.0    5.0     3.0   \n",
       "pearsonr_rank                      3.0         5.0    4.0     1.5   \n",
       "spearmanr_rank                     5.0         4.0    1.0     2.5   \n",
       "median_absolute_error_rank         5.0         3.0    1.0     2.0   \n",
       "earths_mover_distance_rank         3.0         4.0    5.0     2.0   \n",
       "avg_rank                         3.375         4.0  3.625    2.25   \n",
       "\n",
       "                                             4  \n",
       "model                         hurdle_corrected  \n",
       "root_mean_squared_error_rank               1.0  \n",
       "mean_squared_error_rank                    1.0  \n",
       "mean_absolute_error_rank                   2.0  \n",
       "r2_rank                                    1.0  \n",
       "pearsonr_rank                              1.5  \n",
       "spearmanr_rank                             2.5  \n",
       "median_absolute_error_rank                 4.0  \n",
       "earths_mover_distance_rank                 1.0  \n",
       "avg_rank                                  1.75  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df = metric_df.copy()\n",
    "for col in metric_df.columns.tolist()[:-1]:\n",
    "    if col in ['r2', 'pearsonr', 'spearmanr']:\n",
    "        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=False)\n",
    "    else:\n",
    "        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=True)\n",
    "rank_df = rank_df.drop(metric_df.columns.tolist()[:-1], axis=1)\n",
    "rank_df['avg_rank'] = rank_df.iloc[:,1:].mean(axis=1)\n",
    "rank_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>3162.478744</td>\n",
       "      <td>3623.576378</td>\n",
       "      <td>3725.342296</td>\n",
       "      <td>3171.760745</td>\n",
       "      <td>3055.320787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>10001271.807776</td>\n",
       "      <td>13130305.763947</td>\n",
       "      <td>13878175.221577</td>\n",
       "      <td>10060066.223275</td>\n",
       "      <td>9334985.110424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>715.644266</td>\n",
       "      <td>627.788007</td>\n",
       "      <td>618.976847</td>\n",
       "      <td>584.916293</td>\n",
       "      <td>613.394664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.381617</td>\n",
       "      <td>0.188147</td>\n",
       "      <td>0.141906</td>\n",
       "      <td>0.377981</td>\n",
       "      <td>0.422813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pearsonr</th>\n",
       "      <td>0.619072</td>\n",
       "      <td>0.575799</td>\n",
       "      <td>0.581717</td>\n",
       "      <td>0.67697</td>\n",
       "      <td>0.67697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearmanr</th>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.504302</td>\n",
       "      <td>0.533816</td>\n",
       "      <td>0.510708</td>\n",
       "      <td>0.510708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_absolute_error</th>\n",
       "      <td>232.982083</td>\n",
       "      <td>219.622481</td>\n",
       "      <td>89.554954</td>\n",
       "      <td>199.178014</td>\n",
       "      <td>232.555574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earths_mover_distance</th>\n",
       "      <td>287.777288</td>\n",
       "      <td>432.128843</td>\n",
       "      <td>581.049444</td>\n",
       "      <td>286.381443</td>\n",
       "      <td>241.618399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>baseline</td>\n",
       "      <td>winsorized</td>\n",
       "      <td>log1p</td>\n",
       "      <td>hurdle</td>\n",
       "      <td>hurdle_corrected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                1                2  \\\n",
       "root_mean_squared_error      3162.478744      3623.576378      3725.342296   \n",
       "mean_squared_error       10001271.807776  13130305.763947  13878175.221577   \n",
       "mean_absolute_error           715.644266       627.788007       618.976847   \n",
       "r2                              0.381617         0.188147         0.141906   \n",
       "pearsonr                        0.619072         0.575799         0.581717   \n",
       "spearmanr                       0.470085         0.504302         0.533816   \n",
       "median_absolute_error         232.982083       219.622481        89.554954   \n",
       "earths_mover_distance         287.777288       432.128843       581.049444   \n",
       "model                           baseline       winsorized            log1p   \n",
       "\n",
       "                                       3                 4  \n",
       "root_mean_squared_error      3171.760745       3055.320787  \n",
       "mean_squared_error       10060066.223275    9334985.110424  \n",
       "mean_absolute_error           584.916293        613.394664  \n",
       "r2                              0.377981          0.422813  \n",
       "pearsonr                         0.67697           0.67697  \n",
       "spearmanr                       0.510708          0.510708  \n",
       "median_absolute_error         199.178014        232.555574  \n",
       "earths_mover_distance         286.381443        241.618399  \n",
       "model                             hurdle  hurdle_corrected  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why `hurdle` Outperforms `hurdle_corrected` in MAE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duan's method adjusts for underestimation from retransformation of log outcome. This could lead to smaller extreme errors but more less extreme ones. We verify this hypothesis by comparing mean absolute error before and after transformation for errors originally under and over 99th percentile. We confirm that is the case for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_hurdle = (test_df['TargetSales'] - test_df['pred_hurdle']).abs()\n",
    "err_hurdle_corrected = (test_df['TargetSales'] - test_df['pred_hurdle_corrected']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      688.000000\n",
       "mean       584.916293\n",
       "std       3119.628924\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%        199.178014\n",
       "75%        475.603446\n",
       "90%        862.530026\n",
       "95%       1237.540954\n",
       "99%       6763.777844\n",
       "max      55731.205996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_hurdle.describe(percentiles=[.25, .5, .75, .9, .95, .99]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355.4918014848842, 22904.641872667555)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_hurdle[err_hurdle<6763.777844].mean(),\\\n",
    "err_hurdle[err_hurdle>6763.777844].mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392.7718802742851, 22076.839798471465)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_hurdle_corrected[err_hurdle<6763.777844].mean(),\\\n",
    "err_hurdle_corrected[err_hurdle>6763.777844].mean(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why `log1p` Performs So Much Better than Others in MedAE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is for similar reasons that `hurdle` outperforms `hurdle_corrected` in MedAE; however, `log1p` performs twice better than other approaches (it also slightly outperforms `hurdle` models in Spearman's rank correlation), especially the Hurdle models which should be modeling the non-zero outcomes in the same manner. This is because Hurdle models depend not only on the regression but the classification model. We can see that if the classification model were perfect (instead of the current f1 = 0.69), other metrics also improved but not nearly as drastic as MedAE and Spearman's rank correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>3162.478744</td>\n",
       "      <td>3623.576378</td>\n",
       "      <td>3725.342296</td>\n",
       "      <td>3171.760745</td>\n",
       "      <td>3055.320787</td>\n",
       "      <td>3030.854831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>10001271.807776</td>\n",
       "      <td>13130305.763947</td>\n",
       "      <td>13878175.221577</td>\n",
       "      <td>10060066.223275</td>\n",
       "      <td>9334985.110424</td>\n",
       "      <td>9186081.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>715.644266</td>\n",
       "      <td>627.788007</td>\n",
       "      <td>618.976847</td>\n",
       "      <td>584.916293</td>\n",
       "      <td>613.394664</td>\n",
       "      <td>479.558294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.381617</td>\n",
       "      <td>0.188147</td>\n",
       "      <td>0.141906</td>\n",
       "      <td>0.377981</td>\n",
       "      <td>0.422813</td>\n",
       "      <td>0.43202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pearsonr</th>\n",
       "      <td>0.619072</td>\n",
       "      <td>0.575799</td>\n",
       "      <td>0.581717</td>\n",
       "      <td>0.67697</td>\n",
       "      <td>0.67697</td>\n",
       "      <td>0.687639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearmanr</th>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.504302</td>\n",
       "      <td>0.533816</td>\n",
       "      <td>0.510708</td>\n",
       "      <td>0.510708</td>\n",
       "      <td>0.929419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_absolute_error</th>\n",
       "      <td>232.982083</td>\n",
       "      <td>219.622481</td>\n",
       "      <td>89.554954</td>\n",
       "      <td>199.178014</td>\n",
       "      <td>232.555574</td>\n",
       "      <td>34.991964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earths_mover_distance</th>\n",
       "      <td>287.777288</td>\n",
       "      <td>432.128843</td>\n",
       "      <td>581.049444</td>\n",
       "      <td>286.381443</td>\n",
       "      <td>241.618399</td>\n",
       "      <td>234.587018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>baseline</td>\n",
       "      <td>winsorized</td>\n",
       "      <td>log1p</td>\n",
       "      <td>hurdle</td>\n",
       "      <td>hurdle_corrected</td>\n",
       "      <td>hurdle_corrected_perfect_cls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                1                2  \\\n",
       "root_mean_squared_error      3162.478744      3623.576378      3725.342296   \n",
       "mean_squared_error       10001271.807776  13130305.763947  13878175.221577   \n",
       "mean_absolute_error           715.644266       627.788007       618.976847   \n",
       "r2                              0.381617         0.188147         0.141906   \n",
       "pearsonr                        0.619072         0.575799         0.581717   \n",
       "spearmanr                       0.470085         0.504302         0.533816   \n",
       "median_absolute_error         232.982083       219.622481        89.554954   \n",
       "earths_mover_distance         287.777288       432.128843       581.049444   \n",
       "model                           baseline       winsorized            log1p   \n",
       "\n",
       "                                       3                 4  \\\n",
       "root_mean_squared_error      3171.760745       3055.320787   \n",
       "mean_squared_error       10060066.223275    9334985.110424   \n",
       "mean_absolute_error           584.916293        613.394664   \n",
       "r2                              0.377981          0.422813   \n",
       "pearsonr                         0.67697           0.67697   \n",
       "spearmanr                       0.510708          0.510708   \n",
       "median_absolute_error         199.178014        232.555574   \n",
       "earths_mover_distance         286.381443        241.618399   \n",
       "model                             hurdle  hurdle_corrected   \n",
       "\n",
       "                                                    5  \n",
       "root_mean_squared_error                   3030.854831  \n",
       "mean_squared_error                     9186081.006625  \n",
       "mean_absolute_error                        479.558294  \n",
       "r2                                            0.43202  \n",
       "pearsonr                                     0.687639  \n",
       "spearmanr                                    0.929419  \n",
       "median_absolute_error                       34.991964  \n",
       "earths_mover_distance                      234.587018  \n",
       "model                    hurdle_corrected_perfect_cls  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['pred_hurdle_corrected_perfect_cls'] = test_df.has_purchase * test_df.pred_log_exp_corrected\n",
    "metric_hurdle_corrected_perfect_cls = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected_perfect_cls'])\n",
    "metric_hurdle_corrected_perfect_cls['model'] = 'hurdle_corrected_perfect_cls'\n",
    "\n",
    "metric_df2 = pd.DataFrame([metric_baseline,\n",
    "                       metric_winsorized,\n",
    "                       metric_log1p,\n",
    "                       metric_hurdle,\n",
    "                       metric_hurdle_corrected,\n",
    "                       metric_hurdle_corrected_perfect_cls,])\n",
    "metric_df2.transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Baseline Regression Performs Best at Aggregate Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at aggregated mean or sum of actual sales vs predicted sales, baseline regression performs best by far. This is due to the fact that without any constraints a regressor only minimizes the MSE loss and usually ends up predicting values around the mean to balance between under- and over-predictions. However, this level of prediction is often not very useful as a single point and more often done by in a time series setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetSales              760.558808\n",
       "pred_baseline            791.043945\n",
       "pred_winsorized          508.281555\n",
       "pred_log1p_expm1         186.200281\n",
       "pred_hurdle              527.286811\n",
       "pred_hurdle_corrected    647.560493\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['TargetSales','pred_baseline','pred_winsorized','pred_log1p_expm1','pred_hurdle','pred_hurdle_corrected']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetSales              523264.460000\n",
       "pred_baseline            544238.250000\n",
       "pred_winsorized          349697.718750\n",
       "pred_log1p_expm1         128105.793618\n",
       "pred_hurdle              362773.326124\n",
       "pred_hurdle_corrected    445521.619008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['TargetSales','pred_baseline','pred_winsorized','pred_log1p_expm1','pred_hurdle','pred_hurdle_corrected']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
