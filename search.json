[
  {
    "objectID": "notebook/sales_prediction.html",
    "href": "notebook/sales_prediction.html",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "",
    "text": "This notebook details how to predict a real-number outcome that is zero-inflated and long/fat-tailed such as sales prediction in retail. We provide baseline regression, regression trained using winsorized outcome, regression trained on log(y+1) outcome, and hurdle regression with and without Duan’s method."
  },
  {
    "objectID": "notebook/sales_prediction.html#import",
    "href": "notebook/sales_prediction.html#import",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Import",
    "text": "Import\n\nimport pandas as pd\nimport numpy as np\nimport random\nfrom ucimlrepo import fetch_ucirepo \nimport boto3\nimport json\nfrom tqdm.auto import tqdm\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom autogluon.tabular import TabularDataset, TabularPredictor\nfrom sklearn.metrics import (\n    mean_squared_error, mean_absolute_error, r2_score, median_absolute_error,\n    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n)\n\nfrom scipy.stats import pearsonr, spearmanr, wasserstein_distance\nfrom statsmodels.stats.diagnostic import het_white\n\ndef calculate_regression_metrics(y_true, y_pred):\n    return {\n        'root_mean_squared_error': np.sqrt(mean_squared_error(y_true, y_pred)),\n        'mean_squared_error': mean_squared_error(y_true, y_pred),\n        'mean_absolute_error': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'pearsonr': pearsonr(y_true, y_pred)[0],  \n        'spearmanr': spearmanr(y_true, y_pred)[0],\n        'median_absolute_error': median_absolute_error(y_true, y_pred),\n        'earths_mover_distance': wasserstein_distance(y_true, y_pred)\n    }\n\ndef caluclate_classification_metrics(y_true, y_pred):\n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='weighted'),\n        'recall': recall_score(y_true, y_pred, average='weighted'),\n        'f1_score': f1_score(y_true, y_pred, average='weighted'),\n        'confusion_matrix': confusion_matrix(y_true, y_pred)\n    }\n\ndef string_to_yearmon(date):\n    date = date.split()\n    date = date[0].split('/') + date[1].split(':')\n    date = date[2] + '-' + date[0].zfill(2) #+ '-' + date[1].zfill(2) + ' ' + date[3].zfill(2) + ':' + date[4].zfill(2)\n    return date\n\ndef call_llama(system_prompt, input):\n    template = f\"\"\"&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;{system_prompt}&lt;&lt;/SYS&gt;&gt;{input}[/INST]\"\"\"\n    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n    body = json.dumps({\n        \"prompt\": template,\n        \"temperature\": 0.,\n        \"top_p\": 0.9,\n        \"max_gen_len\": 2048,\n    })\n    response = client.invoke_model(\n        body=body,\n        modelId='us.meta.llama3-2-90b-instruct-v1:0',\n        accept='application/json',\n        contentType='application/json'\n    )\n    response_body = json.loads(response['body'].read())\n    return response_body\n\ndef call_claude(system_prompt, input):\n    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n    body=json.dumps(\n        {\n            \"anthropic_version\": \"bedrock-2023-05-31\",\n            \"max_tokens\": 2048,\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt + '\\n' + input,\n                    }\n                    ]\n                }\n                ]\n        }  \n    )  \n\n    \n    response = client.invoke_model(body=body, \n                                   modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',\n                                   contentType='application/json',\n                                   accept='application/json')\n    response_body = json.loads(response.get('body').read())\n   \n    return response_body\n\nfrom sklearn.preprocessing import StandardScaler\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\nclass Winsorizer:\n    def __init__(self, cols, percentile=99):\n        self.cols = cols  # List of columns to apply winsorization to\n        self.percentile = percentile  # Percentile to define the outliers\n        self.lower_bounds = {}  # To store the lower quantiles\n        self.upper_bounds = {}  # To store the upper quantiles\n\n    def fit(self, df):\n        \"\"\"Fit the winsorizer to the data, remembering the quantiles.\"\"\"\n        for col in self.cols:\n            lower = df[col].quantile(1 - self.percentile / 100)\n            upper = df[col].quantile(self.percentile / 100)\n            self.lower_bounds[col] = lower\n            self.upper_bounds[col] = upper\n    \n    def transform(self, df):\n        \"\"\"Apply winsorization to a new DataFrame using the learned quantiles.\"\"\"\n        for col in self.cols:\n            lower = self.lower_bounds[col]\n            upper = self.upper_bounds[col]\n            df[col] = np.clip(df[col], lower, upper)\n        return df\n\n    def fit_transform(self, df):\n        \"\"\"Fit the model and apply winsorization to the same DataFrame.\"\"\"\n        self.fit(df)\n        return self.transform(df)\n\ndef calculate_vif(df, cols):\n    X = df[cols]\n    X_with_const = add_constant(X)  # Add constant for VIF calculation\n    vif_data = pd.DataFrame()\n    vif_data['feature'] = X_with_const.columns\n    vif_data['VIF'] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n    return vif_data\n\nimport seaborn as sns\nimport statsmodels.api as sm"
  },
  {
    "objectID": "notebook/sales_prediction.html#dataset",
    "href": "notebook/sales_prediction.html#dataset",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Dataset",
    "text": "Dataset\nWe use the UCI Online Retail dataset, which are transactions from a UK-based, non-store online retail from 2010-12-01 and 2011-12-09. We perform the following data processing:\n\nRemove transactions without CustomerID; from 541,909 to 406,829 transactions\nFilter out transactions where either UnitPrice or Quantity is less than zero; from 406,829 to 397,884 transactions\nFill in missing product Description with value UNKNOWN.\n\n\nonline_retail = fetch_ucirepo(id=352) \ntransaction_df = online_retail['data']['original']\ntransaction_df.shape\n\n(541909, 8)\n\n\n\n#create yearmon for train-valid split\ntransaction_df['yearmon'] = transaction_df.InvoiceDate.map(string_to_yearmon)\n\n#get rid of transactions without cid\ntransaction_df = transaction_df[~transaction_df.CustomerID.isna()].reset_index(drop=True)\n\n#fill in unknown descriptions\ntransaction_df.Description = transaction_df.Description.fillna('UNKNOWN')\n\n#convert customer id to string\ntransaction_df['CustomerID'] = transaction_df['CustomerID'].map(lambda x: str(int(x)))\n\ntransaction_df.shape\n\n(406829, 9)\n\n\n\n#check if still na\ntransaction_df.isna().mean()\n\nInvoiceNo      0.0\nStockCode      0.0\nDescription    0.0\nQuantity       0.0\nInvoiceDate    0.0\nUnitPrice      0.0\nCustomerID     0.0\nCountry        0.0\nyearmon        0.0\ndtype: float64\n\n\n\n#simplify by filtering unit price and quantity to be non-zero (get rid of discounts, cancellations, etc)\ntransaction_df = transaction_df[(transaction_df.UnitPrice&gt;0)&\\\n                                (transaction_df.Quantity&gt;0)].reset_index(drop=True)\n#add sales\ntransaction_df['Sales'] = transaction_df.UnitPrice * transaction_df.Quantity\ntransaction_df.shape\n\n(397884, 10)"
  },
  {
    "objectID": "notebook/sales_prediction.html#problem-formulation-and-outcome",
    "href": "notebook/sales_prediction.html#problem-formulation-and-outcome",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Problem Formulation and Outcome",
    "text": "Problem Formulation and Outcome\nWe formulate the problem as predicting the sales (TargetSales) during Q4 2011 for each customers who bought at least one item during Q1-Q3 2011. Note that we are interested in predicting the actual sales number per customer as accurately as possible; this is common for marketing use cases such as determining what spend threshold to give each customer in a promotion, targeting customers for upselling, or detecting early signs of churns.\nWe transform the transaction dataset into a customer-level dataset where we calculate features using transactions between 2011-01 to 2011-09 and outcome using transactions between 2011-10 to 2011-12, summing Quantity times UnitPrice. We left-join the customers in feature set to outcome set. This will result in the zero-inflated nature of the outcome as not all customers will come back in Q4. The distribution of non-zero sales is naturally long/fat-tailed with a few customers having extraordinarily high amount of sales in Q4. This resulted in a customer-level dataset with 3,438 customers.\n\nfeature_period = {'start': '2011-01', 'end': '2011-09'}\noutcome_period = {'start': '2011-10', 'end': '2011-12'}\n\nfeature_transaction = transaction_df[(transaction_df.yearmon&gt;=feature_period['start'])&\\\n                                      (transaction_df.yearmon&lt;=feature_period['end'])]\noutcome_transaction = transaction_df[(transaction_df.yearmon&gt;=outcome_period['start'])&\\\n                                      (transaction_df.yearmon&lt;=outcome_period['end'])]\nfeature_transaction.shape, outcome_transaction.shape\n\n((240338, 10), (131389, 10))\n\n\n\n#aggregate sales during outcome period\noutcome_sales = outcome_transaction.groupby('CustomerID').Sales.sum().reset_index()\noutcome_sales\n\n\n\n\n\n\n\n\nCustomerID\nSales\n\n\n\n\n0\n12347\n1519.14\n\n\n1\n12349\n1757.55\n\n\n2\n12352\n311.73\n\n\n3\n12356\n58.35\n\n\n4\n12357\n6207.67\n\n\n...\n...\n...\n\n\n2555\n18276\n335.86\n\n\n2556\n18277\n110.38\n\n\n2557\n18282\n77.84\n\n\n2558\n18283\n974.21\n\n\n2559\n18287\n1072.00\n\n\n\n\n2560 rows × 2 columns\n\n\n\n\n#aggregate sales during feature period\nfeature_sales = feature_transaction.groupby('CustomerID').Sales.sum().reset_index()\nfeature_sales\n\n\n\n\n\n\n\n\nCustomerID\nSales\n\n\n\n\n0\n12346\n77183.60\n\n\n1\n12347\n2079.07\n\n\n2\n12348\n904.44\n\n\n3\n12350\n334.40\n\n\n4\n12352\n2194.31\n\n\n...\n...\n...\n\n\n3433\n18280\n180.60\n\n\n3434\n18281\n80.82\n\n\n3435\n18282\n100.21\n\n\n3436\n18283\n1120.67\n\n\n3437\n18287\n765.28\n\n\n\n\n3438 rows × 2 columns\n\n\n\n\n#merge to get TargetSales including those who spent during feature period but not during outcome (zeroes)\noutcome_df = feature_sales[['CustomerID']].merge(outcome_sales, on='CustomerID', how='left')\noutcome_df['Sales'] = outcome_df['Sales'].fillna(0)\noutcome_df.columns = ['CustomerID', 'TargetSales']\noutcome_df\n\n\n\n\n\n\n\n\nCustomerID\nTargetSales\n\n\n\n\n0\n12346\n0.00\n\n\n1\n12347\n1519.14\n\n\n2\n12348\n0.00\n\n\n3\n12350\n0.00\n\n\n4\n12352\n311.73\n\n\n...\n...\n...\n\n\n3433\n18280\n0.00\n\n\n3434\n18281\n0.00\n\n\n3435\n18282\n77.84\n\n\n3436\n18283\n974.21\n\n\n3437\n18287\n1072.00\n\n\n\n\n3438 rows × 2 columns\n\n\n\n\n#confirm zero-inflated, long/fat-tailed\noutcome_df.TargetSales.describe(percentiles=[i/10 for i in range(10)])\n\ncount      3438.000000\nmean        666.245829\nstd        4016.843037\nmin           0.000000\n0%            0.000000\n10%           0.000000\n20%           0.000000\n30%           0.000000\n40%           0.000000\n50%         102.005000\n60%         263.006000\n70%         425.790000\n80%         705.878000\n90%        1273.611000\nmax      168469.600000\nName: TargetSales, dtype: float64\n\n\n\n#confirm zero-inflated, long/fat-tailed\noutcome_df[outcome_df.TargetSales&lt;=10_000].TargetSales.hist(bins=100)"
  },
  {
    "objectID": "notebook/sales_prediction.html#feature",
    "href": "notebook/sales_prediction.html#feature",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Feature",
    "text": "Feature\nWe represent a customer using traditional RFM features namely recency of purchase, purchase days, total sales, number of distinct products purchased, number of distinct category purchased, customer tenure within 2011, average purchase frequency, average purchase value, and percentage of purchase across all 9 categories. This is based on data from Q1-Q3 2011.\nSince the UCI Online Retail dataset does not have a category but only contains descriptions over 3,000 items, we use LLaMA 3.2 90B to infer categories based on randomly selected 1,000 descriptions. This is to make the category preference representation for each customer, which is more tractable than including features about all 3,000+ items. After that, we use the same model to label a category for each description. The categories are:\n\nHome Decor\nKitchen and Dining\nFashion Accessories\nStationary and Gifts\nToys and Games\nSeasonal and Holiday\nPersonal Care and Wellness\nOutdoor and Garden\nOthers\n\n\nClassify Description into Category\n\nfeature_transaction.Description.nunique()\n\n3548\n\n\n\nGet Category\n\ndescriptions = feature_transaction.Description.unique().tolist()\nprint(descriptions[:5])\n\n#randomize descriptions with seed 112 to get which categories we should use\nnp.random.seed(112)\nrandom_descriptions = np.random.choice(descriptions, 1000, replace=False)\nprint(random_descriptions[:5])\n\n['JUMBO BAG PINK POLKADOT', 'BLUE POLKADOT WRAP', 'RED RETROSPOT WRAP ', 'RECYCLING BAG RETROSPOT ', 'RED RETROSPOT SHOPPER BAG']\n['MODERN FLORAL STATIONERY SET' 'PURPLE BERTIE GLASS BEAD BAG CHARM'\n 'PARTY INVITES SPACEMAN' 'MONTANA DIAMOND CLUSTER EARRINGS'\n 'SKULLS  DESIGN  COTTON TOTE BAG']\n\n\n\n# res = call_llama(\n#     'You are a product categorization assistant at a retail website.',\n#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\\n'.join(random_descriptions)\n#     )\n\n# print(res['generation'])\n\n\n# res\n\n\n# res = call_claude(\n#     'You are a product categorization assistant at a retail website.',\n#     'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\\n'.join(random_descriptions)\n#     )\n\n# print(res['content'][0]['text'])\n\n\n# res\n\nLLaMA 3.2 90B Output:\n&lt;&lt;SYS&gt;&gt;Based on the product descriptions, I would categorize them into the following categories:\n\n1. Home Decor:\n    * Wall art\n    * Decorative items (e.g. vases, figurines, etc.)\n    * Lighting (e.g. candles, lanterns, etc.)\n    * Textiles (e.g. throw pillows, blankets, etc.)\n2. Kitchen and Dining:\n    * Cookware and utensils\n    * Tableware (e.g. plates, cups, etc.)\n    * Kitchen decor (e.g. signs, magnets, etc.)\n    * Food and drink items (e.g. tea, coffee, etc.)\n3. Fashion and Accessories:\n    * Jewelry (e.g. necklaces, earrings, etc.)\n    * Handbags and wallets\n    * Clothing and accessories (e.g. scarves, hats, etc.)\n4. Stationery and Gifts:\n    * Cards and gift wrap\n    * Stationery (e.g. notebooks, pens, etc.)\n    * Gift items (e.g. mugs, keychains, etc.)\n5. Toys and Games:\n    * Toys (e.g. stuffed animals, puzzles, etc.)\n    * Games and puzzles\n6. Seasonal and Holiday:\n    * Christmas decorations and gifts\n    * Easter decorations and gifts\n    * Other seasonal items (e.g. Halloween, etc.)\n7. Personal Care and Wellness:\n    * Beauty and personal care items (e.g. skincare, haircare, etc.)\n    * Wellness and self-care items (e.g. essential oils, etc.)\n8. Outdoor and Garden:\n    * Garden decor and accessories\n    * Outdoor furniture and decor\n    * Gardening tools and supplies\n\nNote that some products may fit into multiple categories, but I have assigned them to the one that seems most relevant.\nClaude 3.5 v2 Output\nBased on these product descriptions, I would suggest the following main product categories:\n\n1. Home Decor\n- Candle holders\n- Picture frames\n- Wall art & signs\n- Clocks\n- Cushions & covers\n- Storage items\n- Decorative objects\n\n2. Jewelry & Accessories\n- Necklaces\n- Bracelets\n- Earrings\n- Hair accessories\n- Bag charms\n- Key rings\n\n3. Garden & Outdoor\n- Plant pots\n- Garden tools\n- Outdoor decorations\n- Bird houses\n- Garden markers\n\n4. Kitchen & Dining\n- Tea sets\n- Mugs\n- Kitchen storage\n- Cutlery\n- Baking accessories\n- Tea towels\n\n5. Stationery & Paper Goods\n- Notebooks\n- Gift wrap\n- Cards\n- Paper decorations\n- Writing sets\n\n6. Party & Celebrations\n- Party supplies\n- Gift bags\n- Christmas decorations\n- Easter items\n- Birthday items\n\n7. Children's Items\n- Toys\n- Children's tableware\n- School supplies\n- Kids' accessories\n\n8. Fashion Accessories\n- Bags\n- Purses\n- Scarves\n- Travel accessories\n\n9. Bath & Beauty\n- Bathroom accessories\n- Toiletry bags\n- Beauty items\n\n10. Lighting\n- Lamps\n- String lights\n- Tea lights\n- Lanterns\n\nThese categories cover the main types of products in the list while providing logical groupings for customers to browse.\n\ncategories = [\n    'Home Decor',\n    'Kitchen and Dining',\n    'Fashion Accessories',\n    'Stationary and Gifts',\n    'Toys and Games',\n    'Seasonal and Holiday',\n    'Personal Care and Wellness',\n    'Outdoor and Garden',   \n]\n\nlen(categories)\n\n8\n\n\n\n\nAnnotate Category to Description\n\n# #loop through descriptions in batches of batch_size\n# res_texts = []\n# batch_size = 100\n# for i in tqdm(range(0, len(descriptions), batch_size)):\n#     batch = descriptions[i:i+batch_size]\n#     d = \"\\n\".join(batch)\n#     inp = f'''Categorize the following product descriptions into {\", \".join(categories)} or Others, if they do not fall into any. \n# Only answer in the following format:\n\n# \"product description of product #1\"|\"product category classified into\"\n# \"product description of product #2\"|\"product category classified into\"\n# ...\n# \"product description of product #n\"|\"product category classified into\"\n\n# Here are the product descriptions:\n# {d}\n# '''\n#     while True:\n#         res = call_claude('You are a product categorizer at a retail website', inp)\n#         # if res['generation_token_count'] &gt; 1: #for llama\n#         if res['usage']['output_tokens'] &gt; 1:\n#             break\n#         else:\n#             print('Retrying...')\n#             time.sleep(2)\n#     res_text = res['content'][0]['text'].strip().split('\\n')\n#         #for llama\n#         # .replace('[SYS]','').replace('&lt;&lt;SYS&gt;&gt;','')\\\n#         # .replace('[/SYS]','').replace('&lt;&lt;/SYS&gt;&gt;','')\\\n#     if res_text!='':\n#         res_texts.extend(res_text)\n\n\n# with open('../data/sales_prediction/product_description_category.csv','w') as f:\n#     f.write('\"product_description\"|\"category\"\\n')\n#     for i in res_texts:\n#         f.write(f'{i}\\n')\n\n\nproduct_description_category = pd.read_csv('../data/sales_prediction/product_description_category.csv',\n                                           sep='|')\n\n#clean product_description\nproduct_description_category['Description'] = descriptions\nproduct_description_category.category.value_counts(normalize=True)\n\ncategory\nHome Decor                    0.328636\nKitchen and Dining            0.195885\nFashion Accessories           0.138670\nStationary and Gifts          0.116122\nSeasonal and Holiday          0.087373\nPersonal Care and Wellness    0.047351\nToys and Games                0.045096\nOutdoor and Garden            0.032976\nOthers                        0.007892\nName: proportion, dtype: float64\n\n\n\nfeature_transaction_cat = feature_transaction.merge(product_description_category,\n                                                    how='inner',\n                                                    on = 'Description',)\nfeature_transaction.shape, feature_transaction_cat.shape\n\n((240338, 10), (240338, 12))\n\n\n\n\n\nRFM\n\n#convert invoice date to datetime\nfeature_transaction_cat['InvoiceDate'] = pd.to_datetime(feature_transaction_cat['InvoiceDate'])\n\n# last date in feature set\ncurrent_date = feature_transaction_cat['InvoiceDate'].max()\n\n#rfm\ncustomer_features = feature_transaction_cat.groupby('CustomerID').agg({\n    'InvoiceDate': [\n        ('recency', lambda x: (current_date - x.max()).days),\n        ('first_purchase_date', 'min'),\n        ('purchase_day', 'nunique'),\n    ],\n    'InvoiceNo': [('nb_invoice', 'nunique')],\n    'Sales': [\n        ('total_sales', 'sum')\n    ],\n    'StockCode': [('nb_product', 'nunique')],\n    'category': [('nb_category', 'nunique')]\n}).reset_index()\n\n# Flatten column names\ncustomer_features.columns = [\n    'CustomerID',\n    'recency',\n    'first_purchase_date',\n    'purchase_day',\n    'nb_invoice',\n    'total_sales',\n    'nb_product',\n    'nb_category'\n]\n\n\n#almost always one purchase a day\n(customer_features.purchase_day==customer_features.nb_invoice).mean()\n\n0.977021524141943\n\n\n\ncustomer_features['customer_lifetime'] = (current_date - customer_features['first_purchase_date']).dt.days\ncustomer_features['avg_purchase_frequency'] = customer_features['customer_lifetime'] / customer_features['purchase_day']\ncustomer_features['avg_purchase_value'] = customer_features['total_sales'] / customer_features['purchase_day']\n\n\n\nCategory Preference\n\n#category preference\ncategory_sales = feature_transaction_cat.pivot_table(\n    values='Sales', \n    index='CustomerID', \n    columns='category', \n    aggfunc='sum', \n    fill_value=0\n)\ncategory_sales.columns = [i.lower().replace(' ','_') for i in category_sales.columns]\ncustomer_features = customer_features.merge(category_sales, on='CustomerID', how='left')\n\ntotal_sales = customer_features['total_sales']\nfor col in category_sales.columns:\n    percentage_col = f'per_{col}'\n    customer_features[percentage_col] = customer_features[col] / total_sales\n\n\n#make sure the categories are not too sparse\n(customer_features.iloc[:,-9:]==0).mean()\n\nper_fashion_accessories           0.409831\nper_home_decor                    0.081734\nper_kitchen_and_dining            0.122455\nper_others                        0.765561\nper_outdoor_and_garden            0.507853\nper_personal_care_and_wellness    0.448226\nper_seasonal_and_holiday          0.369401\nper_stationary_and_gifts          0.305410\nper_toys_and_games                0.487202\ndtype: float64\n\n\n\n\nPutting Them All Together\n\nselected_features = [\n 'recency',\n 'purchase_day',\n 'total_sales',\n 'nb_product',\n 'nb_category',\n 'customer_lifetime',\n 'avg_purchase_frequency',\n 'avg_purchase_value',\n 'per_fashion_accessories',\n 'per_home_decor',\n 'per_kitchen_and_dining',\n 'per_others',\n 'per_outdoor_and_garden',\n 'per_personal_care_and_wellness',\n 'per_seasonal_and_holiday',\n 'per_stationary_and_gifts',\n 'per_toys_and_games']\n\noutcome_variable = 'TargetSales'\n\n\ncustomer_features = customer_features[[ 'CustomerID']+selected_features]\ncustomer_features.head()\n\n\n\n\n\n\n\n\nCustomerID\nrecency\npurchase_day\ntotal_sales\nnb_product\nnb_category\ncustomer_lifetime\navg_purchase_frequency\navg_purchase_value\nper_fashion_accessories\nper_home_decor\nper_kitchen_and_dining\nper_others\nper_outdoor_and_garden\nper_personal_care_and_wellness\nper_seasonal_and_holiday\nper_stationary_and_gifts\nper_toys_and_games\n\n\n\n\n0\n12346\n255\n1\n77183.60\n1\n1\n255\n255.000000\n77183.600000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n1\n12347\n59\n4\n2079.07\n65\n7\n247\n61.750000\n519.767500\n0.145834\n0.204168\n0.294021\n0.000000\n0.005628\n0.147614\n0.000000\n0.073013\n0.129721\n\n\n2\n12348\n5\n3\n904.44\n10\n4\n248\n82.666667\n301.480000\n0.000000\n0.000000\n0.000000\n0.132679\n0.000000\n0.825970\n0.018796\n0.022555\n0.000000\n\n\n3\n12350\n239\n1\n334.40\n17\n7\n239\n239.000000\n334.400000\n0.240431\n0.202751\n0.116926\n0.172548\n0.000000\n0.118421\n0.000000\n0.059211\n0.089713\n\n\n4\n12352\n2\n7\n2194.31\n47\n8\n226\n32.285714\n313.472857\n0.000000\n0.196531\n0.246187\n0.474090\n0.013535\n0.016680\n0.008066\n0.024404\n0.020508"
  },
  {
    "objectID": "notebook/sales_prediction.html#merge-features-and-outcome",
    "href": "notebook/sales_prediction.html#merge-features-and-outcome",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Merge Features and Outcome",
    "text": "Merge Features and Outcome\n\ncustomer_features.shape, outcome_df.shape\n\n((3438, 18), (3438, 2))\n\n\n\ndf = outcome_df.merge(customer_features, on='CustomerID').drop('CustomerID', axis=1)\ndf.shape\n\n(3438, 18)\n\n\n\n#correlations\ndf.iloc[:,1:].corr()\n\n\n\n\n\n\n\n\nrecency\npurchase_day\ntotal_sales\nnb_product\nnb_category\ncustomer_lifetime\navg_purchase_frequency\navg_purchase_value\nper_fashion_accessories\nper_home_decor\nper_kitchen_and_dining\nper_others\nper_outdoor_and_garden\nper_personal_care_and_wellness\nper_seasonal_and_holiday\nper_stationary_and_gifts\nper_toys_and_games\n\n\n\n\nrecency\n1.000000\n-0.299308\n-0.132344\n-0.287415\n-0.326772\n0.298853\n0.893973\n0.008823\n-0.020861\n0.022013\n0.057244\n-0.016069\n0.071268\n-0.082792\n-0.085681\n-0.017813\n-0.009686\n\n\npurchase_day\n-0.299308\n1.000000\n0.540253\n0.690345\n0.304621\n0.332109\n-0.331543\n0.027488\n0.030683\n0.018684\n0.025269\n0.004299\n-0.019992\n-0.035665\n-0.020392\n-0.045384\n-0.028187\n\n\ntotal_sales\n-0.132344\n0.540253\n1.000000\n0.400467\n0.137064\n0.156018\n-0.148762\n0.361138\n0.016511\n-0.013819\n0.047834\n0.006398\n-0.029353\n-0.011937\n-0.016724\n-0.029181\n-0.013139\n\n\nnb_product\n-0.287415\n0.690345\n0.400467\n1.000000\n0.555551\n0.265594\n-0.294923\n0.061039\n-0.003137\n-0.017516\n0.035615\n-0.006842\n-0.026371\n-0.005309\n-0.016586\n0.026716\n-0.010069\n\n\nnb_category\n-0.326772\n0.304621\n0.137064\n0.555551\n1.000000\n0.224232\n-0.321596\n0.019955\n0.004863\n-0.138372\n-0.039363\n0.055555\n0.041405\n0.075882\n0.015498\n0.152869\n0.111150\n\n\ncustomer_lifetime\n0.298853\n0.332109\n0.156018\n0.265594\n0.224232\n1.000000\n0.358431\n0.014933\n0.011220\n0.066111\n0.069175\n-0.019971\n0.029726\n-0.127865\n-0.120399\n-0.050320\n-0.036484\n\n\navg_purchase_frequency\n0.893973\n-0.331543\n-0.148762\n-0.294923\n-0.321596\n0.358431\n1.000000\n0.009157\n-0.016093\n0.027208\n0.037053\n-0.027413\n0.060369\n-0.070352\n-0.074799\n-0.000546\n-0.010612\n\n\navg_purchase_value\n0.008823\n0.027488\n0.361138\n0.061039\n0.019955\n0.014933\n0.009157\n1.000000\n-0.003187\n-0.056690\n0.076862\n0.015427\n-0.028884\n0.004225\n-0.000200\n-0.012729\n-0.002396\n\n\nper_fashion_accessories\n-0.020861\n0.030683\n0.016511\n-0.003137\n0.004863\n0.011220\n-0.016093\n-0.003187\n1.000000\n-0.254015\n-0.177775\n-0.010436\n-0.082834\n-0.038493\n-0.124719\n-0.068166\n-0.051486\n\n\nper_home_decor\n0.022013\n0.018684\n-0.013819\n-0.017516\n-0.138372\n0.066111\n0.027208\n-0.056690\n-0.254015\n1.000000\n-0.481983\n-0.155784\n-0.080637\n-0.158837\n-0.165964\n-0.262313\n-0.245759\n\n\nper_kitchen_and_dining\n0.057244\n0.025269\n0.047834\n0.035615\n-0.039363\n0.069175\n0.037053\n0.076862\n-0.177775\n-0.481983\n1.000000\n-0.013075\n-0.144698\n-0.117031\n-0.204235\n-0.173386\n-0.143931\n\n\nper_others\n-0.016069\n0.004299\n0.006398\n-0.006842\n0.055555\n-0.019971\n-0.027413\n0.015427\n-0.010436\n-0.155784\n-0.013075\n1.000000\n-0.062652\n0.014794\n-0.047940\n-0.033975\n-0.040421\n\n\nper_outdoor_and_garden\n0.071268\n-0.019992\n-0.029353\n-0.026371\n0.041405\n0.029726\n0.060369\n-0.028884\n-0.082834\n-0.080637\n-0.144698\n-0.062652\n1.000000\n-0.045639\n-0.077947\n-0.057297\n-0.001034\n\n\nper_personal_care_and_wellness\n-0.082792\n-0.035665\n-0.011937\n-0.005309\n0.075882\n-0.127865\n-0.070352\n0.004225\n-0.038493\n-0.158837\n-0.117031\n0.014794\n-0.045639\n1.000000\n-0.057926\n-0.025871\n-0.017022\n\n\nper_seasonal_and_holiday\n-0.085681\n-0.020392\n-0.016724\n-0.016586\n0.015498\n-0.120399\n-0.074799\n-0.000200\n-0.124719\n-0.165964\n-0.204235\n-0.047940\n-0.077947\n-0.057926\n1.000000\n-0.019418\n-0.042970\n\n\nper_stationary_and_gifts\n-0.017813\n-0.045384\n-0.029181\n0.026716\n0.152869\n-0.050320\n-0.000546\n-0.012729\n-0.068166\n-0.262313\n-0.173386\n-0.033975\n-0.057297\n-0.025871\n-0.019418\n1.000000\n0.172039\n\n\nper_toys_and_games\n-0.009686\n-0.028187\n-0.013139\n-0.010069\n0.111150\n-0.036484\n-0.010612\n-0.002396\n-0.051486\n-0.245759\n-0.143931\n-0.040421\n-0.001034\n-0.017022\n-0.042970\n0.172039\n1.000000\n\n\n\n\n\n\n\n\n#target and most predictive variable\ndf[df.TargetSales&lt;=25_000].plot.scatter(x='TargetSales',y='total_sales')"
  },
  {
    "objectID": "notebook/sales_prediction.html#train-test-splits",
    "href": "notebook/sales_prediction.html#train-test-splits",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Train-Test Splits",
    "text": "Train-Test Splits\nWe randomly split the dataset into train and test sets at 80/20 ratio. We also confirm the distribution of TargetSales is similar across percentiles and only different at the upper end.\n\n#split into train-valid sets\ntrain_df, test_df = train_test_split(df,\n                                      test_size=0.2, \n                                      random_state=112)\n\n\npd.concat([train_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),\ntest_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),], axis=1)\n\n\n\n\n\n\n\n\nindex\nTargetSales\nindex\nTargetSales\n\n\n\n\n0\ncount\n2750.000000\ncount\n688.000000\n\n\n1\nmean\n642.650436\nmean\n760.558808\n\n\n2\nstd\n4015.305436\nstd\n4024.524400\n\n\n3\nmin\n0.000000\nmin\n0.000000\n\n\n4\n0%\n0.000000\n0%\n0.000000\n\n\n5\n10%\n0.000000\n10%\n0.000000\n\n\n6\n20%\n0.000000\n20%\n0.000000\n\n\n7\n30%\n0.000000\n30%\n0.000000\n\n\n8\n40%\n0.000000\n40%\n0.000000\n\n\n9\n50%\n91.350000\n50%\n113.575000\n\n\n10\n60%\n260.308000\n60%\n277.836000\n\n\n11\n70%\n426.878000\n70%\n418.187000\n\n\n12\n80%\n694.164000\n80%\n759.582000\n\n\n13\n90%\n1272.997000\n90%\n1255.670000\n\n\n14\nmax\n168469.600000\nmax\n77099.380000"
  },
  {
    "objectID": "notebook/sales_prediction.html#baseline-regression",
    "href": "notebook/sales_prediction.html#baseline-regression",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Baseline Regression",
    "text": "Baseline Regression\nThe most naive solution is to predict TargetSales based on the features. We use a stacked ensemble of LightGBM, CatBoost, XGBoost, Random Forest and Extra Trees via AutoGluon. We train with good_quality preset, stated to be “Stronger than any other AutoML Framework”, for speedy training and inference but feel free to try more performant option. We exclude the neural-network models as they require further preprocessing of the features.\nWe use an industry-grade, non-parametric model to be as close to a real use case as possible and make a point that our methodology works not only in a toy-dataset setup.\n\npreset = 'good_quality'\n\n\npredictor = TabularPredictor(label='TargetSales').fit(train_df[selected_features + ['TargetSales']], \n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134505\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.9.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\nCPU Count:          64\nMemory Avail:       470.24 GB / 480.23 GB (97.9%)\nDisk Space Avail:   1451.64 GB / 1968.52 GB (73.7%)\n===================================================\nPresets specified: ['good_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nNote: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n    You can avoid this risk by setting `save_bag_folds=True`.\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n    Running DyStack for up to 900s of the 3600s of remaining time (25%).\n2024-12-14 13:45:05,288 INFO util.py:154 -- Outdated packages:\n  ipywidgets==7.6.5 found, needs ipywidgets&gt;=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n        Context path: \"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\"\nRunning DyStack sub-fit ...\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\"\nTrain Data Rows:    2444\nTrain Data Columns: 17\nLabel Column:       TargetSales\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    481515.82 MB\n    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.0s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.06s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.62s of the 899.66s of remaining time.\nWill use sequential fold fitting strategy because import of ray failed. Reason: ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3990.4801   = Validation score   (-root_mean_squared_error)\n    6.36s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 593.17s of the 893.2s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3921.7042   = Validation score   (-root_mean_squared_error)\n    5.31s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 587.75s of the 887.78s of remaining time.\n    -4516.1791   = Validation score   (-root_mean_squared_error)\n    0.89s    = Training   runtime\n    0.17s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 586.59s of the 886.62s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3857.3111   = Validation score   (-root_mean_squared_error)\n    10.49s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 575.99s of the 876.03s of remaining time.\n    -3900.3038   = Validation score   (-root_mean_squared_error)\n    0.66s    = Training   runtime\n    0.17s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 575.08s of the 875.11s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3941.3599   = Validation score   (-root_mean_squared_error)\n    6.1s     = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 568.89s of the 868.93s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3912.54     = Validation score   (-root_mean_squared_error)\n    12.28s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 856.55s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}\n    -3835.4224   = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 856.47s of the 856.47s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3941.7891   = Validation score   (-root_mean_squared_error)\n    4.54s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 851.87s of the 851.86s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 4314.99\n\n\n    -3894.7078   = Validation score   (-root_mean_squared_error)\n    5.58s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L2 ... Training model for up to 846.2s of the 846.19s of remaining time.\n    -4525.2057   = Validation score   (-root_mean_squared_error)\n    0.87s    = Training   runtime\n    0.17s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 845.08s of the 845.07s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3904.7749   = Validation score   (-root_mean_squared_error)\n    5.45s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 839.51s of the 839.5s of remaining time.\n    -3952.2022   = Validation score   (-root_mean_squared_error)\n    0.68s    = Training   runtime\n    0.17s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 838.57s of the 838.56s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3929.2019   = Validation score   (-root_mean_squared_error)\n    6.6s     = Training   runtime\n    0.04s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 831.87s of the 831.86s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3912.6409   = Validation score   (-root_mean_squared_error)\n    13.59s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 818.17s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}\n    -3823.1639   = Validation score   (-root_mean_squared_error)\n    0.03s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 81.64s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2283.2 rows/s (306 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.25s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.21s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.89s    = Training   runtime\n    0.17s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.6s     = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.66s    = Training   runtime\n    0.17s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.12s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.34s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.6, 'ExtraTreesMSE_BAG_L1': 0.36, 'LightGBM_BAG_L1': 0.04}\n    0.02s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    0.21s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    0.31s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.87s    = Training   runtime\n    0.17s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    0.17s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.68s    = Training   runtime\n    0.17s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.19s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    0.43s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.36, 'ExtraTreesMSE_BAG_L1': 0.32, 'LightGBM_BAG_L2': 0.32}\n    0.03s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 3.45s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134505/ds_sub_fit/sub_fit_ho\")\nDeleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                          model  score_holdout    score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0          CatBoost_BAG_L1_FULL    -803.899801 -3857.311112  root_mean_squared_error        0.006679            NaN  0.597072                 0.006679                     NaN           0.597072            1       True          4\n1      WeightedEnsemble_L2_FULL    -813.259482 -3835.422447  root_mean_squared_error        0.120649            NaN  1.485833                 0.002517                     NaN           0.018860            2       True          8\n2          CatBoost_BAG_L2_FULL    -838.233626 -3904.774934  root_mean_squared_error        0.258556            NaN  3.238374                 0.006184                     NaN           0.173173            2       True         12\n3   RandomForestMSE_BAG_L1_FULL    -847.825565 -4516.179095  root_mean_squared_error        0.113628       0.174859  0.894842                 0.113628                0.174859           0.894842            1       True          3\n4     ExtraTreesMSE_BAG_L2_FULL    -890.912998 -3952.202176  root_mean_squared_error        0.360469            NaN  3.743573                 0.108097                0.171160           0.678372            2       True         13\n5     ExtraTreesMSE_BAG_L1_FULL    -922.896541 -3900.303809  root_mean_squared_error        0.109015       0.173588  0.658955                 0.109015                0.173588           0.658955            1       True          5\n6      WeightedEnsemble_L3_FULL    -977.887954 -3823.163850  root_mean_squared_error        0.260014            NaN  3.409128                 0.003530                     NaN           0.031533            3       True         16\n7          LightGBM_BAG_L1_FULL   -1086.123687 -3921.704247  root_mean_squared_error        0.002438            NaN  0.210945                 0.002438                     NaN           0.210945            1       True          2\n8   RandomForestMSE_BAG_L2_FULL   -1090.066132 -4525.205744  root_mean_squared_error        0.349192            NaN  3.933684                 0.096820                0.174712           0.868483            2       True         11\n9        LightGBMXT_BAG_L1_FULL   -1230.340360 -3990.480139  root_mean_squared_error        0.002607            NaN  0.245293                 0.002607                     NaN           0.245293            1       True          1\n10       LightGBMXT_BAG_L2_FULL   -1234.815155 -3941.789134  root_mean_squared_error        0.255407            NaN  3.276018                 0.003035                     NaN           0.210817            2       True          9\n11    LightGBMLarge_BAG_L1_FULL   -1345.024278 -3912.540001  root_mean_squared_error        0.004740            NaN  0.335057                 0.004740                     NaN           0.335057            1       True          7\n12    LightGBMLarge_BAG_L2_FULL   -1640.347524 -3912.640942  root_mean_squared_error        0.262513            NaN  3.497248                 0.010141                     NaN           0.432046            2       True         15\n13         LightGBM_BAG_L2_FULL   -1743.255667 -3894.707823  root_mean_squared_error        0.256483            NaN  3.377595                 0.004111                     NaN           0.312394            2       True         10\n14          XGBoost_BAG_L1_FULL   -2245.433966 -3941.359884  root_mean_squared_error        0.013265            NaN  0.123036                 0.013265                     NaN           0.123036            1       True          6\n15          XGBoost_BAG_L2_FULL   -2454.083373 -3929.201875  root_mean_squared_error        0.267445            NaN  3.256454                 0.015073                     NaN           0.191253            2       True         14\n    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n    86s  = DyStack   runtime |  3514s    = Remaining runtime\nStarting main fit with num_stack_levels=0.\n    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\nBeginning AutoGluon training ... Time limit = 3514s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134505\"\nTrain Data Rows:    2750\nTrain Data Columns: 17\nLabel Column:       TargetSales\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    480433.27 MB\n    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.1s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.08s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 3513.91s of the 3513.9s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 9800.07\n[2000]  valid_set's rmse: 9792.42\n[3000]  valid_set's rmse: 9791.47\n\n\n    -3713.1197   = Validation score   (-root_mean_squared_error)\n    8.47s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 3505.33s of the 3505.33s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 9561.64\n[2000]  valid_set's rmse: 9538.68\n\n\n    -3635.1505   = Validation score   (-root_mean_squared_error)\n    6.15s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3499.08s of the 3499.08s of remaining time.\n    -4135.0334   = Validation score   (-root_mean_squared_error)\n    0.82s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 3497.99s of the 3497.99s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3669.0125   = Validation score   (-root_mean_squared_error)\n    18.54s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3479.34s of the 3479.34s of remaining time.\n    -3678.3921   = Validation score   (-root_mean_squared_error)\n    0.66s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 3478.41s of the 3478.41s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3785.5048   = Validation score   (-root_mean_squared_error)\n    5.79s    = Training   runtime\n    0.04s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3472.52s of the 3472.51s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -3704.5742   = Validation score   (-root_mean_squared_error)\n    11.91s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3460.51s of remaining time.\n    Ensemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}\n    -3608.5561   = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 53.55s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6308.2 rows/s (344 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.57s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.36s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.82s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.81s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.66s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.16s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.29s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'LightGBM_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.35, 'CatBoost_BAG_L1': 0.15}\n    0.02s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 2.49s ... Best model: \"WeightedEnsemble_L2_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134505\")\n\n\n\ntest_df['pred_baseline'] = predictor.predict(test_df[selected_features])\n\n\nmetric_baseline = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_baseline'])\nmetric_baseline['model'] = 'baseline'\nmetric_baseline\n\n{'root_mean_squared_error': 3162.478744240967,\n 'mean_squared_error': 10001271.807775924,\n 'mean_absolute_error': 715.6442657130541,\n 'r2': 0.3816166296854987,\n 'pearsonr': 0.6190719671013133,\n 'spearmanr': 0.47008461549340863,\n 'median_absolute_error': 232.98208312988282,\n 'earths_mover_distance': 287.77728784026124,\n 'model': 'baseline'}"
  },
  {
    "objectID": "notebook/sales_prediction.html#regression-on-winsorized-outcome",
    "href": "notebook/sales_prediction.html#regression-on-winsorized-outcome",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Regression on Winsorized Outcome",
    "text": "Regression on Winsorized Outcome\nOne possible approach to deal with long/fat-tailed outcome is to train on a winsorized outcome. This may lead to better performance when tested on a winsorized outcome but not so much on original outcome.\n\noutlier_per = 0.99\noutlier_cap_train = train_df['TargetSales'].quantile(outlier_per)\noutlier_cap_train\n\n7180.805199999947\n\n\n\n#winsorize\ntrain_df['TargetSales_win'] = train_df['TargetSales'].map(lambda x: outlier_cap_train if x&gt; outlier_cap_train else x)\ntest_df['TargetSales_win'] = test_df['TargetSales'].map(lambda x: outlier_cap_train if x&gt; outlier_cap_train else x)\n\n\npredictor = TabularPredictor(label='TargetSales_win').fit(train_df[selected_features+['TargetSales_win']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134727\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.9.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\nCPU Count:          64\nMemory Avail:       468.94 GB / 480.23 GB (97.6%)\nDisk Space Avail:   1451.56 GB / 1968.52 GB (73.7%)\n===================================================\nPresets specified: ['good_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nNote: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n    You can avoid this risk by setting `save_bag_folds=True`.\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n    Running DyStack for up to 900s of the 3600s of remaining time (25%).\n/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n        Context path: \"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\"\nRunning DyStack sub-fit ...\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\"\nTrain Data Rows:    2444\nTrain Data Columns: 17\nLabel Column:       TargetSales_win\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    480196.12 MB\n    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.1s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.07s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.8s of the 899.93s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -704.0735    = Validation score   (-root_mean_squared_error)\n    4.98s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 594.77s of the 894.89s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -700.8029    = Validation score   (-root_mean_squared_error)\n    4.27s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 590.42s of the 890.54s of remaining time.\n    -708.5579    = Validation score   (-root_mean_squared_error)\n    0.74s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 589.41s of the 889.53s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -682.2162    = Validation score   (-root_mean_squared_error)\n    6.8s     = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 582.52s of the 882.64s of remaining time.\n    -688.9972    = Validation score   (-root_mean_squared_error)\n    0.64s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 581.63s of the 881.75s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -710.5012    = Validation score   (-root_mean_squared_error)\n    5.15s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 576.4s of the 876.52s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -715.783     = Validation score   (-root_mean_squared_error)\n    16.49s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 859.93s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'XGBoost_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.05}\n    -677.7482    = Validation score   (-root_mean_squared_error)\n    0.03s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 859.84s of the 859.83s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -701.3347    = Validation score   (-root_mean_squared_error)\n    5.45s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 854.32s of the 854.31s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 622.335\n[2000]  valid_set's rmse: 619.896\n[3000]  valid_set's rmse: 619.36\n[4000]  valid_set's rmse: 619.228\n[5000]  valid_set's rmse: 619.165\n[6000]  valid_set's rmse: 619.15\n[7000]  valid_set's rmse: 619.144\n[8000]  valid_set's rmse: 619.142\n[9000]  valid_set's rmse: 619.14\n[10000] valid_set's rmse: 619.14\n\n\n    -669.5782    = Validation score   (-root_mean_squared_error)\n    16.28s   = Training   runtime\n    0.04s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L2 ... Training model for up to 837.9s of the 837.89s of remaining time.\n    -702.8194    = Validation score   (-root_mean_squared_error)\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 836.75s of the 836.74s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -679.668     = Validation score   (-root_mean_squared_error)\n    13.36s   = Training   runtime\n    0.03s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 823.27s of the 823.26s of remaining time.\n    -688.2802    = Validation score   (-root_mean_squared_error)\n    0.68s    = Training   runtime\n    0.17s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 822.32s of the 822.31s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -706.5666    = Validation score   (-root_mean_squared_error)\n    7.33s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 814.89s of the 814.88s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -701.7902    = Validation score   (-root_mean_squared_error)\n    15.1s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 799.67s of remaining time.\n    Ensemble Weights: {'LightGBM_BAG_L2': 0.632, 'CatBoost_BAG_L1': 0.158, 'ExtraTreesMSE_BAG_L1': 0.105, 'XGBoost_BAG_L1': 0.105}\n    -664.9152    = Validation score   (-root_mean_squared_error)\n    0.03s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 100.43s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1980.5 rows/s (306 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.32s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.23s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.74s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.29s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.64s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.08s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.82s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'XGBoost_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.05}\n    0.03s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    0.33s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    1.57s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    0.62s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.68s    = Training   runtime\n    0.17s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.24s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    0.68s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'LightGBM_BAG_L2': 0.632, 'CatBoost_BAG_L1': 0.158, 'ExtraTreesMSE_BAG_L1': 0.105, 'XGBoost_BAG_L1': 0.105}\n    0.03s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 5.9s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134727/ds_sub_fit/sub_fit_ho\")\nDeleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                          model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0           XGBoost_BAG_L2_FULL    -673.227470 -706.566643  root_mean_squared_error        0.261725            NaN  3.356293                 0.014406                     NaN           0.243477            2       True         14\n1          CatBoost_BAG_L2_FULL    -685.276375 -679.668006  root_mean_squared_error        0.253890            NaN  3.729317                 0.006571                     NaN           0.616501            2       True         12\n2     ExtraTreesMSE_BAG_L2_FULL    -686.432329 -688.280166  root_mean_squared_error        0.384582            NaN  3.796237                 0.137263                0.174881           0.683421            2       True         13\n3      WeightedEnsemble_L2_FULL    -687.292057 -677.748155  root_mean_squared_error        0.129074            NaN  1.357070                 0.002933                     NaN           0.026227            2       True          8\n4          CatBoost_BAG_L1_FULL    -688.830702 -682.216238  root_mean_squared_error        0.008315            NaN  0.291358                 0.008315                     NaN           0.291358            1       True          4\n5   RandomForestMSE_BAG_L2_FULL    -690.155342 -702.819447  root_mean_squared_error        0.358528            NaN  3.991187                 0.111209                0.176151           0.878371            2       True         11\n6     LightGBMLarge_BAG_L2_FULL    -699.457560 -701.790157  root_mean_squared_error        0.256358            NaN  3.792534                 0.009039                     NaN           0.679718            2       True         15\n7      WeightedEnsemble_L3_FULL    -699.646914 -664.915201  root_mean_squared_error        0.269660            NaN  4.711405                 0.004106                     NaN           0.030340            3       True         16\n8   RandomForestMSE_BAG_L1_FULL    -700.107179 -708.557877  root_mean_squared_error        0.111719       0.175315  0.737258                 0.111719                0.175315           0.737258            1       True          3\n9     ExtraTreesMSE_BAG_L1_FULL    -701.853556 -688.997247  root_mean_squared_error        0.105658       0.176891  0.644825                 0.105658                0.176891           0.644825            1       True          5\n10          XGBoost_BAG_L1_FULL    -717.776000 -710.501170  root_mean_squared_error        0.008964            NaN  0.078643                 0.008964                     NaN           0.078643            1       True          6\n11       LightGBMXT_BAG_L2_FULL    -723.560168 -701.334719  root_mean_squared_error        0.251497            NaN  3.444983                 0.004178                     NaN           0.332167            2       True          9\n12         LightGBM_BAG_L1_FULL    -726.112842 -700.802863  root_mean_squared_error        0.002110            NaN  0.227411                 0.002110                     NaN           0.227411            1       True          2\n13         LightGBM_BAG_L2_FULL    -728.829307 -669.578190  root_mean_squared_error        0.265554            NaN  4.681065                 0.018236                     NaN           1.568249            2       True         10\n14       LightGBMXT_BAG_L1_FULL    -733.594747 -704.073534  root_mean_squared_error        0.003205            NaN  0.316018                 0.003205                     NaN           0.316018            1       True          1\n15    LightGBMLarge_BAG_L1_FULL    -766.964045 -715.782974  root_mean_squared_error        0.007349            NaN  0.817303                 0.007349                     NaN           0.817303            1       True          7\n    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n    107s     = DyStack   runtime |  3493s    = Remaining runtime\nStarting main fit with num_stack_levels=0.\n    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\nBeginning AutoGluon training ... Time limit = 3493s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134727\"\nTrain Data Rows:    2750\nTrain Data Columns: 17\nLabel Column:       TargetSales_win\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    479639.42 MB\n    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.1s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.08s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 3492.88s of the 3492.88s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -710.5609    = Validation score   (-root_mean_squared_error)\n    5.2s     = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 3487.59s of the 3487.59s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -696.6213    = Validation score   (-root_mean_squared_error)\n    4.91s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3482.58s of the 3482.58s of remaining time.\n    -706.2702    = Validation score   (-root_mean_squared_error)\n    0.77s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 3481.53s of the 3481.53s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -668.1395    = Validation score   (-root_mean_squared_error)\n    8.92s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3472.5s of the 3472.5s of remaining time.\n    -688.8913    = Validation score   (-root_mean_squared_error)\n    0.62s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 3471.6s of the 3471.6s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -699.3326    = Validation score   (-root_mean_squared_error)\n    5.72s    = Training   runtime\n    0.04s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3465.77s of the 3465.77s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -714.8496    = Validation score   (-root_mean_squared_error)\n    14.1s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3451.57s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}\n    -667.3394    = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 41.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4132.1 rows/s (344 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.33s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.29s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.77s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.43s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.62s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.12s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.67s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.833, 'XGBoost_BAG_L1': 0.125, 'ExtraTreesMSE_BAG_L1': 0.042}\n    0.02s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 2.18s ... Best model: \"WeightedEnsemble_L2_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134727\")\n\n\n\ntest_df['pred_winsorized'] = predictor.predict(test_df[selected_features])\n\n\nmetric_winsorized = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_winsorized'])\nmetric_winsorized['model'] = 'winsorized'\nmetric_winsorized\n\n{'root_mean_squared_error': 3623.576377551195,\n 'mean_squared_error': 13130305.76394704,\n 'mean_absolute_error': 627.7880071099414,\n 'r2': 0.18814697894155963,\n 'pearsonr': 0.5757989413256978,\n 'spearmanr': 0.504301956183441,\n 'median_absolute_error': 219.62248107910156,\n 'earths_mover_distance': 432.1288432991232,\n 'model': 'winsorized'}\n\n\n\ncalculate_regression_metrics(test_df['TargetSales_win'], test_df['pred_winsorized'])\n\n{'root_mean_squared_error': 673.4846433338375,\n 'mean_squared_error': 453581.5648065064,\n 'mean_absolute_error': 376.77603327273135,\n 'r2': 0.6171771763549553,\n 'pearsonr': 0.7865724180212539,\n 'spearmanr': 0.504299950810919,\n 'median_absolute_error': 218.8311004638672,\n 'earths_mover_distance': 181.1168694619127}"
  },
  {
    "objectID": "notebook/sales_prediction.html#log1p-regression",
    "href": "notebook/sales_prediction.html#log1p-regression",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Log1p Regression",
    "text": "Log1p Regression\nLog transformation handles long/fat-tailed distribution and is especially useful for certain models since the transformed distribution is roughly normal. However, it cannot handle zero-valued outcome and oftentimes scientists end up adding 1 to the outcome (so often that numpy even has a function for it). This not only introduces bias to the prediction, but also does not solve the zero-inflation as it becomes one-inflation instead.\n\n#log\ntrain_df['TargetSales_log1p'] = train_df['TargetSales'].map(np.log1p)\ntest_df['TargetSales_log1p'] = test_df['TargetSales'].map(np.log1p)\n\n\n#from zero-inflated to one-inflated\ntrain_df['TargetSales_log1p'].hist()\n\n\n\n\n\n\n\n\n\npredictor = TabularPredictor(label='TargetSales_log1p').fit(train_df[selected_features+['TargetSales_log1p']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20241214_134958\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.9.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\nCPU Count:          64\nMemory Avail:       468.19 GB / 480.23 GB (97.5%)\nDisk Space Avail:   1451.46 GB / 1968.52 GB (73.7%)\n===================================================\nPresets specified: ['good_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nNote: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n    You can avoid this risk by setting `save_bag_folds=True`.\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n    Running DyStack for up to 900s of the 3600s of remaining time (25%).\n/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n        Context path: \"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\"\nRunning DyStack sub-fit ...\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\"\nTrain Data Rows:    2444\nTrain Data Columns: 17\nLabel Column:       TargetSales_log1p\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    479431.23 MB\n    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.0s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.06s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.81s of the 899.94s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.7823  = Validation score   (-root_mean_squared_error)\n    4.54s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 595.21s of the 895.34s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8135  = Validation score   (-root_mean_squared_error)\n    3.9s     = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 591.22s of the 891.35s of remaining time.\n    -2.8314  = Validation score   (-root_mean_squared_error)\n    0.8s     = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 590.14s of the 890.26s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.7808  = Validation score   (-root_mean_squared_error)\n    5.75s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 584.28s of the 884.41s of remaining time.\n    -2.8158  = Validation score   (-root_mean_squared_error)\n    0.68s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 583.31s of the 883.44s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8362  = Validation score   (-root_mean_squared_error)\n    5.3s     = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 577.92s of the 878.05s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8628  = Validation score   (-root_mean_squared_error)\n    12.04s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 865.92s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.478, 'LightGBMXT_BAG_L1': 0.435, 'ExtraTreesMSE_BAG_L1': 0.087}\n    -2.7756  = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 865.86s of the 865.85s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 2.69718\n[2000]  valid_set's rmse: 2.65909\n[3000]  valid_set's rmse: 2.65127\n[4000]  valid_set's rmse: 2.64831\n[5000]  valid_set's rmse: 2.64686\n[6000]  valid_set's rmse: 2.64619\n[7000]  valid_set's rmse: 2.64592\n[8000]  valid_set's rmse: 2.64577\n[9000]  valid_set's rmse: 2.64574\n[10000] valid_set's rmse: 2.64573\n[1000]  valid_set's rmse: 2.69753\n[2000]  valid_set's rmse: 2.65357\n[3000]  valid_set's rmse: 2.64919\n[4000]  valid_set's rmse: 2.64645\n[5000]  valid_set's rmse: 2.64479\n[6000]  valid_set's rmse: 2.64422\n[7000]  valid_set's rmse: 2.6439\n[8000]  valid_set's rmse: 2.64387\n[9000]  valid_set's rmse: 2.64384\n[10000] valid_set's rmse: 2.64383\n[1000]  valid_set's rmse: 2.71185\n[2000]  valid_set's rmse: 2.66777\n[3000]  valid_set's rmse: 2.65641\n[4000]  valid_set's rmse: 2.65399\n[5000]  valid_set's rmse: 2.65317\n[6000]  valid_set's rmse: 2.65306\n[7000]  valid_set's rmse: 2.65305\n[1000]  valid_set's rmse: 2.73753\n[2000]  valid_set's rmse: 2.69713\n[3000]  valid_set's rmse: 2.68365\n[4000]  valid_set's rmse: 2.67838\n[5000]  valid_set's rmse: 2.67756\n[6000]  valid_set's rmse: 2.67725\n[7000]  valid_set's rmse: 2.67727\n[1000]  valid_set's rmse: 2.51029\n[2000]  valid_set's rmse: 2.46542\n[3000]  valid_set's rmse: 2.45449\n[4000]  valid_set's rmse: 2.45128\n[5000]  valid_set's rmse: 2.44983\n[6000]  valid_set's rmse: 2.44947\n[7000]  valid_set's rmse: 2.44914\n[8000]  valid_set's rmse: 2.44909\n[9000]  valid_set's rmse: 2.4491\n[10000] valid_set's rmse: 2.44914\n\n\n    -2.6944  = Validation score   (-root_mean_squared_error)\n    52.47s   = Training   runtime\n    0.08s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 813.19s of the 813.18s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 2.64699\n[2000]  valid_set's rmse: 2.64384\n[3000]  valid_set's rmse: 2.64347\n[4000]  valid_set's rmse: 2.64345\n[1000]  valid_set's rmse: 2.6483\n[1000]  valid_set's rmse: 2.87823\n\n\n    -2.7598  = Validation score   (-root_mean_squared_error)\n    9.99s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L2 ... Training model for up to 803.1s of the 803.09s of remaining time.\n    -2.8088  = Validation score   (-root_mean_squared_error)\n    0.75s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 802.07s of the 802.06s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.759   = Validation score   (-root_mean_squared_error)\n    92.85s   = Training   runtime\n    0.04s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 709.08s of the 709.07s of remaining time.\n    -2.778   = Validation score   (-root_mean_squared_error)\n    0.66s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 708.14s of the 708.13s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.7901  = Validation score   (-root_mean_squared_error)\n    6.46s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 701.58s of the 701.57s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 2.76447\n[1000]  valid_set's rmse: 2.80146\n[2000]  valid_set's rmse: 2.8014\n[3000]  valid_set's rmse: 2.8014\n[4000]  valid_set's rmse: 2.8014\n[1000]  valid_set's rmse: 2.88446\n[2000]  valid_set's rmse: 2.88439\n\n\n    -2.7943  = Validation score   (-root_mean_squared_error)\n    45.94s   = Training   runtime\n    0.04s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 655.49s of remaining time.\n    Ensemble Weights: {'LightGBMXT_BAG_L2': 0.72, 'CatBoost_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.04, 'LightGBM_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n    -2.6854  = Validation score   (-root_mean_squared_error)\n    0.03s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 244.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1078.2 rows/s (306 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.23s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.17s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.8s     = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.21s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.68s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.08s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.37s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.478, 'LightGBMXT_BAG_L1': 0.435, 'ExtraTreesMSE_BAG_L1': 0.087}\n    0.02s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    4.94s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    0.76s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.75s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    3.03s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.66s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.16s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    3.93s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'LightGBMXT_BAG_L2': 0.72, 'CatBoost_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.04, 'LightGBM_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n    0.03s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 14.81s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134958/ds_sub_fit/sub_fit_ho\")\nDeleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0          CatBoost_BAG_L1_FULL      -2.885523  -2.780750  root_mean_squared_error        0.019700            NaN   0.210621                 0.019700                     NaN           0.210621            1       True          4\n1      WeightedEnsemble_L2_FULL      -2.894191  -2.775644  root_mean_squared_error        0.155056            NaN   1.140924                 0.002549                     NaN           0.019073            2       True          8\n2   RandomForestMSE_BAG_L2_FULL      -2.894937  -2.808770  root_mean_squared_error        0.407366            NaN   3.299085                 0.126307                0.179813           0.754930            2       True         11\n3     ExtraTreesMSE_BAG_L2_FULL      -2.896741  -2.777983  root_mean_squared_error        0.400050            NaN   3.203568                 0.118991                0.182625           0.659413            2       True         13\n4        LightGBMXT_BAG_L1_FULL      -2.908863  -2.782297  root_mean_squared_error        0.002410            NaN   0.229015                 0.002410                     NaN           0.229015            1       True          1\n5          CatBoost_BAG_L2_FULL      -2.922107  -2.759026  root_mean_squared_error        0.290997            NaN   5.576536                 0.009938                     NaN           3.032381            2       True         12\n6          LightGBM_BAG_L2_FULL      -2.931031  -2.759814  root_mean_squared_error        0.291885            NaN   3.309105                 0.010826                     NaN           0.764950            2       True         10\n7           XGBoost_BAG_L2_FULL      -2.938193  -2.790059  root_mean_squared_error        0.292573            NaN   2.701340                 0.011514                     NaN           0.157185            2       True         14\n8      WeightedEnsemble_L3_FULL      -2.942265  -2.685363  root_mean_squared_error        0.414771            NaN  12.371993                 0.005430                     NaN           0.029768            3       True         16\n9     ExtraTreesMSE_BAG_L1_FULL      -2.946022  -2.815757  root_mean_squared_error        0.130396       0.183574   0.682215                 0.130396                0.183574           0.682215            1       True          5\n10         LightGBM_BAG_L1_FULL      -2.953480  -2.813496  root_mean_squared_error        0.001765            NaN   0.174514                 0.001765                     NaN           0.174514            1       True          2\n11          XGBoost_BAG_L1_FULL      -2.972277  -2.836214  root_mean_squared_error        0.010018            NaN   0.076469                 0.010018                     NaN           0.076469            1       True          6\n12    LightGBMLarge_BAG_L2_FULL      -2.977587  -2.794323  root_mean_squared_error        0.327995            NaN   6.475816                 0.046936                     NaN           3.931662            2       True         15\n13  RandomForestMSE_BAG_L1_FULL      -2.985264  -2.831375  root_mean_squared_error        0.111768       0.181522   0.798739                 0.111768                0.181522           0.798739            1       True          3\n14       LightGBMXT_BAG_L2_FULL      -2.995407  -2.694352  root_mean_squared_error        0.340065            NaN   7.488428                 0.059006                     NaN           4.944273            2       True          9\n15    LightGBMLarge_BAG_L1_FULL      -3.050660  -2.862792  root_mean_squared_error        0.005002            NaN   0.372581                 0.005002                     NaN           0.372581            1       True          7\n    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n    260s     = DyStack   runtime |  3340s    = Remaining runtime\nStarting main fit with num_stack_levels=0.\n    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\nBeginning AutoGluon training ... Time limit = 3340s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_134958\"\nTrain Data Rows:    2750\nTrain Data Columns: 17\nLabel Column:       TargetSales_log1p\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    479126.25 MB\n    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.0s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.07s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 3339.69s of the 3339.68s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.7861  = Validation score   (-root_mean_squared_error)\n    5.11s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 3334.48s of the 3334.48s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8189  = Validation score   (-root_mean_squared_error)\n    4.72s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3329.67s of the 3329.67s of remaining time.\n    -2.8468  = Validation score   (-root_mean_squared_error)\n    0.72s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 3328.66s of the 3328.66s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.7963  = Validation score   (-root_mean_squared_error)\n    5.43s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3323.13s of the 3323.13s of remaining time.\n    -2.8191  = Validation score   (-root_mean_squared_error)\n    0.66s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 3322.18s of the 3322.18s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8365  = Validation score   (-root_mean_squared_error)\n    5.51s    = Training   runtime\n    0.04s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3316.57s of the 3316.57s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -2.8667  = Validation score   (-root_mean_squared_error)\n    12.3s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3304.17s of remaining time.\n    Ensemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}\n    -2.7845  = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 35.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6632.0 rows/s (344 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.21s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.19s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.72s    = Training   runtime\n    0.19s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.18s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.66s    = Training   runtime\n    0.19s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.09s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.41s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'LightGBMXT_BAG_L1': 0.714, 'CatBoost_BAG_L1': 0.143, 'ExtraTreesMSE_BAG_L1': 0.143}\n    0.02s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 1.41s ... Best model: \"WeightedEnsemble_L2_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_134958\")\n\n\n\ntest_df['pred_log1p'] = predictor.predict(test_df[selected_features])\ntest_df['pred_log1p_expm1'] = test_df['pred_log1p'].map(np.expm1)\n\n\nmetric_log1p = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_log1p_expm1'])\nmetric_log1p['model'] = 'log1p'\nmetric_log1p\n\n{'root_mean_squared_error': 3725.342295894091,\n 'mean_squared_error': 13878175.221577456,\n 'mean_absolute_error': 618.9768466651894,\n 'r2': 0.14190585634701047,\n 'pearsonr': 0.5817166874396966,\n 'spearmanr': 0.5338156315937898,\n 'median_absolute_error': 89.55495441784018,\n 'earths_mover_distance': 581.0494444960044,\n 'model': 'log1p'}\n\n\n\ncalculate_regression_metrics(test_df['TargetSales_log1p'], test_df['pred_log1p'])\n\n{'root_mean_squared_error': 2.720047847858299,\n 'mean_squared_error': 7.398660294638562,\n 'mean_absolute_error': 2.418601533469381,\n 'r2': 0.30252750020590236,\n 'pearsonr': 0.5507740732825224,\n 'spearmanr': 0.5338156315937898,\n 'median_absolute_error': 2.349368453025818,\n 'earths_mover_distance': 1.8552344547363062}"
  },
  {
    "objectID": "notebook/sales_prediction.html#hurdle-model",
    "href": "notebook/sales_prediction.html#hurdle-model",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Hurdle Model",
    "text": "Hurdle Model\nHurdle model is a two-stage approach that handles zero inflation by first having a classification model to predict if the outcome is zero or not, then a regression model, trained only on examples with actual non-zero outcomes, to fit a log-transformed outcome. When retransforming the predictions from log to non-log numbers, we perform correction of underestimation using Duan’s method. During inference time, we multiply the predictions from the classification and regression model.\n\nBinary Classification\n\ntrain_df['has_purchase'] = train_df.TargetSales.map(lambda x: 1 if x&gt;0 else 0)\ntest_df['has_purchase'] = test_df.TargetSales.map(lambda x: 1 if x&gt;0 else 0)\n\n\ntrain_df['has_purchase'].mean(), test_df['has_purchase'].mean()\n\n(0.5141818181818182, 0.5305232558139535)\n\n\n\npredictor_cls = TabularPredictor(label='has_purchase').fit(train_df[selected_features+['has_purchase']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20241214_135456\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.9.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\nCPU Count:          64\nMemory Avail:       467.88 GB / 480.23 GB (97.4%)\nDisk Space Avail:   1451.34 GB / 1968.52 GB (73.7%)\n===================================================\nPresets specified: ['good_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nNote: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n    You can avoid this risk by setting `save_bag_folds=True`.\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n    Running DyStack for up to 900s of the 3600s of remaining time (25%).\n/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n        Context path: \"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\"\nRunning DyStack sub-fit ...\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\"\nTrain Data Rows:    2444\nTrain Data Columns: 17\nLabel Column:       has_purchase\nProblem Type:       binary\nPreprocessing data ...\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    479111.52 MB\n    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.1s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.32 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.08s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 9 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.8s of the 899.92s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6944   = Validation score   (accuracy)\n    4.76s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 594.97s of the 895.09s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.687    = Validation score   (accuracy)\n    4.01s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini_BAG_L1 ... Training model for up to 590.87s of the 890.99s of remaining time.\n    0.6661   = Validation score   (accuracy)\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L1 ... Training model for up to 589.72s of the 889.84s of remaining time.\n    0.6543   = Validation score   (accuracy)\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 588.58s of the 888.7s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.698    = Validation score   (accuracy)\n    8.46s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 580.02s of the 880.14s of remaining time.\n    0.6731   = Validation score   (accuracy)\n    0.85s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 578.92s of the 879.04s of remaining time.\n    0.6751   = Validation score   (accuracy)\n    0.83s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 577.82s of the 877.94s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6874   = Validation score   (accuracy)\n    4.94s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 572.75s of the 872.87s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6739   = Validation score   (accuracy)\n    16.57s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 856.19s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 1.0}\n    0.698    = Validation score   (accuracy)\n    0.17s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 9 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 855.98s of the 855.97s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.7017   = Validation score   (accuracy)\n    4.74s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 851.17s of the 851.16s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.7062   = Validation score   (accuracy)\n    4.62s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini_BAG_L2 ... Training model for up to 846.46s of the 846.45s of remaining time.\n    0.6849   = Validation score   (accuracy)\n    0.86s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L2 ... Training model for up to 845.32s of the 845.31s of remaining time.\n    0.6845   = Validation score   (accuracy)\n    0.9s     = Training   runtime\n    0.18s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 844.16s of the 844.15s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.7074   = Validation score   (accuracy)\n    12.05s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 831.99s of the 831.98s of remaining time.\n    0.6845   = Validation score   (accuracy)\n    0.84s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 830.87s of the 830.86s of remaining time.\n    0.6796   = Validation score   (accuracy)\n    0.81s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 829.78s of the 829.77s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.7029   = Validation score   (accuracy)\n    5.77s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 823.88s of the 823.87s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.705    = Validation score   (accuracy)\n    17.18s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 806.57s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L2': 0.957, 'CatBoost_BAG_L1': 0.043}\n    0.7079   = Validation score   (accuracy)\n    0.34s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 93.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1613.2 rows/s (306 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.27s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.21s    = Training   runtime\nFitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.88s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.17s    = Training   runtime\nFitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.85s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.83s    = Training   runtime\n    0.19s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.1s     = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.93s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 1.0}\n    0.17s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    0.23s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    0.23s    = Training   runtime\nFitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.86s    = Training   runtime\n    0.18s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.9s     = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    0.58s    = Training   runtime\nFitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.84s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.81s    = Training   runtime\n    0.18s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.12s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    0.89s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L2': 0.957, 'CatBoost_BAG_L1': 0.043}\n    0.34s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 4.63s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_135456/ds_sub_fit/sub_fit_ho\")\nDeleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0           LightGBM_BAG_L1_FULL       0.699346   0.686989    accuracy        0.001600            NaN  0.208330                 0.001600                     NaN           0.208330            1       True          2\n1           CatBoost_BAG_L1_FULL       0.699346   0.698036    accuracy        0.003851            NaN  0.167360                 0.003851                     NaN           0.167360            1       True          5\n2       WeightedEnsemble_L2_FULL       0.699346   0.698036    accuracy        0.005369            NaN  0.340888                 0.001517                     NaN           0.173529            2       True         10\n3     ExtraTreesEntr_BAG_L1_FULL       0.692810   0.675123    accuracy        0.128038       0.188885  0.825164                 0.128038                0.188885           0.825164            1       True          7\n4         LightGBMXT_BAG_L2_FULL       0.692810   0.701718    accuracy        0.585924            NaN  5.335749                 0.003118                     NaN           0.228724            2       True         11\n5           CatBoost_BAG_L2_FULL       0.692810   0.707447    accuracy        0.588336            NaN  5.688442                 0.005529                     NaN           0.581416            2       True         15\n6       WeightedEnsemble_L3_FULL       0.692810   0.707856    accuracy        0.591025            NaN  6.027241                 0.002690                     NaN           0.338799            3       True         20\n7     ExtraTreesGini_BAG_L1_FULL       0.689542   0.673077    accuracy        0.135107       0.184615  0.849001                 0.135107                0.184615           0.849001            1       True          6\n8   RandomForestEntr_BAG_L1_FULL       0.683007   0.654255    accuracy        0.151755       0.179378  0.880783                 0.151755                0.179378           0.880783            1       True          4\n9   RandomForestGini_BAG_L2_FULL       0.679739   0.684943    accuracy        0.707727            NaN  5.968028                 0.124921                0.182446           0.861002            2       True         13\n10    ExtraTreesGini_BAG_L2_FULL       0.679739   0.684534    accuracy        0.714077            NaN  5.943708                 0.131271                0.187909           0.836683            2       True         16\n11          LightGBM_BAG_L2_FULL       0.676471   0.706219    accuracy        0.585907            NaN  5.337967                 0.003100                     NaN           0.230941            2       True         12\n12    ExtraTreesEntr_BAG_L2_FULL       0.676471   0.679624    accuracy        0.713373            NaN  5.920607                 0.130566                0.184792           0.813582            2       True         17\n13           XGBoost_BAG_L1_FULL       0.673203   0.687398    accuracy        0.010908            NaN  0.096438                 0.010908                     NaN           0.096438            1       True          8\n14           XGBoost_BAG_L2_FULL       0.673203   0.702946    accuracy        0.595513            NaN  5.224690                 0.012707                     NaN           0.117664            2       True         18\n15  RandomForestEntr_BAG_L2_FULL       0.673203   0.684534    accuracy        0.720246            NaN  6.002285                 0.137439                0.180509           0.895260            2       True         14\n16        LightGBMXT_BAG_L1_FULL       0.666667   0.694354    accuracy        0.002619            NaN  0.272291                 0.002619                     NaN           0.272291            1       True          1\n17     LightGBMLarge_BAG_L1_FULL       0.663399   0.673895    accuracy        0.007822            NaN  0.927927                 0.007822                     NaN           0.927927            1       True          9\n18  RandomForestGini_BAG_L1_FULL       0.660131   0.666121    accuracy        0.141106       0.181869  0.879733                 0.141106                0.181869           0.879733            1       True          3\n19     LightGBMLarge_BAG_L2_FULL       0.656863   0.704992    accuracy        0.593734            NaN  5.992391                 0.010928                     NaN           0.885365            2       True         19\n    0    = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n    100s     = DyStack   runtime |  3500s    = Remaining runtime\nStarting main fit with num_stack_levels=0.\n    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\nBeginning AutoGluon training ... Time limit = 3500s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_135456\"\nTrain Data Rows:    2750\nTrain Data Columns: 17\nLabel Column:       has_purchase\nProblem Type:       binary\nPreprocessing data ...\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    478823.35 MB\n    Train Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.1s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.07s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 9 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 3500.15s of the 3500.14s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6964   = Validation score   (accuracy)\n    4.26s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 3495.79s of the 3495.79s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6884   = Validation score   (accuracy)\n    4.1s     = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini_BAG_L1 ... Training model for up to 3491.61s of the 3491.6s of remaining time.\n    0.6615   = Validation score   (accuracy)\n    0.89s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3490.43s of the 3490.43s of remaining time.\n    0.6644   = Validation score   (accuracy)\n    0.84s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 3489.34s of the 3489.34s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6935   = Validation score   (accuracy)\n    7.5s     = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3481.73s of the 3481.73s of remaining time.\n    0.6738   = Validation score   (accuracy)\n    0.83s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3480.63s of the 3480.62s of remaining time.\n    0.6716   = Validation score   (accuracy)\n    0.85s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 3479.5s of the 3479.49s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6789   = Validation score   (accuracy)\n    5.27s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3474.1s of the 3474.1s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.6738   = Validation score   (accuracy)\n    17.2s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3456.77s of remaining time.\n    Ensemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n    0.6964   = Validation score   (accuracy)\n    0.18s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 43.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 43309.0 rows/s (344 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.19s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.21s    = Training   runtime\nFitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.89s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.84s    = Training   runtime\n    0.19s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.1s     = Training   runtime\nFitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.83s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.85s    = Training   runtime\n    0.19s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.12s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.93s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n    0.18s    = Training   runtime\nUpdated best model to \"LightGBMXT_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBMXT_BAG_L1_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 2.02s ... Best model: \"LightGBMXT_BAG_L1_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_135456\")\n\n\n\ntest_df['pred_binary'] = predictor_cls.predict(test_df[selected_features])\n\n\ncaluclate_classification_metrics(test_df['has_purchase'], test_df['pred_binary'])\n\n{'accuracy': 0.6918604651162791,\n 'precision': 0.6941069004479309,\n 'recall': 0.6918604651162791,\n 'f1_score': 0.6921418829824787,\n 'confusion_matrix': array([[229,  94],\n        [118, 247]])}\n\n\n\n\nRegression on Non-Zero Outcome\n\ntrain_df_nonzero = train_df[train_df.has_purchase==1].reset_index(drop=True)\ntest_df_nonzero = test_df[test_df.has_purchase==1].reset_index(drop=True)\n\ntrain_df_nonzero.shape, test_df_nonzero.shape\n\n((1414, 21), (365, 31))\n\n\n\n#log\ntrain_df_nonzero['TargetSales_log'] = train_df_nonzero['TargetSales'].map(np.log)\ntest_df_nonzero['TargetSales_log'] = test_df_nonzero['TargetSales'].map(np.log)\n\n\ntrain_df_nonzero['TargetSales_log'].hist()\n\n\n\n\n\n\n\n\n\npredictor_reg = TabularPredictor(label='TargetSales_log').fit(train_df_nonzero[selected_features+['TargetSales_log']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20241214_161346\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.9.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\nCPU Count:          64\nMemory Avail:       466.78 GB / 480.23 GB (97.2%)\nDisk Space Avail:   1450.75 GB / 1968.52 GB (73.7%)\n===================================================\nPresets specified: ['good_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nNote: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n    You can avoid this risk by setting `save_bag_folds=True`.\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n    This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n    Running DyStack for up to 900s of the 3600s of remaining time (25%).\n/home/charipol/miniconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.40.0 detected. 2.10.0 &lt;= ray &lt; 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n        Context path: \"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\"\nRunning DyStack sub-fit ...\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\"\nTrain Data Rows:    1256\nTrain Data Columns: 17\nLabel Column:       TargetSales_log\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    477983.00 MB\n    Train Data (Original)  Memory Usage: 0.16 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.0s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.05s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.81s of the 899.94s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7829  = Validation score   (-root_mean_squared_error)\n    5.83s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 593.9s of the 894.03s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7864  = Validation score   (-root_mean_squared_error)\n    5.68s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 588.14s of the 888.27s of remaining time.\n    -0.8046  = Validation score   (-root_mean_squared_error)\n    0.7s     = Training   runtime\n    0.15s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 587.17s of the 887.3s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7747  = Validation score   (-root_mean_squared_error)\n    7.49s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 579.61s of the 879.74s of remaining time.\n    -0.7815  = Validation score   (-root_mean_squared_error)\n    0.62s    = Training   runtime\n    0.15s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 578.75s of the 878.88s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7865  = Validation score   (-root_mean_squared_error)\n    5.41s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 573.25s of the 873.38s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 0.732165\n[2000]  valid_set's rmse: 0.730646\n[3000]  valid_set's rmse: 0.730279\n[4000]  valid_set's rmse: 0.730248\n[5000]  valid_set's rmse: 0.730238\n[6000]  valid_set's rmse: 0.730238\n[7000]  valid_set's rmse: 0.730238\n\n\n    -0.8114  = Validation score   (-root_mean_squared_error)\n    42.21s   = Training   runtime\n    0.03s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 831.05s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.455, 'ExtraTreesMSE_BAG_L1': 0.227, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.136}\n    -0.7698  = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 830.98s of the 830.98s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7955  = Validation score   (-root_mean_squared_error)\n    5.59s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 825.34s of the 825.33s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 0.776795\n\n\n    -0.7972  = Validation score   (-root_mean_squared_error)\n    7.51s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L2 ... Training model for up to 817.73s of the 817.72s of remaining time.\n    -0.8017  = Validation score   (-root_mean_squared_error)\n    0.67s    = Training   runtime\n    0.15s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 816.81s of the 816.8s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7824  = Validation score   (-root_mean_squared_error)\n    5.55s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 811.18s of the 811.18s of remaining time.\n    -0.7873  = Validation score   (-root_mean_squared_error)\n    0.61s    = Training   runtime\n    0.15s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 810.31s of the 810.3s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.8012  = Validation score   (-root_mean_squared_error)\n    6.75s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 803.46s of the 803.45s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.8115  = Validation score   (-root_mean_squared_error)\n    15.94s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 787.41s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.412, 'ExtraTreesMSE_BAG_L1': 0.176, 'LightGBM_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'XGBoost_BAG_L2': 0.118, 'LightGBM_BAG_L2': 0.059}\n    -0.7689  = Validation score   (-root_mean_squared_error)\n    0.03s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 112.67s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 945.3 rows/s (157 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.43s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.4s     = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.7s     = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.38s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.62s    = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.13s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    3.38s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.455, 'ExtraTreesMSE_BAG_L1': 0.227, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.136}\n    0.02s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    0.4s     = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    0.61s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.67s    = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    0.2s     = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.61s    = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.3s     = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    0.84s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.412, 'ExtraTreesMSE_BAG_L1': 0.176, 'LightGBM_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'XGBoost_BAG_L2': 0.118, 'LightGBM_BAG_L2': 0.059}\n    0.03s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 7.83s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_161346/ds_sub_fit/sub_fit_ho\")\nDeleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0     ExtraTreesMSE_BAG_L1_FULL      -0.839346  -0.781522  root_mean_squared_error        0.130818       0.146218  0.616536                 0.130818                0.146218           0.616536            1       True          5\n1     ExtraTreesMSE_BAG_L2_FULL      -0.853589  -0.787303  root_mean_squared_error        0.446297            NaN  6.640192                 0.132555                0.153409           0.613806            2       True         13\n2      WeightedEnsemble_L3_FULL      -0.857556  -0.768871  root_mean_squared_error        0.340568            NaN  6.967287                 0.005255                     NaN           0.026960            3       True         16\n3   RandomForestMSE_BAG_L1_FULL      -0.861175  -0.804629  root_mean_squared_error        0.122124       0.147519  0.702981                 0.122124                0.147519           0.702981            1       True          3\n4      WeightedEnsemble_L2_FULL      -0.862117  -0.769820  root_mean_squared_error        0.157042            NaN  1.533079                 0.004246                     NaN           0.017303            2       True          8\n5        LightGBMXT_BAG_L1_FULL      -0.864283  -0.782882  root_mean_squared_error        0.002461            NaN  0.427038                 0.002461                     NaN           0.427038            1       True          1\n6          CatBoost_BAG_L2_FULL      -0.866735  -0.782409  root_mean_squared_error        0.322393            NaN  6.225857                 0.008651                     NaN           0.199471            2       True         12\n7   RandomForestMSE_BAG_L2_FULL      -0.867588  -0.801697  root_mean_squared_error        0.442486            NaN  6.695999                 0.128743                0.152188           0.669613            2       True         11\n8        LightGBMXT_BAG_L2_FULL      -0.867632  -0.795484  root_mean_squared_error        0.317761            NaN  6.431228                 0.004019                     NaN           0.404842            2       True          9\n9           XGBoost_BAG_L2_FULL      -0.867990  -0.801243  root_mean_squared_error        0.327944            NaN  6.329812                 0.014201                     NaN           0.303426            2       True         14\n10         LightGBM_BAG_L2_FULL      -0.869884  -0.797155  root_mean_squared_error        0.321112            NaN  6.636901                 0.007370                     NaN           0.610516            2       True         10\n11         LightGBM_BAG_L1_FULL      -0.872511  -0.786431  root_mean_squared_error        0.001978            NaN  0.396514                 0.001978                     NaN           0.396514            1       True          2\n12         CatBoost_BAG_L1_FULL      -0.876613  -0.774745  root_mean_squared_error        0.007943            NaN  0.375822                 0.007943                     NaN           0.375822            1       True          4\n13          XGBoost_BAG_L1_FULL      -0.908105  -0.786510  root_mean_squared_error        0.012056            NaN  0.126903                 0.012056                     NaN           0.126903            1       True          6\n14    LightGBMLarge_BAG_L2_FULL      -0.929002  -0.811482  root_mean_squared_error        0.322513            NaN  6.862701                 0.008771                     NaN           0.836315            2       True         15\n15    LightGBMLarge_BAG_L1_FULL      -0.943116  -0.811385  root_mean_squared_error        0.036361            NaN  3.380592                 0.036361                     NaN           3.380592            1       True          7\n    1    = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n    121s     = DyStack   runtime |  3479s    = Remaining runtime\nStarting main fit with num_stack_levels=1.\n    For future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\nBeginning AutoGluon training ... Time limit = 3479s\nAutoGluon will save models to \"AutogluonModels/ag-20241214_161346\"\nTrain Data Rows:    1414\nTrain Data Columns: 17\nLabel Column:       TargetSales_log\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    478011.59 MB\n    Train Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('float', []) : 12 | ['total_sales', 'avg_purchase_frequency', 'avg_purchase_value', 'per_fashion_accessories', 'per_home_decor', ...]\n        ('int', [])   :  5 | ['recency', 'purchase_day', 'nb_product', 'nb_category', 'customer_lifetime']\n    0.0s = Fit runtime\n    17 features in original data used to generate 17 features in processed data.\n    Train Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.06s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n    This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L1 models ...\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 2318.53s of the 3478.66s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7909  = Validation score   (-root_mean_squared_error)\n    5.92s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 2312.52s of the 3472.65s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7919  = Validation score   (-root_mean_squared_error)\n    5.67s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L1 ... Training model for up to 2306.77s of the 3466.9s of remaining time.\n    -0.8074  = Validation score   (-root_mean_squared_error)\n    0.67s    = Training   runtime\n    0.15s    = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 2305.84s of the 3465.97s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.783   = Validation score   (-root_mean_squared_error)\n    6.6s     = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2299.16s of the 3459.29s of remaining time.\n    -0.7902  = Validation score   (-root_mean_squared_error)\n    0.6s     = Training   runtime\n    0.15s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 2298.3s of the 3458.44s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.8026  = Validation score   (-root_mean_squared_error)\n    5.14s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2293.07s of the 3453.2s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.8166  = Validation score   (-root_mean_squared_error)\n    14.87s   = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3438.24s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}\n    -0.78    = Validation score   (-root_mean_squared_error)\n    0.02s    = Training   runtime\n    0.0s     = Validation runtime\nExcluded models: ['NN_TORCH', 'FASTAI'] (Specified by `excluded_model_types`)\nFitting 7 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 3438.17s of the 3438.16s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 0.741321\n[2000]  valid_set's rmse: 0.735104\n[1000]  valid_set's rmse: 0.756407\n[1000]  valid_set's rmse: 0.712855\n\n\n    -0.7869  = Validation score   (-root_mean_squared_error)\n    9.95s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 3428.15s of the 3428.14s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7932  = Validation score   (-root_mean_squared_error)\n    6.95s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestMSE_BAG_L2 ... Training model for up to 3421.11s of the 3421.1s of remaining time.\n    -0.8097  = Validation score   (-root_mean_squared_error)\n    0.7s     = Training   runtime\n    0.15s    = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 3420.15s of the 3420.15s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.7847  = Validation score   (-root_mean_squared_error)\n    9.03s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 3411.04s of the 3411.04s of remaining time.\n    -0.795   = Validation score   (-root_mean_squared_error)\n    0.6s     = Training   runtime\n    0.15s    = Validation runtime\nFitting model: XGBoost_BAG_L2 ... Training model for up to 3410.19s of the 3410.18s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    -0.8102  = Validation score   (-root_mean_squared_error)\n    6.21s    = Training   runtime\n    0.04s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3403.88s of the 3403.87s of remaining time.\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n\n\n[1000]  valid_set's rmse: 0.75982\n[2000]  valid_set's rmse: 0.759573\n[1000]  valid_set's rmse: 0.838684\n[2000]  valid_set's rmse: 0.838386\n\n\n    -0.8107  = Validation score   (-root_mean_squared_error)\n    31.41s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3372.32s of remaining time.\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}\n    -0.7746  = Validation score   (-root_mean_squared_error)\n    0.04s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 106.52s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1175.2 rows/s (177 batch size)\nAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\nRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n    Models trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n    This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n    To learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBMXT_BAG_L1_FULL ...\n    0.43s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n    0.4s     = Training   runtime\nFitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.67s    = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_BAG_L1_FULL ...\n    0.29s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n    0.6s     = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_BAG_L1_FULL ...\n    0.09s    = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_BAG_L1_FULL ...\n    0.73s    = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.5, 'ExtraTreesMSE_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}\n    0.02s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMXT_BAG_L2_FULL ...\n    0.83s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBM_BAG_L2_FULL ...\n    0.54s    = Training   runtime\nFitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.7s     = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: CatBoost_BAG_L2_FULL ...\n    0.39s    = Training   runtime\nFitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n    0.6s     = Training   runtime\n    0.15s    = Validation runtime\nFitting 1 L2 models ...\nFitting model: XGBoost_BAG_L2_FULL ...\n    0.18s    = Training   runtime\nFitting 1 L2 models ...\nFitting model: LightGBMLarge_BAG_L2_FULL ...\n    2.46s    = Training   runtime\nFitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n    Ensemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMLarge_BAG_L2': 0.083}\n    0.04s    = Training   runtime\nUpdated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 7.11s ... Best model: \"WeightedEnsemble_L3_FULL\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241214_161346\")\n\n\n\ntest_df_nonzero['pred_log'] = predictor_reg.predict(test_df_nonzero[selected_features])\ntest_df_nonzero['pred_log_exp'] = test_df_nonzero['pred_log'].map(np.exp)\n\ntest_df['pred_log'] = predictor_reg.predict(test_df[selected_features])\ntest_df['pred_log_exp'] = test_df['pred_log'].map(np.exp)\n\n\ncalculate_regression_metrics(test_df_nonzero['TargetSales'], test_df_nonzero['pred_log_exp'])\n\n{'root_mean_squared_error': 4330.443144695726,\n 'mean_squared_error': 18752737.82944221,\n 'mean_absolute_error': 880.0418223064565,\n 'r2': 0.3647576298877435,\n 'pearsonr': 0.6756393928483335,\n 'spearmanr': 0.5762190201444638,\n 'median_absolute_error': 243.0658528752748,\n 'earths_mover_distance': 546.7166312173882}\n\n\n\ntest_df['pred_hurdle'] = test_df.pred_binary * test_df.pred_log_exp\n\n\nmetric_hurdle = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle'])\nmetric_hurdle['model'] = 'hurdle'\nmetric_hurdle\n\n{'root_mean_squared_error': 3171.760744960863,\n 'mean_squared_error': 10060066.22327469,\n 'mean_absolute_error': 584.9162934881963,\n 'r2': 0.3779813431428882,\n 'pearsonr': 0.6769697889999318,\n 'spearmanr': 0.5107083593715698,\n 'median_absolute_error': 199.1780137692856,\n 'earths_mover_distance': 286.381442541919,\n 'model': 'hurdle'}\n\n\n\n\nDuan’s Method\nWhen predicting a log-transformed outcome, we typically want to re-transform the predictions to non-log numbers by applying the exponential function. However, this ignores a small bias due to the error term in the process.\n\\[ln(y) = f(X) + \\epsilon\\]\nwhere * \\(y\\) is actual outcome. * \\(X\\) is the features. * \\(f(.)\\) is a trained model. * \\(\\epsilon\\) is the error term.\nwhen re-transforming \\[\n\\begin{align}\ny &= exp(ln(y)) \\\\\n&= exp(f(X) + \\epsilon ) \\\\\n&= exp(f(X)) \\cdot exp(\\epsilon) \\\\\nE[y] &= E[exp(f(X))] \\cdot E[exp(\\epsilon)]\n\\end{align}\n\\]\nDuan estimates the E[\\(exp(\\epsilon)\\)] as \\[\n\\begin{align}\n\\hat \\lambda &= E[exp(ln(y) - ln(\\hat y))]\n\\end{align}\n\\]\nwhere * \\(\\hat \\lambda\\) is the Duan’s smearing estimator of the bias from re-transformation \\(E[exp(\\epsilon)]\\) * \\(\\hat y\\) is the prediction aka \\(f(X)\\)\n\ntrain_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\ntrain_df_nonzero['pred_log_exp'] = train_df_nonzero['pred_log'].map(np.exp)\n\nsmearing_estimator = np.mean(np.exp(train_df_nonzero['TargetSales_log'] - train_df_nonzero['pred_log']))\nsmearing_estimator\n\n1.2280991653046711\n\n\n\nnp.exp(train_df_nonzero['TargetSales_log'] - train_df_nonzero['pred_log']).hist()\n\n\n\n\n\n\n\n\n\ntest_df['pred_log_exp_corrected'] = test_df['pred_log_exp'] * smearing_estimator\ntest_df['pred_hurdle_corrected'] = test_df.pred_binary * test_df.pred_log_exp_corrected\n\n\nmetric_hurdle_corrected = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected'])\nmetric_hurdle_corrected['model'] = 'hurdle_corrected'\nmetric_hurdle_corrected\n\n{'root_mean_squared_error': 3055.3207868281233,\n 'mean_squared_error': 9334985.110424023,\n 'mean_absolute_error': 613.3946643257099,\n 'r2': 0.42281345159207295,\n 'pearsonr': 0.6769697889999318,\n 'spearmanr': 0.5107083593715698,\n 'median_absolute_error': 232.55557358084502,\n 'earths_mover_distance': 241.61839859133218,\n 'model': 'hurdle_corrected'}\n\n\n\n\nAssumption on Independent and Identically Distributed Residuals\nBut not so fast, the formulation of Duan’s smearing estimator assumes that estimates of error terms (residuals) for log predictions be independent and identically distributed. Since we are dealing with individual customers, independence can be assumed. However, if we look at the plot of residuals vs predicted log values, we can see that they are not identically distributed.\n\n#plot residual and predicted log value\ntrain_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\ntrain_df_nonzero['residual_log'] = (train_df_nonzero['pred_log'] - train_df_nonzero['TargetSales_log'])\n\n# Create the scatter plot\nsns.scatterplot(x='pred_log', y='residual_log', data=train_df_nonzero)\n\n# Add the Lowess smoothing line\nsns.regplot(x='pred_log', y='residual_log', data=train_df_nonzero, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n\n\n\n\n\n\n\n\nAlthough note that White test does not reject the null hypothesis of the residuals being homoscedastic in reference to the features. This counterintuitive result might stem from the fact that White test is assuming linear or quadratic relationships between outcome and features while the residuals are derived from a stacked ensemble of decision trees.\n\nwhite_stat, white_p_value, _, _ = het_white(train_df_nonzero['residual_log'], \n                                            train_df_nonzero[selected_features])\nprint(f\"White Test Statistic: {white_stat}\")\nprint(f\"P-value: {white_p_value}\")\n\nWhite Test Statistic: 129.31318320644837\nP-value: 0.8761278601130765\n\n\nOur choice is to either trust the White test and pretend assume everything is fine; or trust our eyes and replace the non-zero regression model with one that produces iid residuals such as generalized least squares (GLS) with heteroscedasticity-robust standard errors. In order to satisfy the assumptions of GLS, we perform winsorization, standardization and verify multicollinearity among the features.\n\ntrain_df_nonzero_processed = train_df_nonzero.copy()\n\n#winsorize at 99%\nwinsorizer = Winsorizer(cols=selected_features, percentile=99)\nwinsorizer.fit(train_df_nonzero_processed)\ntrain_df_nonzero_processed = winsorizer.transform(train_df_nonzero_processed)\n\n#standard scaling\nscaler = StandardScaler()\nscaler.fit(train_df_nonzero_processed[selected_features])\ntrain_df_nonzero_processed[selected_features] = scaler.transform(train_df_nonzero_processed[selected_features])\n\n#check vif\nvif_data = calculate_vif(train_df_nonzero_processed, selected_features)\n\n# Print the VIF for each feature\nprint(vif_data)\n\n# Filter out features with high VIF (e.g., VIF &gt; 10 suggests multicollinearity)\nhigh_vif_features = vif_data[vif_data['VIF'] &gt; 10]\nprint(\"High VIF features:\", high_vif_features)\n\n                           feature        VIF\n0                            const   1.000000\n1                          recency   3.976800\n2                     purchase_day   6.193391\n3                      total_sales   5.837235\n4                       nb_product   2.386644\n5                      nb_category   2.691338\n6                customer_lifetime   2.271404\n7           avg_purchase_frequency   5.291575\n8               avg_purchase_value   2.449152\n9          per_fashion_accessories   5.826894\n10                  per_home_decor  15.806683\n11          per_kitchen_and_dining  12.053308\n12                      per_others   1.779531\n13          per_outdoor_and_garden   2.729103\n14  per_personal_care_and_wellness   2.908001\n15        per_seasonal_and_holiday   4.234883\n16        per_stationary_and_gifts   4.252687\n17              per_toys_and_games   3.185269\nHigh VIF features:                    feature        VIF\n10          per_home_decor  15.806683\n11  per_kitchen_and_dining  12.053308\n\n\n\n# Calculate VIF after dropping highly correlated features\nselected_features_no_corr = [i for i in selected_features if i!='per_kitchen_and_dining']\nvif_data = calculate_vif(train_df_nonzero_processed.drop('per_kitchen_and_dining',axis=1), \n                         selected_features_no_corr)\n\n# Print the VIF for each feature\nprint(vif_data)\n\n# Filter out features with high VIF (e.g., VIF &gt; 10 suggests multicollinearity)\nhigh_vif_features = vif_data[vif_data['VIF'] &gt; 10]\nprint(\"High VIF features:\", high_vif_features)\n\n                           feature       VIF\n0                            const  1.000000\n1                          recency  3.975755\n2                     purchase_day  6.193274\n3                      total_sales  5.835455\n4                       nb_product  2.355212\n5                      nb_category  2.238039\n6                customer_lifetime  2.265888\n7           avg_purchase_frequency  5.288665\n8               avg_purchase_value  2.447088\n9          per_fashion_accessories  1.271944\n10                  per_home_decor  1.642046\n11                      per_others  1.172240\n12          per_outdoor_and_garden  1.122673\n13  per_personal_care_and_wellness  1.141183\n14        per_seasonal_and_holiday  1.180130\n15        per_stationary_and_gifts  1.310125\n16              per_toys_and_games  1.198112\nHigh VIF features: Empty DataFrame\nColumns: [feature, VIF]\nIndex: []\n\n\n\ny = train_df_nonzero_processed['TargetSales_log']\nX = train_df_nonzero_processed[selected_features_no_corr]\nX = sm.add_constant(X)\n\ngls_model = sm.GLS(y, X)\ngls_results = gls_model.fit(cov_type='HC3')\n\n# 4. Print the summary of the regression\nprint(gls_results.summary())\n\n                            GLS Regression Results                            \n==============================================================================\nDep. Variable:        TargetSales_log   R-squared:                       0.460\nModel:                            GLS   Adj. R-squared:                  0.454\nMethod:                 Least Squares   F-statistic:                     75.24\nDate:                Sat, 14 Dec 2024   Prob (F-statistic):          2.27e-175\nTime:                        16:56:46   Log-Likelihood:                -1661.3\nNo. Observations:                1414   AIC:                             3357.\nDf Residuals:                    1397   BIC:                             3446.\nDf Model:                          16                                         \nCovariance Type:                  HC3                                         \n==================================================================================================\n                                     coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------------------\nconst                              6.3127      0.021    299.031      0.000       6.271       6.354\nrecency                            0.0054      0.047      0.114      0.909      -0.087       0.098\npurchase_day                       0.3697      0.046      7.977      0.000       0.279       0.460\ntotal_sales                        0.1438      0.049      2.905      0.004       0.047       0.241\nnb_product                        -0.0293      0.032     -0.929      0.353      -0.091       0.033\nnb_category                        0.1163      0.034      3.448      0.001       0.050       0.182\ncustomer_lifetime                 -0.0170      0.032     -0.524      0.600      -0.081       0.047\navg_purchase_frequency            -0.0103      0.052     -0.197      0.844      -0.113       0.092\navg_purchase_value                 0.3817      0.034     11.257      0.000       0.315       0.448\nper_fashion_accessories           -0.0216      0.030     -0.724      0.469      -0.080       0.037\nper_home_decor                    -0.0063      0.034     -0.188      0.851      -0.072       0.060\nper_others                        -0.0165      0.023     -0.706      0.480      -0.062       0.029\nper_outdoor_and_garden            -0.0397      0.022     -1.768      0.077      -0.084       0.004\nper_personal_care_and_wellness    -0.0042      0.025     -0.167      0.867      -0.054       0.045\nper_seasonal_and_holiday          -0.0796      0.025     -3.248      0.001      -0.128      -0.032\nper_stationary_and_gifts           0.0166      0.024      0.698      0.485      -0.030       0.063\nper_toys_and_games                -0.0230      0.026     -0.900      0.368      -0.073       0.027\n==============================================================================\nOmnibus:                      162.402   Durbin-Watson:                   2.022\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1272.986\nSkew:                           0.198   Prob(JB):                    3.75e-277\nKurtosis:                       7.631   Cond. No.                         6.59\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC3)\n\n\n\n#plot residual and predicted log value\ntrain_df_nonzero_processed['pred_log_gls'] = gls_results.predict(X).reset_index(drop=True)\ntrain_df_nonzero_processed['residual_log_gls'] = (train_df_nonzero_processed['pred_log_gls'] - train_df_nonzero_processed['TargetSales_log'])\ntrain_df_nonzero_processed.plot.scatter(x='pred_log_gls', y='residual_log_gls')\n\n\n\n\n\n\n\n\n\nwhite_stat, white_p_value, _, _ = het_white(train_df_nonzero_processed['residual_log_gls'], \n                                            X)\nprint(f\"White Test Statistic: {white_stat}\")\nprint(f\"P-value: {white_p_value}\")\n\nWhite Test Statistic: 135.0623196454856\nP-value: 0.8343390085729777\n\n\n\n#preprocess test set\ntest_df_processed = test_df.copy()\n\n#winsorize at 99%\ntest_df_processed = winsorizer.transform(test_df_processed)\n\n#standard scaling\ntest_df_processed[selected_features] = scaler.transform(test_df_processed[selected_features])\n\n#drop highly correlated features\ntest_df_processed = test_df_processed.drop('per_kitchen_and_dining', axis=1)\n\n#infer\nX_test = test_df_processed[selected_features_no_corr]\nX_test = sm.add_constant(X_test)\ntest_df_processed['pred_log_gls'] = gls_results.predict(X_test)\n\n\nsmearing_estimator_gls = np.mean(np.exp(train_df_nonzero_processed['TargetSales_log'] - train_df_nonzero_processed['pred_log_gls']))\nsmearing_estimator_gls\n\n1.8597808961776598\n\n\n\ntest_df['pred_log_exp_gls'] = test_df_processed['pred_log_gls'].map(np.exp)\n\ntest_df['pred_log_exp_gls_corrected'] = test_df['pred_log_exp_gls'] * smearing_estimator_gls\ntest_df['pred_hurdle_gls_corrected'] = test_df.pred_binary * test_df.pred_log_exp_gls_corrected\n\nmetric_hurdle_gls_corrected = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_gls_corrected'])\nmetric_hurdle_gls_corrected['model'] = 'hurdle_gls_corrected'\nmetric_hurdle_gls_corrected\n\n{'root_mean_squared_error': 5289.79271849163,\n 'mean_squared_error': 27981907.004607063,\n 'mean_absolute_error': 970.7645208697954,\n 'r2': -0.73013455627538,\n 'pearsonr': 0.7076845600551718,\n 'spearmanr': 0.5187878933164471,\n 'median_absolute_error': 339.03363694351526,\n 'earths_mover_distance': 556.014141615775,\n 'model': 'hurdle_gls_corrected'}"
  },
  {
    "objectID": "notebook/sales_prediction.html#evaluation",
    "href": "notebook/sales_prediction.html#evaluation",
    "title": "Predict Zero-inflated and Long/fat-tailed Outcomes",
    "section": "Evaluation",
    "text": "Evaluation\nWe can see that the hurdle_corrected method performs best across all metrics except for 1) mean absolute error where it performs about 5% worse than hurdle method without the correction and 2) median absolute error where it only performs better than baseline regression and 3) Spearman’s rank correlation where it underperforms log1p by 4%; correlations are tied between the two Hurdle methods by definition since we multiply Duan’s smearing estimator to hurdle predictions to get hurdle_corrected.\n\nmetric_df = pd.DataFrame([metric_baseline,\n                       metric_winsorized,\n                       metric_log1p,\n                       metric_hurdle,\n                       metric_hurdle_corrected,])\n\n\nrank_df = metric_df.copy()\nfor col in metric_df.columns.tolist()[:-1]:\n    if col in ['r2', 'pearsonr', 'spearmanr']:\n        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=False)\n    else:\n        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=True)\nrank_df = rank_df.drop(metric_df.columns.tolist()[:-1], axis=1)\nrank_df['avg_rank'] = rank_df.iloc[:,1:].mean(axis=1)\nrank_df.transpose()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\n\n\nroot_mean_squared_error_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\nmean_squared_error_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\nmean_absolute_error_rank\n5.0\n4.0\n3.0\n1.0\n2.0\n\n\nr2_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\npearsonr_rank\n3.0\n5.0\n4.0\n1.5\n1.5\n\n\nspearmanr_rank\n5.0\n4.0\n1.0\n2.5\n2.5\n\n\nmedian_absolute_error_rank\n5.0\n3.0\n1.0\n2.0\n4.0\n\n\nearths_mover_distance_rank\n3.0\n4.0\n5.0\n2.0\n1.0\n\n\navg_rank\n3.375\n4.0\n3.625\n2.25\n1.75\n\n\n\n\n\n\n\n\nmetric_df.transpose()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\nroot_mean_squared_error\n3162.478744\n3623.576378\n3725.342296\n3171.760745\n3055.320787\n\n\nmean_squared_error\n10001271.807776\n13130305.763947\n13878175.221577\n10060066.223275\n9334985.110424\n\n\nmean_absolute_error\n715.644266\n627.788007\n618.976847\n584.916293\n613.394664\n\n\nr2\n0.381617\n0.188147\n0.141906\n0.377981\n0.422813\n\n\npearsonr\n0.619072\n0.575799\n0.581717\n0.67697\n0.67697\n\n\nspearmanr\n0.470085\n0.504302\n0.533816\n0.510708\n0.510708\n\n\nmedian_absolute_error\n232.982083\n219.622481\n89.554954\n199.178014\n232.555574\n\n\nearths_mover_distance\n287.777288\n432.128843\n581.049444\n286.381443\n241.618399\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\n\n\n\n\n\n\n\n\nWhy hurdle Outperforms hurdle_corrected in MAE?\nDuan’s method adjusts for underestimation from retransformation of log outcome. This could lead to smaller extreme errors but more less extreme ones. We verify this hypothesis by comparing mean absolute error before and after transformation for errors originally under and over 99th percentile. We confirm that is the case for this problem.\n\nerr_hurdle = (test_df['TargetSales'] - test_df['pred_hurdle']).abs()\nerr_hurdle_corrected = (test_df['TargetSales'] - test_df['pred_hurdle_corrected']).abs()\n\n\nerr_hurdle.describe(percentiles=[.25, .5, .75, .9, .95, .99]) \n\ncount      688.000000\nmean       584.916293\nstd       3119.628924\nmin          0.000000\n25%          0.000000\n50%        199.178014\n75%        475.603446\n90%        862.530026\n95%       1237.540954\n99%       6763.777844\nmax      55731.205996\ndtype: float64\n\n\n\nerr_hurdle[err_hurdle&lt;6763.777844].mean(),\\\nerr_hurdle[err_hurdle&gt;6763.777844].mean(),\n\n(355.4918014848842, 22904.641872667555)\n\n\n\nerr_hurdle_corrected[err_hurdle&lt;6763.777844].mean(),\\\nerr_hurdle_corrected[err_hurdle&gt;6763.777844].mean(),\n\n(392.7718802742851, 22076.839798471465)\n\n\n\n\nWhy log1p Performs So Much Better than Others in MedAE?\nIt is for similar reasons that hurdle outperforms hurdle_corrected in MedAE; however, log1p performs twice better than other approaches (it also slightly outperforms hurdle models in Spearman’s rank correlation), especially the Hurdle models which should be modeling the non-zero outcomes in the same manner. This is because Hurdle models depend not only on the regression but the classification model. We can see that if the classification model were perfect (instead of the current f1 = 0.69), other metrics also improved but not nearly as drastic as MedAE and Spearman’s rank correlation.\n\ntest_df['pred_hurdle_corrected_perfect_cls'] = test_df.has_purchase * test_df.pred_log_exp_corrected\nmetric_hurdle_corrected_perfect_cls = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected_perfect_cls'])\nmetric_hurdle_corrected_perfect_cls['model'] = 'hurdle_corrected_perfect_cls'\n\nmetric_df2 = pd.DataFrame([metric_baseline,\n                       metric_winsorized,\n                       metric_log1p,\n                       metric_hurdle,\n                       metric_hurdle_corrected,\n                       metric_hurdle_corrected_perfect_cls,])\nmetric_df2.transpose()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\nroot_mean_squared_error\n3162.478744\n3623.576378\n3725.342296\n3171.760745\n3055.320787\n3030.854831\n\n\nmean_squared_error\n10001271.807776\n13130305.763947\n13878175.221577\n10060066.223275\n9334985.110424\n9186081.006625\n\n\nmean_absolute_error\n715.644266\n627.788007\n618.976847\n584.916293\n613.394664\n479.558294\n\n\nr2\n0.381617\n0.188147\n0.141906\n0.377981\n0.422813\n0.43202\n\n\npearsonr\n0.619072\n0.575799\n0.581717\n0.67697\n0.67697\n0.687639\n\n\nspearmanr\n0.470085\n0.504302\n0.533816\n0.510708\n0.510708\n0.929419\n\n\nmedian_absolute_error\n232.982083\n219.622481\n89.554954\n199.178014\n232.555574\n34.991964\n\n\nearths_mover_distance\n287.777288\n432.128843\n581.049444\n286.381443\n241.618399\n234.587018\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\nhurdle_corrected_perfect_cls\n\n\n\n\n\n\n\n\n\nWhy Baseline Regression Performs Best at Aggregate Level\nIf we look at aggregated mean or sum of actual sales vs predicted sales, baseline regression performs best by far. This is due to the fact that without any constraints a regressor only minimizes the MSE loss and usually ends up predicting values around the mean to balance between under- and over-predictions. However, this level of prediction is often not very useful as a single point and more often done by in a time series setup.\n\ntest_df[['TargetSales','pred_baseline','pred_winsorized','pred_log1p_expm1','pred_hurdle','pred_hurdle_corrected']].mean()\n\nTargetSales              760.558808\npred_baseline            791.043945\npred_winsorized          508.281555\npred_log1p_expm1         186.200281\npred_hurdle              527.286811\npred_hurdle_corrected    647.560493\ndtype: float64\n\n\n\ntest_df[['TargetSales','pred_baseline','pred_winsorized','pred_log1p_expm1','pred_hurdle','pred_hurdle_corrected']].sum()\n\nTargetSales              523264.460000\npred_baseline            544238.250000\npred_winsorized          349697.718750\npred_log1p_expm1         128105.793618\npred_hurdle              362773.326124\npred_hurdle_corrected    445521.619008\ndtype: float64"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Charin and I am a senior applied scientist at Amazon. My main focus is on estimating heterogeneity effects for customer targeting and personalization, using causal inference techniques and counterfactuals generated by large language models. This is a collection of technical writings I find useful."
  },
  {
    "objectID": "posts/sales_prediction/index.html",
    "href": "posts/sales_prediction/index.html",
    "title": "Predict How Much A Customer Will Spend",
    "section": "",
    "text": "I have spent nearly a decade as a data scientist in the retail sector, but I have been approaching customer spend predictions the wrong way until I attended Gregory M. Duncan’s lecture. Accurately predicting how much an individual customer will spend in the next X days enables key retail use cases such as personalized promotion (determine X in Buy-X-Get-Y), customer targeting for upselling (which customers have higher purchasing power), and early churn detection (customers do not spend as much as they should). What makes this problem particularly difficult is because the distribution of customer spending is both zero-inflated and long/fat-tailed. Intuitively, most customers who visit your store are not going to make a purchase and among those who do, there will be some super customers who purchase an outrageous amount more than the average customer. Some parametric models allow for zero-inflated outcomes such as Poisson, negative binomial, Conway-Maxwell-Poisson; however, they do not handle the long/fat-tailed explicitly. Even for non-parametric models such as decision tree ensembles, more resources (trees and splits) will be dedicated to separating zeros and handling outliers; this could lead to deterioration in performance. Using the real-world dataset UCI Online Retail, we will compare the performance of common approaches namely naive baseline regression, regression on winsorized outcome, regression on log-plus-one-transformed outcome to what Duncan suggested: hurdle model with Duan’s method. We will demonstrate why this approach outperforms the others in most evaluation metrics and why it might not in some.\nCode\nimport pandas as pd\nimport numpy as np\nimport random\nfrom ucimlrepo import fetch_ucirepo \nimport boto3\nimport json\nfrom tqdm.auto import tqdm\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom autogluon.tabular import TabularDataset, TabularPredictor\nimport seaborn as sns\n\n\nfrom sklearn.metrics import (\n    mean_squared_error, mean_absolute_error, r2_score, median_absolute_error,\n    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n)\nfrom scipy.stats import pearsonr, spearmanr, wasserstein_distance\nfrom statsmodels.stats.diagnostic import het_white\n\ndef calculate_regression_metrics(y_true, y_pred):\n    return {\n        'root_mean_squared_error': np.sqrt(mean_squared_error(y_true, y_pred)),\n        'mean_squared_error': mean_squared_error(y_true, y_pred),\n        'mean_absolute_error': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'pearsonr': pearsonr(y_true, y_pred)[0],\n        'spearmanr': spearmanr(y_true, y_pred)[0],\n        'median_absolute_error': median_absolute_error(y_true, y_pred),\n        'earths_mover_distance': wasserstein_distance(y_true, y_pred)\n    }\n\ndef caluclate_classification_metrics(y_true, y_pred):\n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='weighted'),\n        'recall': recall_score(y_true, y_pred, average='weighted'),\n        'f1_score': f1_score(y_true, y_pred, average='weighted'),\n        'confusion_matrix': confusion_matrix(y_true, y_pred)\n    }\n\ndef string_to_yearmon(date):\n    date = date.split()\n    date = date[0].split('/') + date[1].split(':')\n    date = date[2] + '-' + date[0].zfill(2) #+ '-' + date[1].zfill(2) + ' ' + date[3].zfill(2) + ':' + date[4].zfill(2)\n    return date\n\ndef call_llama(system_prompt, input):\n    template = f\"\"\"&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;{system_prompt}&lt;&lt;/SYS&gt;&gt;{input}[/INST]\"\"\"\n    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n    body = json.dumps({\n        \"prompt\": template,\n        \"temperature\": 0.,\n        \"top_p\": 0.9,\n        \"max_gen_len\": 2048,\n    })\n    response = client.invoke_model(\n        body=body,\n        modelId='us.meta.llama3-2-90b-instruct-v1:0',\n        accept='application/json',\n        contentType='application/json'\n    )\n    response_body = json.loads(response['body'].read())\n    return response_body\n\ndef call_claude(system_prompt, input):\n    client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n    body=json.dumps(\n        {\n            \"anthropic_version\": \"bedrock-2023-05-31\",\n            \"max_tokens\": 2048,\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt + '\\n' + input,\n                    }\n                    ]\n                }\n                ]\n        }  \n    )  \n\n    \n    response = client.invoke_model(body=body, \n                                   modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',\n                                   contentType='application/json',\n                                   accept='application/json')\n    response_body = json.loads(response.get('body').read())\n   \n    return response_body"
  },
  {
    "objectID": "posts/sales_prediction/index.html#this-is-not-a-drill-real-world-datasets-meticulous-feature-engineering-state-of-the-art-automl",
    "href": "posts/sales_prediction/index.html#this-is-not-a-drill-real-world-datasets-meticulous-feature-engineering-state-of-the-art-automl",
    "title": "Predict How Much A Customer Will Spend",
    "section": "This Is Not a Drill: Real-world Datasets, Meticulous Feature Engineering, State-of-the-art AutoML",
    "text": "This Is Not a Drill: Real-world Datasets, Meticulous Feature Engineering, State-of-the-art AutoML\nTo make this exercise as realistic as possible, we will use a real-world dataset (as opposed to a simulated one), perform as much feature engineering as we would in a real-world setting, and employ the best AutoML solution the market has to offer in AutoGluon.\n\n\nCode\nonline_retail = fetch_ucirepo(id=352) \ntransaction_df = online_retail['data']['original']\noriginal_nb = transaction_df.shape[0]\n\n#create yearmon for train-valid split\ntransaction_df['yearmon'] = transaction_df.InvoiceDate.map(string_to_yearmon)\n\n#get rid of transactions without cid\ntransaction_df = transaction_df[~transaction_df.CustomerID.isna()].reset_index(drop=True)\nhas_cid_nb = transaction_df.shape[0]\n\n#fill in unknown descriptions\ntransaction_df.Description = transaction_df.Description.fillna('UNKNOWN')\n\n#convert customer id to string\ntransaction_df['CustomerID'] = transaction_df['CustomerID'].map(lambda x: str(int(x)))\n\n#simplify by filtering unit price and quantity to be non-zero (get rid of discounts, cancellations, etc)\ntransaction_df = transaction_df[(transaction_df.UnitPrice&gt;0)&\\\n                                (transaction_df.Quantity&gt;0)].reset_index(drop=True)\nhas_sales_nb = transaction_df.shape[0]\n\n#add sales\ntransaction_df['Sales'] = transaction_df.UnitPrice * transaction_df.Quantity\n\n\nWe use the UCI Online Retail dataset, which contain transactions from a UK-based, non-store online retail from 2010-12 and 2011-12. We perform the following data processing:\n\nRemove transactions without CustomerID; from 541,909 to 406,829 transactions\nFilter out transactions where either UnitPrice or Quantity is less than zero; from 406,829 to 397,884 transactions\nFill in missing product Description with value UNKNOWN.\n\n\n\nCode\nprint(transaction_df.shape)\ntransaction_df.sample(5)\n\n\n(397884, 10)\n\n\n\n\n\n\n\n\n\nInvoiceNo\nStockCode\nDescription\nQuantity\nInvoiceDate\nUnitPrice\nCustomerID\nCountry\nyearmon\nSales\n\n\n\n\n276682\n570008\n22598\nCHRISTMAS MUSICAL ZINC TREE\n12\n10/7/2011 9:30\n0.85\n13359\nUnited Kingdom\n2011-10\n10.20\n\n\n2894\n536746\n22604\nSET OF 4 NAPKIN CHARMS CUTLERY\n6\n12/2/2010 13:39\n2.55\n16510\nUnited Kingdom\n2010-12\n15.30\n\n\n238815\n566361\n85123A\nWHITE HANGING HEART T-LIGHT HOLDER\n12\n9/12/2011 12:32\n2.95\n15253\nUnited Kingdom\n2011-09\n35.40\n\n\n72407\n545830\n47590B\nPINK HAPPY BIRTHDAY BUNTING\n3\n3/7/2011 13:10\n5.45\n17634\nUnited Kingdom\n2011-03\n16.35\n\n\n78138\n546538\n15044A\nPINK PAPER PARASOL\n6\n3/14/2011 14:51\n2.95\n16327\nUnited Kingdom\n2011-03\n17.70\n\n\n\n\n\n\n\nWe formulate the problem as predicting the sales (TargetSales) during Q4 2011 for each customers who bought at least one item during Q1-Q3 2011. Note that we are interested in predicting the spend per customer as accurately as possible; this is common for marketing use cases such as determining what spend threshold to give each customer in a promotion, targeting customers for upselling, or detecting early signs of churns. It is notably different from predicting total spend of all customers during a time period, which usually requires a different approach.\n\n\nCode\nfeature_period = {'start': '2011-01', 'end': '2011-09'}\noutcome_period = {'start': '2011-10', 'end': '2011-12'}\n\nfeature_transaction = transaction_df[(transaction_df.yearmon&gt;=feature_period['start'])&\\\n                                      (transaction_df.yearmon&lt;=feature_period['end'])]\noutcome_transaction = transaction_df[(transaction_df.yearmon&gt;=outcome_period['start'])&\\\n                                      (transaction_df.yearmon&lt;=outcome_period['end'])]\n\n#aggregate sales during outcome period\noutcome_sales = outcome_transaction.groupby('CustomerID').Sales.sum().reset_index()\n\n#aggregate sales during feature period\nfeature_sales = feature_transaction.groupby('CustomerID').Sales.sum().reset_index()\n\n#merge to get TargetSales including those who spent during feature period but not during outcome (zeroes)\noutcome_df = feature_sales[['CustomerID']].merge(outcome_sales, on='CustomerID', how='left')\noutcome_df['Sales'] = outcome_df['Sales'].fillna(0)\noutcome_df.columns = ['CustomerID', 'TargetSales']\n\n\nWe transform the transaction dataset into a customer-level dataset where we calculate features using transactions between 2011-01 to 2011-09 and outcome using transactions between 2011-10 to 2011-12, summing Quantity times UnitPrice. We left-join the customers in feature set to outcome set. This will result in the zero-inflated nature of the outcome as not all customers will come back in Q4. The distribution of non-zero sales is naturally long/fat-tailed with a few customers having extraordinarily high amount of sales in Q4. This resulted in a customer-level dataset with 3,438 customers.\n\n\nCode\n#confirm zero-inflated, long/fat-tailed\noutcome_df.TargetSales.describe(percentiles=[i/10 for i in range(10)])\n\n\ncount      3438.000000\nmean        666.245829\nstd        4016.843037\nmin           0.000000\n0%            0.000000\n10%           0.000000\n20%           0.000000\n30%           0.000000\n40%           0.000000\n50%         102.005000\n60%         263.006000\n70%         425.790000\n80%         705.878000\n90%        1273.611000\nmax      168469.600000\nName: TargetSales, dtype: float64\n\n\n\n\nCode\n#confirm zero-inflated, long/fat-tailed\noutcome_df[outcome_df.TargetSales&lt;=10_000].TargetSales.hist(bins=100)\n\n\n\n\n\n\n\n\n\nWe represent a customer using traditional RFM features namely recency of purchase, purchase days, total sales, number of distinct products purchased, number of distinct category purchased, customer tenure within 2011, average purchase frequency, average purchase value, and percentage of purchase across all 9 categories. This is based on data from Q1-Q3 2011.\nSince the UCI Online Retail dataset does not have a category but only contains descriptions over 3,000 items, we use LLaMA 3.2 90B to infer categories based on randomly selected 1,000 descriptions. This is to make the category preference representation for each customer, which is more tractable than including features about all 3,548 items. After that, we use Claude 3.5 v2 to label a category for each description as it performs structured output a little more reliably. The categories are:\n\nHome Decor\nKitchen and Dining\nFashion Accessories\nStationary and Gifts\nToys and Games\nSeasonal and Holiday\nPersonal Care and Wellness\nOutdoor and Garden\nOthers\n\n\n\nCode\ndescriptions = feature_transaction.Description.unique().tolist()\nprint(descriptions[:5])\n\n#randomize descriptions with seed 112 to get which categories we should use\nnp.random.seed(112)\nrandom_descriptions = np.random.choice(descriptions, 1000, replace=False)\n\nres = call_llama(\n    'You are a product categorization assistant at a retail website.',\n    'Given the following product descriptions, come up with a few product categories they should be classified into.'+'\\n'.join(random_descriptions)\n)\n\ncategories = [\n    'Home Decor',\n    'Kitchen and Dining',\n    'Fashion Accessories',\n    'Stationary and Gifts',\n    'Toys and Games',\n    'Seasonal and Holiday',\n    'Personal Care and Wellness',\n    'Outdoor and Garden',   \n]\n\nprint(res['generation'])\n\n\n['JUMBO BAG PINK POLKADOT', 'BLUE POLKADOT WRAP', 'RED RETROSPOT WRAP ', 'RECYCLING BAG RETROSPOT ', 'RED RETROSPOT SHOPPER BAG']\n &lt;&lt;SYS&gt;&gt;Based on the product descriptions, I would categorize them into the following categories:\n\n1. Home Decor:\n    * Wall art\n    * Decorative items (e.g. vases, figurines, etc.)\n    * Lighting (e.g. candles, lanterns, etc.)\n    * Textiles (e.g. throw pillows, blankets, etc.)\n2. Kitchen and Dining:\n    * Cookware and utensils\n    * Tableware (e.g. plates, cups, etc.)\n    * Kitchen decor (e.g. signs, magnets, etc.)\n    * Food and drink items (e.g. tea, coffee, etc.)\n3. Fashion and Accessories:\n    * Jewelry (e.g. necklaces, earrings, etc.)\n    * Handbags and wallets\n    * Clothing and accessories (e.g. scarves, hats, etc.)\n    * Beauty and personal care items (e.g. cosmetics, skincare, etc.)\n4. Stationery and Gifts:\n    * Greeting cards\n    * Gift wrap and bags\n    * Stationery (e.g. notebooks, pens, etc.)\n    * Gift items (e.g. mugs, keychains, etc.)\n5. Toys and Games:\n    * Toys (e.g. stuffed animals, puzzles, etc.)\n    * Games and puzzles\n    * Outdoor toys and games\n6. Seasonal and Holiday:\n    * Christmas decorations and gifts\n    * Easter decorations and gifts\n    * Halloween decorations and gifts\n    * Other seasonal and holiday items\n7. Office and School:\n    * Office supplies (e.g. pens, paper, etc.)\n    * School supplies (e.g. backpacks, lunchboxes, etc.)\n    * Desk accessories (e.g. paperweights, etc.)\n8. Garden and Outdoor:\n    * Gardening tools and supplies\n    * Outdoor decor (e.g. planters, etc.)\n    * Patio and outdoor furniture\n9. Baby and Kids:\n    * Baby clothing and accessories\n    * Kids' clothing and accessories\n    * Toys and games for kids\n    * Nursery decor and furniture\n\nNote that some products may fit into multiple categories, but I've tried to categorize them based on their primary function or theme.\n\n\n\n\nCode\n#loop through descriptions in batches of batch_size\nres_texts = []\nbatch_size = 100\nfor i in tqdm(range(0, len(descriptions), batch_size)):\n    batch = descriptions[i:i+batch_size]\n    d = \"\\n\".join(batch)\n    inp = f'''Categorize the following product descriptions into {\", \".join(categories)} or Others, if they do not fall into any. \nOnly answer in the following format:\n\n\"product description of product #1\"|\"product category classified into\"\n\"product description of product #2\"|\"product category classified into\"\n...\n\"product description of product #n\"|\"product category classified into\"\n\nHere are the product descriptions:\n{d}\n'''\n    while True:\n        res = call_claude('You are a product categorizer at a retail website', inp)\n        # if res['generation_token_count'] &gt; 1: #for llama\n        if res['usage']['output_tokens'] &gt; 1:\n            break\n        else:\n            print('Retrying...')\n            time.sleep(2)\n    res_text = res['content'][0]['text'].strip().split('\\n')\n        #for llama\n        # .replace('[SYS]','').replace('&lt;&lt;SYS&gt;&gt;','')\\\n        # .replace('[/SYS]','').replace('&lt;&lt;/SYS&gt;&gt;','')\\\n    if res_text!='':\n        res_texts.extend(res_text)\n\nwith open('../../data/sales_prediction/product_description_category.csv','w') as f:\n    f.write('\"product_description\"|\"category\"\\n')\n    for i in res_texts:\n        f.write(f'{i}\\n')\n\n\nHere is the share of product descriptions in each annotated category:\n\n\nCode\nproduct_description_category = pd.read_csv('../../data/sales_prediction/product_description_category.csv',\n                                           sep='|')\n\n#clean product_description\nproduct_description_category['Description'] = descriptions\nproduct_description_category.category.value_counts(normalize=True)\n\n\ncategory\nHome Decor                    0.328636\nKitchen and Dining            0.195885\nFashion Accessories           0.138670\nStationary and Gifts          0.116122\nSeasonal and Holiday          0.087373\nPersonal Care and Wellness    0.047351\nToys and Games                0.045096\nOutdoor and Garden            0.032976\nOthers                        0.007892\nName: proportion, dtype: float64\n\n\nWe merge the RFM features with preference features, that is share of sales in each category for every customer, then the outcome TargetSales to create the universe set for the problem.\n\n\nCode\nfeature_transaction_cat = feature_transaction.merge(product_description_category,\n                                                    how='inner',\n                                                    on = 'Description',)\nfeature_transaction.shape, feature_transaction_cat.shape\n\n#convert invoice date to datetime\nfeature_transaction_cat['InvoiceDate'] = pd.to_datetime(feature_transaction_cat['InvoiceDate'])\n\n# last date in feature set\ncurrent_date = feature_transaction_cat['InvoiceDate'].max()\n\n#rfm\ncustomer_features = feature_transaction_cat.groupby('CustomerID').agg({\n    'InvoiceDate': [\n        ('recency', lambda x: (current_date - x.max()).days),\n        ('first_purchase_date', 'min'),\n        ('purchase_day', 'nunique'),\n    ],\n    'InvoiceNo': [('nb_invoice', 'nunique')],\n    'Sales': [\n        ('total_sales', 'sum')\n    ],\n    'StockCode': [('nb_product', 'nunique')],\n    'category': [('nb_category', 'nunique')]\n}).reset_index()\n\n# Flatten column names\ncustomer_features.columns = [\n    'CustomerID',\n    'recency',\n    'first_purchase_date',\n    'purchase_day',\n    'nb_invoice',\n    'total_sales',\n    'nb_product',\n    'nb_category'\n]\n\ncustomer_features['customer_lifetime'] = (current_date - customer_features['first_purchase_date']).dt.days\ncustomer_features['avg_purchase_frequency'] = customer_features['customer_lifetime'] / customer_features['purchase_day']\ncustomer_features['avg_purchase_value'] = customer_features['total_sales'] / customer_features['purchase_day']\n\n#category preference\ncategory_sales = feature_transaction_cat.pivot_table(\n    values='Sales', \n    index='CustomerID', \n    columns='category', \n    aggfunc='sum', \n    fill_value=0\n)\ncategory_sales.columns = [i.lower().replace(' ','_') for i in category_sales.columns]\ncustomer_features = customer_features.merge(category_sales, on='CustomerID', how='left')\n\ntotal_sales = customer_features['total_sales']\nfor col in category_sales.columns:\n    percentage_col = f'per_{col}'\n    customer_features[percentage_col] = customer_features[col] / total_sales\n\nselected_features = [\n 'recency',\n 'purchase_day',\n 'total_sales',\n 'nb_product',\n 'nb_category',\n 'customer_lifetime',\n 'avg_purchase_frequency',\n 'avg_purchase_value',\n 'per_fashion_accessories',\n 'per_home_decor',\n 'per_kitchen_and_dining',\n 'per_others',\n 'per_outdoor_and_garden',\n 'per_personal_care_and_wellness',\n 'per_seasonal_and_holiday',\n 'per_stationary_and_gifts',\n 'per_toys_and_games']\n\noutcome_variable = 'TargetSales'\n\ncustomer_features = customer_features[[ 'CustomerID']+selected_features]\ndf = outcome_df.merge(customer_features, on='CustomerID').drop('CustomerID', axis=1)\nprint(df.shape)\ndf.sample(5)\n\n\n(3438, 18)\n\n\n\n\n\n\n\n\n\nTargetSales\nrecency\npurchase_day\ntotal_sales\nnb_product\nnb_category\ncustomer_lifetime\navg_purchase_frequency\navg_purchase_value\nper_fashion_accessories\nper_home_decor\nper_kitchen_and_dining\nper_others\nper_outdoor_and_garden\nper_personal_care_and_wellness\nper_seasonal_and_holiday\nper_stationary_and_gifts\nper_toys_and_games\n\n\n\n\n2606\n0.00\n53\n2\n597.48\n138\n8\n184\n92.000000\n298.740\n0.079383\n0.433973\n0.343710\n0.003465\n0.000000\n0.041357\n0.016570\n0.056688\n0.024854\n\n\n196\n0.00\n78\n2\n2209.85\n37\n6\n226\n113.000000\n1104.925\n0.030771\n0.275245\n0.628549\n0.000000\n0.021178\n0.022535\n0.000000\n0.021721\n0.000000\n\n\n2900\n3893.79\n10\n6\n4099.11\n78\n9\n172\n28.666667\n683.185\n0.003879\n0.761507\n0.104540\n0.003879\n0.012442\n0.014015\n0.051597\n0.043312\n0.004830\n\n\n2187\n0.00\n227\n1\n122.40\n1\n1\n227\n227.000000\n122.400\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n322\n0.00\n68\n1\n147.12\n3\n2\n68\n68.000000\n147.120\n0.881729\n0.118271\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n\n\nUnivariate correlation expectedly pinpoints total_sales in during Q1-Q3 2011 as the most predictive feature; however, we can see that it is still not very predictive. This shows that the problem is not a trivial one.\n\n\nCode\nprint(df[['TargetSales','total_sales']].corr())\n\n#target and most predictive variable\ndf[df.TargetSales&lt;=25_000].plot.scatter(x='TargetSales',y='total_sales')\n\n\n             TargetSales  total_sales\nTargetSales     1.000000     0.558558\ntotal_sales     0.558558     1.000000\n\n\n\n\n\n\n\n\n\nWe randomly split the dataset into train and test sets at 80/20 ratio. We also confirm the distribution of TargetSales is similar across percentiles between train and test and only different at the upper end.\n\n\nCode\n#split into train-valid sets\ntrain_df, test_df = train_test_split(df,\n                                      test_size=0.2, \n                                      random_state=112)\npd.concat([train_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),\ntest_df.TargetSales.describe(percentiles=[i/10 for i in range(10)]).reset_index(),], axis=1)\n\n\n\n\n\n\n\n\n\nindex\nTargetSales\nindex\nTargetSales\n\n\n\n\n0\ncount\n2750.000000\ncount\n688.000000\n\n\n1\nmean\n642.650436\nmean\n760.558808\n\n\n2\nstd\n4015.305436\nstd\n4024.524400\n\n\n3\nmin\n0.000000\nmin\n0.000000\n\n\n4\n0%\n0.000000\n0%\n0.000000\n\n\n5\n10%\n0.000000\n10%\n0.000000\n\n\n6\n20%\n0.000000\n20%\n0.000000\n\n\n7\n30%\n0.000000\n30%\n0.000000\n\n\n8\n40%\n0.000000\n40%\n0.000000\n\n\n9\n50%\n91.350000\n50%\n113.575000\n\n\n10\n60%\n260.308000\n60%\n277.836000\n\n\n11\n70%\n426.878000\n70%\n418.187000\n\n\n12\n80%\n694.164000\n80%\n759.582000\n\n\n13\n90%\n1272.997000\n90%\n1255.670000\n\n\n14\nmax\n168469.600000\nmax\n77099.380000"
  },
  {
    "objectID": "posts/sales_prediction/index.html#naive-baseline-regression",
    "href": "posts/sales_prediction/index.html#naive-baseline-regression",
    "title": "Predict How Much A Customer Will Spend",
    "section": "Naive Baseline Regression",
    "text": "Naive Baseline Regression\nThe most naive solution is to simply predict TargetSales based on the features. We use a stacked ensemble of LightGBM, CatBoost, XGBoost, Random Forest and Extra Trees via AutoGluon. We train with good_quality preset, stated to be “Stronger than any other AutoML Framework”, for speedy training and inference but feel free to try more performant options. We exclude the neural-network models as they require further preprocessing of the features. We use an industry-grade, non-parametric model to be as close to a real use case as possible and make a point that the methodology works not only in a toy-dataset setup.\n\n\nCode\npreset = 'good_quality'\n\npredictor = TabularPredictor(label='TargetSales').fit(train_df[selected_features + ['TargetSales']], \n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\ntest_df['pred_baseline'] = predictor.predict(test_df[selected_features])\n\n\n\n\nCode\nmetric_baseline = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_baseline'])\nmetric_baseline['model'] = 'baseline'\nmetric_baseline\n\n\n{'root_mean_squared_error': 3162.478744240967,\n 'mean_squared_error': 10001271.807775924,\n 'mean_absolute_error': 715.6442657130541,\n 'r2': 0.3816166296854987,\n 'pearsonr': 0.6190719671013133,\n 'spearmanr': 0.47008461549340863,\n 'median_absolute_error': 232.98208312988282,\n 'earths_mover_distance': 287.77728784026124,\n 'model': 'baseline'}"
  },
  {
    "objectID": "posts/sales_prediction/index.html#regression-on-winsorized-outcome",
    "href": "posts/sales_prediction/index.html#regression-on-winsorized-outcome",
    "title": "Predict How Much A Customer Will Spend",
    "section": "Regression on Winsorized Outcome",
    "text": "Regression on Winsorized Outcome\n\n\nCode\noutlier_per = 0.99\noutlier_cap_train = train_df['TargetSales'].quantile(outlier_per)\n\n\nAn alternative approach to deal with long/fat-tailed outcome is to train on a winsorized outcome. In our case, we cap the outlier at 99.0% or TargetSales equals 7,180.81. While this solves the long/fat-tailed issues, it does not deal with zero inflation and also introduce bias to the outcome. This leads to better performance when tested on the winsorized outcome, but not so much on the original outcome.\n\n\nCode\n#winsorize\ntrain_df['TargetSales_win'] = train_df['TargetSales'].map(lambda x: outlier_cap_train if x&gt; outlier_cap_train else x)\ntest_df['TargetSales_win'] = test_df['TargetSales'].map(lambda x: outlier_cap_train if x&gt; outlier_cap_train else x)\n\npredictor = TabularPredictor(label='TargetSales_win').fit(train_df[selected_features+['TargetSales_win']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\ntest_df['pred_winsorized'] = predictor.predict(test_df[selected_features])\n\n\n\n\nCode\nmetric_winsorized = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_winsorized'])\nmetric_winsorized['model'] = 'winsorized'\nmetric_winsorized\n\n\n{'root_mean_squared_error': 3623.576377551195,\n 'mean_squared_error': 13130305.76394704,\n 'mean_absolute_error': 627.7880071099414,\n 'r2': 0.18814697894155963,\n 'pearsonr': 0.5757989413256978,\n 'spearmanr': 0.504301956183441,\n 'median_absolute_error': 219.62248107910156,\n 'earths_mover_distance': 432.1288432991232,\n 'model': 'winsorized'}"
  },
  {
    "objectID": "posts/sales_prediction/index.html#regression-on-log-plus-one-transformed-outcome",
    "href": "posts/sales_prediction/index.html#regression-on-log-plus-one-transformed-outcome",
    "title": "Predict How Much A Customer Will Spend",
    "section": "Regression on Log-plus-one-transformed Outcome",
    "text": "Regression on Log-plus-one-transformed Outcome\nLog transformation handles long/fat-tailed distribution and is especially useful for certain models since the transformed distribution is closer normal. However, it cannot handle zero-valued outcome and oftentimes scientists end up adding 1 to the outcome (so often that numpy even has a function for it). This not only introduces bias to the prediction, but also does not solve the zero-inflation as it becomes one-inflation instead.\n\n\nCode\n#log\ntrain_df['TargetSales_log1p'] = train_df['TargetSales'].map(np.log1p)\ntest_df['TargetSales_log1p'] = test_df['TargetSales'].map(np.log1p)\n\n#from zero-inflated to one-inflated\ntrain_df['TargetSales_log1p'].hist()\n\n\n\n\n\n\n\n\n\nWe can see that this is the best performing approach so far, which is one of the reasons why so many scientists end up going for this not-entirely-correct approach.\n\n\nCode\npredictor = TabularPredictor(label='TargetSales_log1p').fit(train_df[selected_features+['TargetSales_log1p']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\n\ntest_df['pred_log1p'] = predictor.predict(test_df[selected_features])\ntest_df['pred_log1p_expm1'] = test_df['pred_log1p'].map(np.expm1)\n\n\n\n\nCode\nmetric_log1p = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_log1p_expm1'])\nmetric_log1p['model'] = 'log1p'\nmetric_log1p\n\n\n{'root_mean_squared_error': 3725.342295894091,\n 'mean_squared_error': 13878175.221577456,\n 'mean_absolute_error': 618.9768466651894,\n 'r2': 0.14190585634701047,\n 'pearsonr': 0.5817166874396966,\n 'spearmanr': 0.5338156315937898,\n 'median_absolute_error': 89.55495441784018,\n 'earths_mover_distance': 581.0494444960044,\n 'model': 'log1p'}"
  },
  {
    "objectID": "posts/sales_prediction/index.html#hurdle-model",
    "href": "posts/sales_prediction/index.html#hurdle-model",
    "title": "Predict How Much A Customer Will Spend",
    "section": "Hurdle Model",
    "text": "Hurdle Model\nHurdle model is a two-stage approach that handles zero inflation by first having a classification model to predict if the outcome is zero or not, then a regression model, trained only on examples with actual non-zero outcomes, to fit a log-transformed outcome. When retransforming the predictions from log to non-log numbers, we perform correction of underestimation using Duan’s method. During inference time, we multiply the predictions from the classification and corrected regression model.\n\n\nCode\ntrain_df['has_purchase'] = train_df.TargetSales.map(lambda x: 1 if x&gt;0 else 0)\ntest_df['has_purchase'] = test_df.TargetSales.map(lambda x: 1 if x&gt;0 else 0)\n\npredictor_cls = TabularPredictor(label='has_purchase').fit(train_df[selected_features+['has_purchase']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\ntest_df['pred_binary'] = predictor_cls.predict(test_df[selected_features])\n\n\nFor our splits, 51.42% of train and 53.05% of test include customers with non-zero purchase outcome. As with all two-stage approaches, we need to make sure the intermediate model performs reasonably in classifying zero/non-zero outcomes.\n\n\nCode\ncaluclate_classification_metrics(test_df['has_purchase'], test_df['pred_binary'])\n\n\n{'accuracy': 0.6918604651162791,\n 'precision': 0.6941069004479309,\n 'recall': 0.6918604651162791,\n 'f1_score': 0.6921418829824787,\n 'confusion_matrix': array([[229,  94],\n        [118, 247]])}\n\n\n\n\nCode\ntrain_df_nonzero = train_df[train_df.has_purchase==1].reset_index(drop=True)\ntest_df_nonzero = test_df[test_df.has_purchase==1].reset_index(drop=True)\n\n#log\ntrain_df_nonzero['TargetSales_log'] = train_df_nonzero['TargetSales'].map(np.log)\ntest_df_nonzero['TargetSales_log'] = test_df_nonzero['TargetSales'].map(np.log)\n\n\nAfter that, we perform log-transformed regression on the examples with non-zero outcome (1,414 examples in train). Without the need to worry about ln(0) outcome, the regression is much more straightforward albeit with fewer examples to train on.\n\n\nCode\ntrain_df_nonzero['TargetSales_log'].hist()\n\n\n\n\n\n\n\n\n\n\n\nCode\npredictor_reg = TabularPredictor(label='TargetSales_log').fit(train_df_nonzero[selected_features+['TargetSales_log']],\n                                                      presets=preset,\n                                                      excluded_model_types=['NN_TORCH','FASTAI','KNN'],\n                                                      )\ntest_df_nonzero['pred_log'] = predictor_reg.predict(test_df_nonzero[selected_features])\ntest_df_nonzero['pred_log_exp'] = test_df_nonzero['pred_log'].map(np.exp)\n\ntest_df['pred_log'] = predictor_reg.predict(test_df[selected_features])\ntest_df['pred_log_exp'] = test_df['pred_log'].map(np.exp)\n\ntest_df['pred_hurdle'] = test_df.pred_binary * test_df.pred_log_exp\n\n\nFor inference, we combine the binary prediction (purchase/no purchase) from the classification model with the re-transformed (exponentialized) numerical prediction from the regression model by simply multiplying them together. As you can see, this approach yields the best performance so far and this is where I used to think everything has been accounted for.\n\n\nCode\nmetric_hurdle = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle'])\nmetric_hurdle['model'] = 'hurdle'\nmetric_hurdle\n\n\n{'root_mean_squared_error': 3171.760744960863,\n 'mean_squared_error': 10060066.22327469,\n 'mean_absolute_error': 584.9162934881963,\n 'r2': 0.3779813431428882,\n 'pearsonr': 0.6769697889999318,\n 'spearmanr': 0.5107083593715698,\n 'median_absolute_error': 199.1780137692856,\n 'earths_mover_distance': 286.381442541919,\n 'model': 'hurdle'}"
  },
  {
    "objectID": "posts/sales_prediction/index.html#but-wait-there-is-moreーenter-naihua-duan",
    "href": "posts/sales_prediction/index.html#but-wait-there-is-moreーenter-naihua-duan",
    "title": "Predict How Much A Customer Will Spend",
    "section": "But Wait, There Is MoreーEnter Naihua Duan",
    "text": "But Wait, There Is MoreーEnter Naihua Duan\nIn the previous section, we have blissfully assumed that we can freely log-transform and re-transform the outcome during training and inference without any bias. This is not the case as there is a small bias generated in the process due to the error term.\n\\[ln(y) = f(X) + \\epsilon\\]\nwhere\n\n\\(y\\) is actual outcome.\n\\(X\\) is the features.\n\\(f(.)\\) is a trained model.\n\\(\\epsilon\\) is the error term.\n\nwhen re-transforming\n\\[\n\\begin{align}\ny &= exp(ln(y)) \\\\\n&= exp(f(X) + \\epsilon ) \\\\\n&= exp(f(X)) \\cdot exp(\\epsilon) \\\\\nE[y] &= E[exp(f(X))] \\cdot E[exp(\\epsilon)]\n\\end{align}\n\\]\nThe average treatment affect (ATE; \\(E[y]\\)) is underestimated by \\(E[exp(\\epsilon)]\\). Naihua Duan (段乃華), a Taiwanese biostatistician, suggested a consistent estimator of \\(E[exp(\\epsilon)]\\) in his 1983 work as\n\\[\n\\begin{align}\n\\hat \\lambda &= E[exp(ln(y) - ln(\\hat y))]\n\\end{align}\n\\]\nwhere\n\n\\(\\hat \\lambda\\) is the Duan’s smearing estimator of the bias from re-transformation \\(E[exp(\\epsilon)]\\)\n\\(\\hat y\\) is the prediction aka \\(f(X)\\)\n\nFun Fact: If you assume Duan were a western name, you would have been \npronouncing the method's name incorrectly since it should be [twàn]'s \nmethod, NOT /dwɑn/'s method.\nBefore we proceed, the formulation of Duan’s smearing estimator assumes that estimates of error terms (residuals) for log predictions be independent and identically distributed. Since we are dealing with individual customers, independence can be assumed. However, if we look at the plot of residuals vs predicted log values (based on training set), we can see that they do not look particularly identically distributed.\n\n\nCode\n#plot residual and predicted log value\ntrain_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\ntrain_df_nonzero['residual_log'] = (train_df_nonzero['pred_log'] - train_df_nonzero['TargetSales_log'])\n\n# Create the scatter plot\nsns.scatterplot(x='pred_log', y='residual_log', data=train_df_nonzero)\n\n# Add the Lowess smoothing line\nsns.regplot(x='pred_log', y='residual_log', data=train_df_nonzero, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n\n\n\n\n\n\n\n\n\nAlthough note that White test does not reject the null hypothesis of the residuals being homoscedastic in reference to the features. This counterintuitive result might stem from the fact that White test is assuming linear or quadratic relationships between outcome and features while the residuals are derived from a stacked ensemble of decision trees.\n\n\nCode\nwhite_stat, white_p_value, _, _ = het_white(train_df_nonzero['residual_log'], \n                                            train_df_nonzero[selected_features])\nprint(f\"White Test Statistic: {white_stat}\")\nprint(f\"P-value: {white_p_value}\")\n\n\nWhite Test Statistic: 129.31318320644837\nP-value: 0.8761278601130765\n\n\nOur choice is to either trust the White test and pretend assume everything is fine; or trust our eyes and replace the non-zero regression model with one that produces iid residuals such as generalized least squares (GLS) with heteroscedasticity-robust standard errors. The tradeoff is that often models that produce homoscedastic residuals perform worse in terms of predictive power (see example of GLS implementation in Assumption on Indepedent and Identically Distributed Residuals section of the notebook).\nAssuming we trust the White test, we can easily derive Duan’s smearing estimator by taking mean of error between actual and predicted TargetSales in the training set.\n\n\nCode\ntrain_df_nonzero['pred_log'] = predictor_reg.predict(train_df_nonzero[selected_features])\ntrain_df_nonzero['pred_log_exp'] = train_df_nonzero['pred_log'].map(np.exp)\n\nsmearing_estimator = np.mean(np.exp(train_df_nonzero['TargetSales_log'] - train_df_nonzero['pred_log']))\nsmearing_estimator\n\n\n1.2280991653046711\n\n\nWe multiply this to the predictions of the hurdle model to correct the underestimation due to re-transformation bias.\n\n\nCode\ntest_df['pred_log_exp_corrected'] = test_df['pred_log_exp'] * smearing_estimator\ntest_df['pred_hurdle_corrected'] = test_df.pred_binary * test_df.pred_log_exp_corrected\n\nmetric_hurdle_corrected = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected'])\nmetric_hurdle_corrected['model'] = 'hurdle_corrected'\nmetric_hurdle_corrected\n\n\n{'root_mean_squared_error': 3055.3207868281233,\n 'mean_squared_error': 9334985.110424023,\n 'mean_absolute_error': 613.3946643257099,\n 'r2': 0.42281345159207295,\n 'pearsonr': 0.6769697889999318,\n 'spearmanr': 0.5107083593715698,\n 'median_absolute_error': 232.55557358084502,\n 'earths_mover_distance': 241.61839859133218,\n 'model': 'hurdle_corrected'}"
  },
  {
    "objectID": "posts/sales_prediction/index.html#the-eval-bar",
    "href": "posts/sales_prediction/index.html#the-eval-bar",
    "title": "Predict How Much A Customer Will Spend",
    "section": "The Eval Bar",
    "text": "The Eval Bar\nWe can see that the hurdle model with Duan’s correction performs best across majority of the metrics. We will now deep dive on metrics where it did not to understand the caveats when taking this approach.\n\n\nCode\nmetric_df = pd.DataFrame([metric_baseline,\n                       metric_winsorized,\n                       metric_log1p,\n                       metric_hurdle,\n                       metric_hurdle_corrected,])\n\nrank_df = metric_df.copy()\nfor col in metric_df.columns.tolist()[:-1]:\n    if col in ['r2', 'pearsonr', 'spearmanr']:\n        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=False)\n    else:\n        rank_df[f'{col}_rank'] = rank_df[col].rank(ascending=True)\nrank_df = rank_df.drop(metric_df.columns.tolist()[:-1], axis=1)\nrank_df['avg_rank'] = rank_df.iloc[:,1:].mean(axis=1)\nrank_df.transpose()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\n\n\nroot_mean_squared_error_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\nmean_squared_error_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\nmean_absolute_error_rank\n5.0\n4.0\n3.0\n1.0\n2.0\n\n\nr2_rank\n2.0\n4.0\n5.0\n3.0\n1.0\n\n\npearsonr_rank\n3.0\n5.0\n4.0\n1.5\n1.5\n\n\nspearmanr_rank\n5.0\n4.0\n1.0\n2.5\n2.5\n\n\nmedian_absolute_error_rank\n5.0\n3.0\n1.0\n2.0\n4.0\n\n\nearths_mover_distance_rank\n3.0\n4.0\n5.0\n2.0\n1.0\n\n\navg_rank\n3.375\n4.0\n3.625\n2.25\n1.75\n\n\n\n\n\n\n\n\n\nCode\nmetric_df.transpose()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\nroot_mean_squared_error\n3162.478744\n3623.576378\n3725.342296\n3171.760745\n3055.320787\n\n\nmean_squared_error\n10001271.807776\n13130305.763947\n13878175.221577\n10060066.223275\n9334985.110424\n\n\nmean_absolute_error\n715.644266\n627.788007\n618.976847\n584.916293\n613.394664\n\n\nr2\n0.381617\n0.188147\n0.141906\n0.377981\n0.422813\n\n\npearsonr\n0.619072\n0.575799\n0.581717\n0.67697\n0.67697\n\n\nspearmanr\n0.470085\n0.504302\n0.533816\n0.510708\n0.510708\n\n\nmedian_absolute_error\n232.982083\n219.622481\n89.554954\n199.178014\n232.555574\n\n\nearths_mover_distance\n287.777288\n432.128843\n581.049444\n286.381443\n241.618399\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\n\n\n\n\n\n\n\n\nWhy Duan’s Correction Results in Slightly Worse MAE?\nDuan’s method adjusts for underestimation from re-transformation of log outcome. This could lead to smaller extreme errors, but more frequent occurrences of less extreme ones. We verify this hypothesis by comparing mean absolute error before and after transformation for errors originally under and over 99th percentile. We confirm that is the case for our problem.\n\n\nCode\nerr_hurdle = (test_df['TargetSales'] - test_df['pred_hurdle']).abs()\nerr_hurdle_corrected = (test_df['TargetSales'] - test_df['pred_hurdle_corrected']).abs()\n\nprint('Distribution of errors for Hurdle model without correction')\nerr_hurdle.describe(percentiles=[.25, .5, .75, .9, .95, .99]) \n\n\nDistribution of errors for Hurdle model without correction\n\n\ncount      688.000000\nmean       584.916293\nstd       3119.628924\nmin          0.000000\n25%          0.000000\n50%        199.178014\n75%        475.603446\n90%        862.530026\n95%       1237.540954\n99%       6763.777844\nmax      55731.205996\ndtype: float64\n\n\n\n\nCode\nprint('Hurdle Model without correction')\nprint(f'Mean absolute error under 99th percentile: {err_hurdle[err_hurdle&lt;6763.777844].mean()}')\nprint(f'Mean absolute error over 99th percentile: {err_hurdle[err_hurdle&gt;6763.777844].mean()}')\n\nprint('Hurdle Model with correction')\nprint(f'Mean absolute error under 99th percentile: {err_hurdle_corrected[err_hurdle&lt;6763.777844].mean()}')\nprint(f'Mean absolute error over 99th percentile: {err_hurdle_corrected[err_hurdle&gt;6763.777844].mean()}')\n\n\nHurdle Model without correction\nMean absolute error under 99th percentile: 355.4918014848842\nMean absolute error over 99th percentile: 22904.641872667555\nHurdle Model with correction\nMean absolute error under 99th percentile: 392.7718802742851\nMean absolute error over 99th percentile: 22076.839798471465\n\n\n\n\nImportance of Classification Model\nThe overperformance of log-transform regression over both hurdle model approarches in Spearman’s rank correlation and median absolute error demonstrates the importance of a classification model. At first glance, it is perplexing since we have just spent a large portion of this article to justify that hurdle models handle zero inflation better and re-transformation without Duan’s method is biased. However, it becomes clear once you compare performance of the hurdle model with a classification model (f1 = 0.69) and a hypothetical, perfect classification model. Other metrics also improved but not nearly as drastic as MedAE and Spearman’s rank correlation.\n\n\nCode\ntest_df['pred_hurdle_corrected_perfect_cls'] = test_df.has_purchase * test_df.pred_log_exp_corrected\nmetric_hurdle_corrected_perfect_cls = calculate_regression_metrics(test_df['TargetSales'], test_df['pred_hurdle_corrected_perfect_cls'])\nmetric_hurdle_corrected_perfect_cls['model'] = 'hurdle_corrected_perfect_cls'\n\nmetric_df2 = pd.DataFrame([metric_baseline,\n                       metric_winsorized,\n                       metric_log1p,\n                       metric_hurdle,\n                       metric_hurdle_corrected,\n                       metric_hurdle_corrected_perfect_cls,])\nmetric_df2.transpose()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\nroot_mean_squared_error\n3162.478744\n3623.576378\n3725.342296\n3171.760745\n3055.320787\n3030.854831\n\n\nmean_squared_error\n10001271.807776\n13130305.763947\n13878175.221577\n10060066.223275\n9334985.110424\n9186081.006625\n\n\nmean_absolute_error\n715.644266\n627.788007\n618.976847\n584.916293\n613.394664\n479.558294\n\n\nr2\n0.381617\n0.188147\n0.141906\n0.377981\n0.422813\n0.43202\n\n\npearsonr\n0.619072\n0.575799\n0.581717\n0.67697\n0.67697\n0.687639\n\n\nspearmanr\n0.470085\n0.504302\n0.533816\n0.510708\n0.510708\n0.929419\n\n\nmedian_absolute_error\n232.982083\n219.622481\n89.554954\n199.178014\n232.555574\n34.991964\n\n\nearths_mover_distance\n287.777288\n432.128843\n581.049444\n286.381443\n241.618399\n234.587018\n\n\nmodel\nbaseline\nwinsorized\nlog1p\nhurdle\nhurdle_corrected\nhurdle_corrected_perfect_cls\n\n\n\n\n\n\n\n\n\nRemember What Problem We Are Solving\nOne last thing to remember is that we are trying to predict sales of each individual customer, not total sales of all customers. If we look at aggregated mean or sum of actual sales vs predicted sales, baseline regression performs best by far. This is due to the fact that without any constraints a regressor only minimizes the MSE loss and usually ends up predicting values around the mean to balance between under- and over-predictions. However, this level of prediction is often not very useful as a single point. Imagine you want to give promotions with higher or lower spend thresholds to customers according to their purchasing power; you will not be able to do so with a model that is accurate on aggregate but not so much on individual customers.\n\n\nCode\ntest_df[['TargetSales','pred_baseline','pred_winsorized','pred_log1p_expm1','pred_hurdle','pred_hurdle_corrected']].mean()\n\n\nTargetSales              760.558808\npred_baseline            791.043945\npred_winsorized          508.281555\npred_log1p_expm1         186.200281\npred_hurdle              527.286811\npred_hurdle_corrected    647.560493\ndtype: float64"
  },
  {
    "objectID": "posts/sales_prediction/index.html#closing-remarks",
    "href": "posts/sales_prediction/index.html#closing-remarks",
    "title": "Predict How Much A Customer Will Spend",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nAnd this is how you predict how much a customer will spend in the least wrong way. My hope is that you will not need to spend ten years in data science to find out how to do it like I did."
  },
  {
    "objectID": "posts/interesting_career/index.html",
    "href": "posts/interesting_career/index.html",
    "title": "How to Have a Robustly Interesting Career in Data Science",
    "section": "",
    "text": "I have been a data scientist👨‍💻 ever since around the time HBR popularized the term in its job sexiness article. My run started out of necessity, since back then it was very difficult to get a job when you were an Econ graduate with an eclectic mix of skills in statistics and programming; suddenly it became one of the most sought-after skill combinations on the market. It has been about a decade since. Lately, I have been asked about how to have a successful career in the field. Success is quite the subjective term, but let me try to formulate my thoughts on how to keep it interesting doing what I love in spite of external circumstances.\n\n\n\nfeatured_image\n\n\nObjective Function As any half decent scientist would do, let us begin at the desirable end state and work backwards. I have always optimized for business impact. I relish in seeing my models bring joy to customers, efficiency to selling partners, and productivity to fellow builders. Something as simple as seeing a widget on the home screen powered by one of my models makes my day. Thankfully, my data products have consistently delivered at least double-digit millions of dollars in value (cost savings and/or top-line uplifts) annually. And this keeps me sane in the midst of all the [insert-your-hype-keyword] FOMO. The key is to find an objective function that really matters to you, and not fall for the vanity metrics. For instance, I have written some research papers and did some fun open source projects, but a lot of these feel too abstract to quantify. If I were to try to optimize for them, I would likely end up chasing after citations, Github stars, or other arbitrary numbers. I would overfit them and the activities of writing papers and contributing to open source projects themselves would become secondary to the vanity metrics. This will not be the case if writing great research papers is something that really matters to you. You need to find an objective function that correlates almost perfectly with the joy you experience as a scientist.\nBuild with Stakes As you move to fulfill your objectives, it is important that you do so by building concrete products with high enough stakes. I strongly believe this is the only way to level up as a scientist. The anti-thesis to this is to get stuck in the learning loop; you keep taking online courses, overfitting toy datasets, hunting for certificates, and you wonder why your career is not going anywhere while the snakeoil vendors keep buying new sports cars. It is because these learning materials when taken in excess only serve to make you feel good about yourself. Yes, you learned something new and yes, you might have built some capstone projects. But these have virtually no consequence if you fail. In fact, they are structured in a way that it is more difficult for you to fail. You stop thinking for yourself and just enjoy the pseudo-intellectual force feeding. It comes as no surprise that you need to think for yourself to grow as a scientist. The stakes do not have to be monetary. It can be anything that matters if you fail to complete your tasks. Enter a competition that evaluates scientific prowess (avoid slide show contests), create an open source project that helps with your hobbies, or most likely propose a project at work that affects your compensation/promotion evaluation. Conduct experiments, write production codes, and document everything either as technical reports or research papers. Hold yourself to the highest standards.\nFind The Right Party The most important person in your career is your mentor. Ideally, you want to find the person whose objective function aligns well with yours and have a clear track records of building with stakes. At different stages, you might have more than one for different aspects such as one for business and another for research, or for different perspectives. But if I were to be honest, you would be extremely lucky to find one at all. Your mentor should not only be the person you aspire to be, but also someone you think you would have a chance to overcome in a fair fight one day. Once you have found such person, you would usually be surrounded by good company. Humans are social animals and no matter how hard you try to follow your objective function and hold yourself to the highest standards, it will be almost impossible without people with similar mentality by your side. This is the most luck-dependent component. Be grateful if you can find the right party and be the party people would like to join one day.\nIntegrity Every action has a price. We are in a privileged position to have a skillset that often determines the outcome of the business and rarely people question. You could gain a small but decisive advantage almost scotch-free; keep randomizing the seeds in validation splits and/or model initialization to get a marginally good result in offline evaluation to justify a launch, slice and dice the control and treatment groups to get a statistically significant result, pick a seemingly strong model that is out-of-domain to compare with your specifically finetuned model and call your model SoTA, the list goes on. But you should never do any of this, not only because you are a good person who does not want to lose sleep, but because you will eventually pay the price. I can guarantee there is always a price. Any useful scientist will call you out on any of the examples I gave; if not, time and repeated online experiments will expose your fudging of the numbers. Your choice is to keep job hopping before this happens and keep the career Ponzi scheme alive. Or simply be an honest scientist, enjoys the scientific process, learns from your mistakes, and grow.\nSide Quests Whatever you do, there is always a room for side quests. Your main quest is to satisfy your objective function, but as any good optimization method, exploration is needed to ensure a robust solution. A side quest is an excuse to try the new technology you have been raring to get your hands on, a low-stake confidence builder, and most importantly a great way to remind us how much we love the craft. These are things I hold closest to my heart as I navigate the fast-paced, uncertainty-filled landscape of data science. I have conducted a few dozens of model validation experiments and each one is never less anxiety-inducing than the last. We are in the business of results and results can be brutal. In these turbulent economic conditions, I hope these templates can be useful to you as much as they were to me in surviving some unpleasant situations that may be beyond our control and continuing to do the things we love.\nBe safe from scammers and snakeoil vendors. And I will see you around."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chariblog - technical writings in applied science",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPredict How Much A Customer Will Spend\n\n\n\nretail\n\nzero-inflated\n\nlong/fat-tailed\n\nhurdle\n\n\n\n\n\n\n\n\n\n2024-11-25\n\n\ncstorm125\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Have a Robustly Interesting Career in Data Science\n\n\n\ncareer\n\n\n\n\n\n\n\n\n\n2024-11-23\n\n\ncstorm125\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebook/sql_almost_exercise.html#sanity-checks",
    "href": "notebook/sql_almost_exercise.html#sanity-checks",
    "title": "(Almost) All SQL You Need Exercise: Personalized Recommendation",
    "section": "Sanity Checks",
    "text": "Sanity Checks\nAfter downloading and creating transaction_tbl in our database, let us first do some sanity checks.\n\n# @title Query to randomly see 100 rows\n\nanswer_key = f\"\"\"\nselect * from transaction_tbl limit 100;\n\"\"\"\nhint = 'select * and limit'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Count how many events, how many unique customers, how many unique items, how many unique event types.\n\nanswer_key = f\"\"\"\nselect\n count(*) as nb_event\n ,count(distinct user_id) as nb_user\n ,count(distinct item_id) as nb_item\n ,count(distinct behavior_type) as nb_event_type\nfrom transaction_tbl;\n\"\"\"\nhint = 'count and count distinct'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title How many events and unique users per event type?\n\nanswer_key = f\"\"\"\nselect\n behavior_type\n ,count(*) as nb_event\n ,count(distinct user_id) as nb_user\nfrom transaction_tbl\ngroup by 1;\n\"\"\"\nhint = 'group by'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Convert integer timestamp into human-readable timestamp `event_timestamp` and date `event_date`, then save as `transaction_tbl_x` view.\n\nanswer_key = f\"\"\"\ncreate or replace view transaction_tbl_x as (\nselect\n a.*\n ,to_timestamp(a.timestamp) as event_timestamp\n ,strftime(to_timestamp(a.timestamp), '%Y-%m-%d') as event_date\n ,substring(cast(to_timestamp(a.timestamp)as varchar),1,7) as year_month --optional\nfrom transaction_tbl a\n);\n\nselect * from transaction_tbl_x limit 10;\n\"\"\"\nhint = 'to_timestamp and date_trunc'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Check distribution of `event_date`. Is there anything weird?\n\nanswer_key = f\"\"\"\nselect\n event_date\n ,count(*) as nb_event\nfrom transaction_tbl_x\ngroup by 1\norder by 1;\n\"\"\"\nhint = 'Do not forget we are using `transaction_tbl_x` now. Order by `event_date` to see if there is anything odd.'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\nIt is quite clear from exploration that most of the events come from 2017-11-25 to 2017-12-03, so let us use 2017-11-25 to 2017-11-30 as training set and 2017-12-01 to 2017-12-03 as test set. If this were your production database, having events from the 1920s mixed in there should raise a flag but we will ignore them in this educational setting.\n\n# @title Create `train_tbl` with events from `2017-11-25` to `2017-11-30` and `test_tbl` with events from `2017-12-01` to `2017-12-03`\n\nanswer_key = f\"\"\"\ncreate or replace view train_tbl as (\nselect\n *\nfrom transaction_tbl_x\nwhere event_date between '2017-11-25' and '2017-11-30'\n);\n\ncreate or replace view test_tbl as (\nselect\n *\nfrom transaction_tbl_x\nwhere event_date between '2017-12-01' and '2017-12-03'\n);\n\nselect 'train' split, count(*) nb_event, count(distinct user_id) nb_user from train_tbl\nunion all\nselect 'test' split, count(*) nb_event, count(distinct user_id) nb_user from test_tbl;\n\"\"\"\nhint = 'where-clause and `between`'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)"
  },
  {
    "objectID": "notebook/sql_almost_exercise.html#success-measurement-metric-and-baseline",
    "href": "notebook/sql_almost_exercise.html#success-measurement-metric-and-baseline",
    "title": "(Almost) All SQL You Need Exercise: Personalized Recommendation",
    "section": "Success Measurement: Metric and Baseline",
    "text": "Success Measurement: Metric and Baseline\nOur task is to recommend 10 items that each user will most likely purchase during the test set period. The only information we have is what they viewed (pv), added to cart (cart) or favorited (fav) during the training set period.\n\nMetric\nOur metric is top-10 hit rate based on purchases. This means that for each customer, we will recommend 10 items and if the user purchased any of those items during the test set period, the user is marked as 1 else as 0. We then take an average across all users to get our score.\nExample: top-3 hit rate calculation\n\n\n\nuser_id\npred\nis_purchased_in_test_tbl\n\n\n\n\nA\nX\n0\n\n\nA\nY\n0\n\n\nA\nZ\n1\n\n\nB\nW\n0\n\n\nB\nT\n0\n\n\nB\nR\n0\n\n\nC\nQ\n0\n\n\nC\nT\n1\n\n\nC\nX\n1\n\n\n\n\n\n\nuser_id\nhit\nhit_flag\n\n\n\n\nA\n1\n1\n\n\nB\n0\n0\n\n\nC\n2\n1\n\n\n\n\ntop-3 hit rate = 1+0+1 / 3 = 66%\n\n\n\nBaseline\nThe most simple baseline we can compare our recommendation system with is recommending top-10 best-selling items to all users.\nLet us try to measure the performance of this simple baseline.\n\n# @title Create view `eval_tbl` containing `user_id`, `item_id` only for items the users in `test_tbl` purchased (`buy`)\n\nanswer_key = f\"\"\"\ncreate or replace view eval_tbl as (\nselect\n user_id\n ,item_id\nfrom test_tbl\nwhere behavior_type = 'buy'\ngroup by 1,2\n);\n\nselect * from eval_tbl;\n\"\"\"\nhint = 'group by and where'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Get top 10 most-interacted items in training set\n\nanswer_key = f\"\"\"\nselect\n item_id\n ,count(*) as nb_event\nfrom train_tbl\ngroup by 1\norder by 2 desc\nlimit 10;\n\"\"\"\nhint = 'group by and limit'\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Create view `pred_top10_tbl` containing all `user_id` from `test_tbl`. Each `user_id` should have 10 rows each row with the 10 recommendations, in this case top-10 most interacted items (same for all `user_id`).\nanswer_key = f\"\"\"\ncreate or replace view pred_top10_tbl as (\n\nwith test_user_tbl as (\nselect\n user_id\n ,max(1) as joining_column\nfrom test_tbl\ngroup by 1),\n\ntop10_tbl as (\nselect\n item_id\n ,count(*) as nb_buy\n ,max(1) as joining_column\nfrom train_tbl\ngroup by 1\norder by 2 desc\nlimit 10)\n\nselect\n a.user_id\n ,b.item_id\nfrom test_user_tbl a\ninner join top10_tbl b\non a.joining_column = b.joining_column\n);\n\nselect count(*) nb_pred, count(distinct user_id) nb_user from pred_top10_tbl;\n\"\"\"\nhint = '''\nYou need to create a new `joining_column` that is all the same values max(1) to `inner join` on.\nOr use `cross join`: https://www.geeksforgeeks.org/sql/sql-cross-join/\ncount(distinct user_id) and count(*) again to make sure that each user has 10 recommendations.\n'''\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here. This is a tough one so you might want to use the hint.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title With `pred_top10_tbl` and `eval_tbl`, calculate top-10 hit rate\n\nanswer_key = f\"\"\"\nselect\n avg(case when nb_hit &gt; 0 then 1 else 0 end) as top_10_hit_rate\nfrom\n(select\n a.user_id\n ,sum(case when b.item_id is not null then 1 else 0 end) as nb_hit\nfrom eval_tbl a\nleft join pred_top10_tbl b\non a.user_id = b.user_id\n and a.item_id = b.item_id\ngroup by 1) c;\n\"\"\"\nhint = f\"\"\"\nRemember that we average 1/0s across users, not items.\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\nConsidering we have 1,253,465 items in total, it is not surprising that our top-10 hit rate is only 0.0923% of all users in the test set. Let us see if we can do better."
  },
  {
    "objectID": "notebook/sql_almost_exercise.html#recommend-what-they-have-interacted-with-but-have-yet-bought",
    "href": "notebook/sql_almost_exercise.html#recommend-what-they-have-interacted-with-but-have-yet-bought",
    "title": "(Almost) All SQL You Need Exercise: Personalized Recommendation",
    "section": "Recommend what they have interacted with but have yet bought",
    "text": "Recommend what they have interacted with but have yet bought\nOne of the most powerful recommendation algorithm is to recommend what users have interacted with the most. In fact, this is what you would see in world’s best online retail sites, especially those dealing with groceries, beauty, and health and personal care. We add a small twist by only ordering the top-10 recommendation for each customer by all interactions (pv, cart, fav) EXCEPT buy. This is because if a user has bought the item before, it might not be likely for them to buy again in such as short period of time between training set and test set.\n\n# @title Create view `pred_mfp_tbl` containing all `user_id` from `train_tbl`. Each user should have 10 recommendations based on the top-10 items, ordered by the number of times they have interacted (`pv`, `cart`, `fav`) with, but have yet bought (`buy`).\n\nanswer_key = f\"\"\"\ncreate or replace view pred_mfp_tbl as (\nselect * from\n(select\n user_id\n ,item_id\n ,row_number() over (partition by user_id order by nb_nonbuy_event desc) as rnk\nfrom\n(select\n user_id\n ,item_id\n ,count(*) as nb_nonbuy_event\nfrom train_tbl\nwhere behavior_type &lt;&gt; 'buy'\ngroup by 1,2) a\n) b\nwhere rnk &lt;=10);\n\nselect\n nb_pred\n ,count(*) as nb_user\nfrom\n(select\n user_id\n ,count(*) as nb_pred\nfrom pred_mfp_tbl\ngroup by 1) a\ngroup by 1 order by 2 desc;\n\"\"\"\nhint = f\"\"\"\nWe need window function to make sure we have at most 10 items per customer.\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Check if we have recommendation in `pred_mfp_tbl` for every user in `test_tbl`?\n\nanswer_key = f\"\"\"\nselect\n avg(case when b.user_id is not null then 1 else 0 end) as has_pred\nfrom (select distinct user_id from test_tbl) a\nleft join (select distinct user_id from pred_mfp_tbl) b\non a.user_id = b.user_id;\n\"\"\"\nhint = f\"\"\"\nleft join then count the nulls\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title For users who we do not have recommendations for in `pred_mfp_tbl`, give them recommendations from `pred_top10_tbl`. Create a new view for this called `pred_final_tbl`.\n\nanswer_key = f\"\"\"\ncreate or replace view pred_top10_tbl_missing_only as (\nselect\n a.user_id\n ,a.item_id\nfrom pred_top10_tbl a\nleft join pred_mfp_tbl b\non a.user_id = b.user_id\nwhere b.user_id is null);\n\ncreate or replace view pred_final_tbl as (\nselect user_id,item_id from pred_mfp_tbl\nunion all\nselect user_id,item_id from pred_top10_tbl_missing_only);\n\nselect 'pred' split, count(*) nb_pred, count(distinct user_id) nb_user from pred_final_tbl\nunion all\nselect 'test' split, count(*) nb_pred, count(distinct user_id) nb_user from test_tbl;\n\"\"\"\nhint = f\"\"\"\nOne way you can do this is:\n\n1) Find out who did not get recommendation in `pred_mfp_tbl`\n2) Filter `pred_top10_tbl` to have only those users\n3) Concatenate `pred_top10_tbl` containing the missing users and `pred_mfp_tbl` to create view `pred_final_tbl`. Make sure columns are the same when you concatenate.\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n\n# @title Calculate top-10 hit rate for `pred_final_tbl` and see if it is better than `pred_top10_tbl`\n\nanswer_key = f\"\"\"\nselect\n 'pred_top10_tbl' model\n ,avg(case when nb_hit &gt; 0 then 1 else 0 end) as top_10_hit_rate\nfrom\n(select\n a.user_id\n ,sum(case when b.item_id is not null then 1 else 0 end) as nb_hit\nfrom eval_tbl a\nleft join pred_top10_tbl b\non a.user_id = b.user_id\n and a.item_id = b.item_id\ngroup by 1) c\n\nunion all\n\nselect\n 'pred_final_tbl' model\n ,avg(case when nb_hit &gt; 0 then 1 else 0 end) as top_10_hit_rate\nfrom\n(select\n a.user_id\n ,sum(case when b.item_id is not null then 1 else 0 end) as nb_hit\nfrom eval_tbl a\nleft join pred_final_tbl b\non a.user_id = b.user_id\n and a.item_id = b.item_id\ngroup by 1) c;\n\"\"\"\nhint = f\"\"\"\nDo the same thing as what you did for `pred_top10_tbl` then concatenate the result together.\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)\n\n🎊 Congratulations! You have made 21x improvement on the baseline to get almost 2% top-10 hit rate. This marks the end of this exercise but if you want to further improve our algorithm, feel free to do so with the console below.\n\n# @title Run anything\n\nanswer_key = f\"\"\"\nThere is no correcrt answer in life.\n\"\"\"\nhint = f\"\"\"\nYou just need to mess around and find out.\n\"\"\"\n\n#input\ntext_area = widgets.Textarea(\n    value=\"Write your query here.\",\n    rows=10,  # Initial number of visible rows\n    description=\"Query:\",\n    layout={'width': '730px'} # Adjust width as needed\n)\n\n#output\nquery_result = query_result = widgets.Output(\n    layout=widgets.Layout(\n        border='1px solid lightgray', # Add a border to make the scrollable area visible\n        height='300px',              # Fixed height for the output area\n        overflow_y='scroll'          # Enable vertical scrolling\n    )\n)\n\n#button\nexecute_button = widgets.Button(\n    description='Execute query',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef process_query(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        display(execute_query(query))\nexecute_button.on_click(process_query)\n\nanswer_button = widgets.Button(\n    description='Reveal answer key',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_answer_key(b):\n    query = text_area.value\n    with query_result:\n        query_result.clear_output()\n        print(f'Answer key is: \\n{answer_key}')\nanswer_button.on_click(show_answer_key)\n\nhint_button = widgets.Button(\n    description='Reveal hint',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    icon='check' # (FontAwesome icons available)\n)\ndef show_hint(b):\n    with query_result:\n        query_result.clear_output()\n        print(f'Hint: \\n{hint}')\nhint_button.on_click(show_hint)\n\ndisplay(text_area, execute_button, hint_button, answer_button, query_result)"
  }
]